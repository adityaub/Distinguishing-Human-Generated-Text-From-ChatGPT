category,text,Label,Result
0,"NLP is a multidisciplinary field that draws from linguistics and computer science, particularly artificial intelligence ,.  In terms of linguistics, a program must be able to deal with words that have multiple meanings (“wind up the clock” and “the wind is cold today”) as well as grammatical ambiguities (in the phrase “little girl’s school” is it the school that is little, the girls, or both?).  Of course each language has its own forms of ambiguity. Programs can use several strategies for dealing with these problems, including using statistical models to predict the likely meaning of a given phrase based on a “corpus” of existing text in that language ,. As formidable as the task of extracting the correct (literal) meaning from text can be, it is really only the first level of natural language processing.  If a program is to successfully summarize or draw conclusions about a news report from North Korea, for example, it would also have to have a knowledge base of facts about that country and/or a set of “frames” , about how to interpret various situations such as threat, bluff, or compromise. )",0,Human
1,"There are a variety of emerging applications for NLP, including the following:, voice-controlled computer interfaces (such as in aircraft cockpits), programs that can assist with planning or other tasks ,, more-realistic interactions with computer-controlled game characters, robots that interact with humans in various settings such as hospitals, automatic analysis or summarization of news stories and other text, intelligence and surveillance applications (analysis of communication, etc. ), data mining, creating consumer profiles, and other ecommerce applications, search-engine improvements, such as in determining relevancy",0,Human
2,"As each new means of communication and social interaction is introduced, social customs and etiquette evolve in response.  For example, it took time before the practice of saying “hello” and identifying oneself became the universal way to initiate a phone conversation. By the 1980s, a system of topical news postings , carried on the Internet was becoming widely used in universities, the computer industry, and scientific institutions.  Many new users did not understand the system, and posted messages that were off topic.  Others used their postings as to insult or attack (“flame”) other users, particularly in newsgroups discussing perennially controversial topics such as abortion.  When a significant number of postings in a newsgroup are devoted to flaming and counter-flaming, many users who had sought civilized, intelligent discussion leave in protest. In 1984, Chuq von Rospach wrote a document entitled “A Primer on How to Work with the Usenet Community. ” It and later guides to net etiquette or “netiquette” offered useful guidelines to new users and to more experienced users who wanted to facilitate civil discourse. ",0,Human
3,"These suggestions include:, Learn about the purpose of a newsgroup before you post to it.  If a group is moderated, understand the moderator’s guidelines so your postings won’t be rejected. , Before posting, follow some discussions to see what sort of language, tone, and attitude seems to be appropriate for this group Do not post bulky graphics or other attachments unless the group is designed for them. , Avoid “ad hominem” (to the person) attacks when discussing disagreements. , Do not post in ALL CAPS, which is interpreted as “shouting. ”, Check your postings for proper spelling and grammar.  On the other hand, avoid “flaming” other users for their spelling or grammar errors. , When replying to an existing message, include enough of the original message to provide context for your reply, but no more. , If you know the answer to a question or problem raised by another user, send it to that user by e-mail.  That way the newsgroup doesn’t get cluttered up with dozens of versions of the same information. ",0,Human
4,"In recent years there has been growing concern that Internet users may eventually be treated differently by service providers depending on the kind of data they download or the kind of application programs they use online.  Advocates of network (or net) neutrality , want legislation that would bar cable, DSL, or other providers , from making such distinctions, such as by charging content providers higher fees for high volumes of data or even blocking certain applications.  Advocates of net neutrality believe that, since there are rather limited choices for broadband Internet service, discrimination on the basis of Web content could lead to a loss of freedom for consumers and providers alike",0,Human
5,"By the late 1970s, researchers at many major universities were using the UNIX operating system ,.  In 1979, a suite of utilities called UUCP was distributed with the widely used UNIX Version 7.  These utilities could be used to transfer files between UNIX computers that were linked by some form of telephone or network connection. Two Duke University graduate students, Tom Truscott and Jim Ellis, decided to set up a way in which users on different computers could share a collection of files containing text messages on various topics.  They wrote a simple set of shell scripts that could be used for distributing and viewing these message files.  The first version of the news network linked computers at Duke and at the University of North Carolina.  Soon these programs were revised and rewritten in the C language and distributed to other UNIX users as the “A” release of the News software. During the 1980s, the news system was expanded and features such as moderated newsgroups were added.  As the Internet and its TCP/IP protocol , became a more widespread standard for connecting computers, a version of News using the NNTP (Network News Transmission Protocol) over the Internet was released in 1986.  Netnews is a mature system today, with news reading software available for virtually every type of computer",0,Human
6,"Netnews postings are simply text files that begin with a set of standard headers, similar to those used in e-mail.  (Like e-mail, news postings can have binary graphics or program files attached, using a standard called MIME, for Multipurpose Internet Mail Extensions. )The files are stored on news servers—machines that have the spare capacity to handle the hundreds of gigabytes of messages now posted each week.  The files are stored in a typical hierarchical UNIX fashion, grouped into approximately 75,000 different newsgroups. As shown in the following table, the newsgroups are broken down into 10 major categories.  The names of individual groups begin with the major category and then specify subdivisions.  For example, the newsgroup comp. sys. ibm. pc deals with IBM PC-compatible personal computers, while comp. os. linux deals with the Linux operating system. ",0,Human
7,"The servers are linked into a branching distribution system.  Messages being posted by users are forwarded to the nearest major regional “node” site, which in turn distributes them to other major nodes.  In turn, when messages arrive at a major node from another region, they are distributed to all the smaller sites that share the newsfeed.  Due to the volume of groups and messages, many sites now choose to receive only a subset of the total newsfeed.  Sites also determine when messages will expire (and thus be removed from the site). There are dozens of different news reading programs that can be used to view the available newsgroups and postings.  On UNIX systems, programs such as elm and tin are popular, while other newsreaders cater to Windows, Macintosh, and other systems.  Major Web browsers such as Netscape and Internet Explorer offer simplified news reading features.  To use these news readers, the user accesses a newsfeed at an address provided by the Internet Service Provider (ISP).  There are also services that let users simply navigate through the news system by following the links on a Web page.  The former service called DejaNews, now Google Groups, is the best-known and most complete such site",0,Human
8,"In the 1940s, the main objective in developing the first digital computers was to speed up the process of calculation.  In the 1950s, the machines began to be used for more general data-processing tasks by governments and business.  By the 1960s, computers were in use in most major academic, government, and business organizations.  The desire for users to share data and to communicate both within and outside their organization led to efforts to link computers together into networks. Computer manufacturers began to develop proprietary networking software to link their computers, but they were limited to a particular kind of computer, such as a DEC PDP minicomputer, or an IBM mainframe.  However, the U. S.  Defense Department, seeing the need for a robust, decentralized network that could maintain links between their computers under wartime conditions, funded the development of a protocol that, given appropriate hardware to bridge the gap, could link these disparate networks ,. ",0,Human
9,"According to the OSI (open systems interconnection) model, a network can be considered to be a series of seven layers laid one atop another ,. The physical layer is at the bottom.  It specifies the physical connections between the computers, which can be anything from ordinary phone lines to cable, fiber optic, or wireless.  This layer specifies the required electrical characteristics (such as voltage changes and durations that constitute the physical signal that is recognized as either a 1 or 0 in the “bit stream. ”The next layer, called the data link layer, specifies how data will be grouped into chunks of bits (frames or packets) and how transmission errors will be dealt with ,. The network layer groups the data frames as parts of a properly formed data packet and routes that packet from the sending node to the specified destination node.  A variety of routing algorithms can be used to determine the most efficient route given current traffic or line conditions. The transport layer views the packets as part of a complete transmission of an object (such as a Web page) and ensures that all the packets belonging to that object are sorted into their original sequence at the destination.  This is necessary because packets belonging to the same message may be sent via different routes in keeping with traffic or line conditions. The session layer provides application programs communicating over the network with the ability to initiate, terminate, or restart an interrupted data transfer. The presentation layer ensures that data formats are consistent so that all applications know what to expect.  This layer can also provide special services ,. Finally, the application layer gives applications highlevel commands for performing tasks over the network, such as file transfer protocol (ftp)",0,Human
10,"A network attached storage (NAS) unit can be thought of as a dedicated data storage unit that is available to all users of a network.  Unlike a traditional dedicated file storage unit ,, a NAS unit typically has an operating system and software designed specifically (and only) for providing data storage services.  The actual storage is usually provided by an array of hard drives ,.  Files on the NAS are accessed through protocols such as SMB (server message block), common on Windows networks, and NFS (network file system), used on many UNIX and some Linux networks.  In recent years smaller, lower-cost NAS devices have become available for smaller networks, including home networks, where they can store music, video, and other files ,",0,Human
11,"Although it sounds similar, a storage area network (SAN) does not function as its own file server.  Rather, it attaches storage modules such as hard drives or tape libraries to an existing server so that it appears to the server’s operating system as though it were locally attached.  Typically the protocol used to attach the storage is SCSI ,, but the physical connection is fiber or high-speed Ethernet.  The emphasis for SAN applications is the need for fast access to data, such as in large online databases, e-mail servers, and high-volume file servers.  SANs offer great flexibility, since storage can be expanded without changing the network structure, and a replacement server can quickly be attached to the storage in case of hardware failure",0,Human
12,"In the kind of science fiction sometimes called “cyberpunk,”people are able to “jack in” or connect their brains directly tocomputer networks.  Because of this direct input into the brain(or perhaps the optic and other sensory nerves), a personwho is jacked in experiences the virtual world as fully real,and can (depending on the world’s rules) manipulate it withhis or her mind.  This kind of all-immersive virtual reality isstill science fiction, but today people are beginning to controlcomputers and artificial limbs directly with their minds. ",0,Human
13,"Neuroprosthetics is the creation of artificial limbs or sensoryorgans that are directly connected to the nervous system. The first (and most widely used) example is the cochlearimplant, which can restore hearing by taking sound signals from a microphone and converting them to electricalimpulses that directly stimulate auditory nerves within thecochlea, a part of the inner ear.  Similarly, experimental retinal implants that stimulate optic nerves are beginning tooffer crude but useful vision to certain blind patients. Research in connecting the brain to artificial arms orlegs is still in its early stages, but scientists using microelectrode arrays have been able to record signals from thebrain’s neurons and correlate them to different types ofmotor movements.  In a series of experiments at Duke University, researchers first trained a monkey to operate a joystick to move a shape in a video game.  They then recordedand analyzed the signals produced by the monkey’s brainwhile playing the game, and correlated them with themotor movements in the joystick.  Next, they replicatedthese movements with a robotic arm as the monkey movedthe joystick.  Finally, they were able to train the monkey tomove the robotic arm without using the joystick at all, simply by “thinking” about the movements. ",0,Human
14,"As more is learned about the detailed functioning of neuronal networks inside the brain, “cognitive prosthetics” maybecome feasible.  One example might be computer memory modules that might act as a surrogate or extension ofhuman memory, perhaps helping compensate for loss ofmemory due to age or disease.  (Early experiments on interfacing to the hippocampus, a part of the brain important forforming memories, have been underway since 2003. )Other possibilities might include processors that couldgive a person the ability to think about a mathematicalproblem and “see” the answer, or to search databases or theWeb simply by visualizing or thinking about the information desired",0,Human
15,"Integers (whole numbers) have the simplest representation, but there are two important considerations: the totalnumber of bits available and whether one bit is used to holdthe sign. Since all numbers are stored as binary digits, an unsignedinteger has a range from 0 to 2bits where “bits” is the totalnumber of bits available.  Thus if there are 16 bits available, the maximum value for an integer is 65535.  If negativenumbers are to be handled, a signed integer must be used(in most languages such as C, C++, and Java, an integer issigned unless unsigned is specified).  Since one bit is usedto hold the sign and each bit doubles the maximum size, itfollows that a signed integer can have only half the rangeabove or below zero.  Thus, a 16-bit signed integer can rangefrom -32,768 to 32,767. One complication is that the available sizes of integersdepend on whether the computer system’s native data sizeis 16, 32, or 64 bits.  In most cases the native size is 32 bits,so the declaration “int” in a C program on such a machineimplies a signed 32-bit integer that can range from - 231 or-2,147,483,647 to 231-1, or 2,147,483,647.  However, if one isusing large numbers in a program, it is important to checkthat the chosen type is large enough.  The long specifier isoften used to indicate an integer twice the normal size, or64 bits in this case. ",0,Human
16,"Numbers with a fractional (decimal) part are usually storedin a format called floating point.  The “floating” means thatthe location of the decimal point can be moved as necessaryto fit the number within the specified digit range.  A floatingpoint number is actually stored in four separate parts.  Firstcomes the sign, indicating whether the number is negativeor positive.  Next comes the mantissa, which contains theactual digits of the number, both before and after the decimal point.  The radix is the “base” for the number systemused.  Finally, the exponent determines where the decimalpoint will be placed. For example, the base 10 number 247. 35 could be represented as 24735 × 10-2.  The -2 moves the decimal pointat the end two places to the left.  However, floating-pointnumbers are normalized to a form in which there is just onedigit to the left of the decimal point.  Thus, 247. 35 wouldactually be written 2. 4735 × 102.  This system is also knownas scientific notation. As noted earlier, actual data storage in modern computers is always in binary, but the same principle applies. According to IEEE Standard 754, 32-bit floating-point numbers use 1 bit for the sign, 8 bits for the exponent, and 23bits for the mantissa (also called the significand, since itexpressed the digits that are significant—that is, guaranteed not to be “lost” through overflow or underflow in processing).  The double precision float, declared as a “double”in C programs, uses 1, 11, and 52 bits respectively. ",0,Human
17,"Many objects are more elaborate or specialized variations ofmore basic objects.  For example, in Microsoft Windows thevarious kinds of dialog boxes are specialized versions of thegeneral Window class.  Therefore, the specialized versionis created by declaring it to be derived from a “base class. ”Put another way, the specialized class inherits the basicdata and functions available in the base (parent) class.  Theprogrammer can then add new data or functions or modifythe inherited ones to create the necessary behavior for thespecialized class. Languages such as C++ allow for a class to be derivedfrom more than one base class.  This is called multipleinheritance.  For example, a Message Window class mightinherit its overall structure from the Window class andits text-display capabilities from the Message class.  However, it can sometimes be difficult to keep the relationshipsbetween multiple classes clear.  The Java language takes thealternative approach of being limited to only single inheritance of classes, but allowing interfaces (specifications ofhow a class interacts with the program) to be multiplyinherited. ",0,Human
18,"Different kinds of objects often have analogous methods. For example, suppose there is a series of classes that represent various polygons: square, triangle, hexagon, and so forth.  Each class has a method called “perimeter” thatreturns the total distance around the edges of the object.  Ifeach of these classes is derived from a base polygon class,each class inherits the base class’s perimeter method andadapts it for its own use.  Thus, a square might calculateits perimeter simply by multiplying the length of a side byfour, while the rectangle would have to add up differentsized pairs of sides, and so on. ",0,Human
19,"In the late 1990s “banner ads” started to appear on Websites, and other forms of advertising soon followed.  Companies rushed into the online world, either with the belief thatit had unlimited potential for finding new customers, or outof fear that the competition would get there first.  Unfortunately it was hard to measure the actual effectiveness ofads, and Web sites (such as for publications) that lookedto third-party advertising as a source of income found theoutlook bleak in the wake of the bursting of the “dot-combubble” of the early 2000 decade. Only a few years later, however, advertisers using newbusiness models and targeting techniques have made onlineadvertising not only a viable business, but a rapidly growing one.  (According to the Interactive Advertsing Bureau,Internet advertising revenue in the United States in 2007was $21. 2 billion, up 26 percent from 2005. )The effects of the online advertising revolution are rippling outward, impacting traditional advertising mediasuch as newspapers (in particular see craigslist), magazines, and even television. ",0,Human
20,"Types of ads include the following:, Banner ads are contained in rectangles, often at the topof the Web page.  (Sometimes they can mimic dialogboxes from the operating system. ) They still accountfor about half of all online advertising, and can appearon sites of all types. , Pop-up or pop-under ads appear above or beneath thecurrent window, respectivelyFloating ads appear over the main page content, oftenmoving across the screen. , Interstitial ads are displayed before the requestedcontent (such as an article or video) is shown.  Theyrun for a specified period of time, although they cansometimes be closed by the viewer. Many ads are animated; some even contain video clips. There are also ads formatted for mobile devices, includingtext messages sent to cell phones. ",0,Human
21,"Google and other large search enginesor portals can make money from advertisers is through“affiliate marketing”; Google’s version is called Ad Sense. Participating Web sites are indexed, and the resulting keywords are matched with ads awaiting placement.  The sitecarrying the ad generally gets a per-click payment.  However, the problem of “click fraud” has also arisen: Scammerscan set up an affiliate site and then use special software togenerate the clicks, while making them come from a varietyof sources.  Despite these problems, in 2006 about 40 percent of revenue from online advertising was attributed tosearch-related ads. ",0,Human
22,"The dark side of online advertising is found in programsthat are surreptitiously installed on users’ PCs and thendownload and display advertising from shady Web operations ,.  While many users nowregularly run programs to block such malware, even legitimate online advertising can irritate users, particularlywhen ads are too prominent, float over (and block) text, orlurk behind the browser window.  Modern Web browsershave ad-blocking features that work with varying degreesof effectiveness.  As with TV, online advertisers increasinglyhave to cope with impatient users who do not have to lookat ads unless they actually want to. Advertisers can employ several strategies to keep userswilling to look at ads.  One is to make the ad unobtrusiveand brief, and on the way to something the user reallywants to see.  In 2007 YouTube began such advertising. Another is to provide free versions of software or servicesthat, in exchange for being free, require the user to put upwith some screen real estate being devoted to ads.  Finally,as with TV, advertising can be woven into the content itself,such as in online computer games. A sensitive area is the attempt to balance advertisers’desire to know as much as possible about consumers’ interestsand buying habits with the same consumers’ concern aboutprotecting their privacy",0,Human
23,"A variety of other frauds and scams appear online or viae-mail with some frequency:, the “419” or “Nigerian money letter” that promises arich cut for helping facilitate a money transfer for adistressed official, fraudulent charitable solicitations, particularly aftersuch disasters as the Asian tsunami or HurricaneKatrina, adoption and marriage scams, educational fraud, such as worthless degrees offeredby unaccredited institutions, dubious employment schemes or “home businesses”involving preparing mailings or medical billing, services that offer to “repair” bad credit ratings, tax-avoidance schemes, often based on nonexistentlegal claims or loopholes",0,Human
24,"Online casinos appeared in 1995, but at first they couldonly be played “for fun,” with no actual money changinghands.  That soon changed: In 1996, InterCasino appeared—it would be the first of hundreds of online casinos, sportsbookmakers, and other types of gambling.  Generally theseoperations are based outside of the United States—Caribbean islands such as Antigua and Curaçao are popular locations. Online casinos offer traditional table games such asblackjack, roulette, and craps.  Generally odds and payoffsare comparable to those at traditional casinos.  Assumingthe game is honest and properly programmed, the house’srevenue comes from a percentage of the amount bet—blackjack having the lowest house percentage and roulette thegreatest.  Slot machines (which give an even higher percentage to the house) can also be simulated online. ",0,Human
25,"Online poker has become very popular, particularly gamessuch as Texas Hold’Em.  Estimated revenues from onlinepoker in the United States were $2. 4 billion in 2005. Unlike the case with casino games, online poker playersplay against each other, not the house.  The house’s revenuecomes from a “rake,” or percentage, of the pot.  Many sitesoffer organized tournaments, and some online players havegone on to win traditional tournaments.  (The aptly namedChris Moneymaker won an online tournament, qualifyinghim to enter the 2004 World Series of Poker, which he wenton to win. )Like online casinos, online poker is illegal in the UnitedStates.  Proponents argue that while any given hand is random, poker in the long run is a game of skill, not chance.  Agroup called the Poker Players Alliance has been lobbyingto exempt poker from Internet gambling laws. A third type of online gambling is sports betting, whichis legal in many countries but only in Nevada in the UnitedStates.  The Web has also given sports bettors a forum fordiscussing (or arguing about) teams and their prospects. ",0,Human
26,"Online games today range from elaborate war games toopen-ended fantasy worlds to virtual universes that mirror“real-world” activities, including economics, politics, andeven education. The first online games appeared in the late 1970s onPLATO, an educational network, as well as on the earlyInternet of the 1980s.  These MUDs (multiuser dungeons)were generally based on pen-and-paper role-playing gamesof the time, notably Dungeons & Dragons.  These games were text based, with players typing their characters’ actionsand dialog while the changing world as seen by the players was similarly described.  By the early 1990s, however,MUDs had spun off many variants.  Many were still “hackn’ slash” dungeon games (which were also offered on America Online and other commercial services).  Many of theseMUD-like games such as AOL’s Neverwinter Nights offeredsimple graphics.  Meanwhile other games began to offermore sophisticated social interactions as well as the abilityof players to make their own additions to the game world,including buildings. ",0,Human
27,"Today’s online games feature a “persistent world” hosted onone or more servers that grows and develops from day to dayand in which the “avatars” or representatives of thousandsof players interact with game-generated creatures or oneanother, using client software.  Players can spend hundredsof hours helping their characters develop skills, increasingtheir levels through experience points gained from successful combat or other activities.  Players (and their characters) frequently form organizations such as guilds or clans,because the tougher challenges generally require the cooperation of different types of classes of characters (fighters,healers, and magic-users). Modern MM ORPGs began in the late 1990s with suchtitles as Ultima Online and EverQuest.  The most popularMMORPG in the mid-2000s was World of Warcraft. ",0,Human
28,"As with shoppers, investors have increasingly been attractedto the interactivity and ease of online transactions.  In addition to allowing stocks to be bought or sold with just a fewclicks, online brokers (also called discount brokers) chargemuch lower transaction fees than their traditional counterparts, typically less than $10 per trade. Some online brokers, such as E*Trade, Scottrade, andTD Ameritrade, were established as Internet brokers.  However, traditional brokerages such as Charles Schwab andWaterhouse have also opened online discount brokerages. In addition to fast, inexpensive trading, many onlinebrokers also offer a variety of resources and tools, including stock quotes and charts, research reports, and screening programs to help investors pick the mutual funds orindividual investments that meet their objectives.  For moresophisticated investors, some brokers offer simulations fortesting investment strategies and programmed trading,which will execute buy or sell orders automatically depending on specified conditions. Online brokers can specialize, seeking customers whowant to make frequent trades but do not need other support, or investors who are interested in obtaining IPOs (initial public offerings) of up-and-coming companies.  Somebrokers may emphasize mutual funds and cater to retirement accounts, while others might offer government or corporate bonds, foreign stocks, “penny stocks,” or more exoticinvestments. The interactivity and low transaction costs in onlineinvesting may encourage people to become involved inhighly speculative penny stocks, options, day trading, foreign exchange markets, and other areas that are not suitablefor most individual investors.  While there is a great dealof useful information available online, it is a good idea tobegin by discussing investment goals and potential riskswith a trusted financial adviser. ",0,Human
29,"In evaluating a job site it is important to get a feel forthe kinds of jobs offered and the target audience, such asprofessionals, recent graduates, white-collar or service sector jobs, and so on.  Other important features to look forinclude:, powerful search or filtering capability, such as by typeof job or employer, keywords in job description, orlocality, the ability to put one’s resume online and edit orupdate it as needed. , the ability to have several versions of one’s resumetailored to different types of jobs, automatic e-mail alerts about newly added jobs thatmeet the user’s criteria, privacy protections so that contact information fromresumes is not used for marketing or other nonemployment purposes, lack of fees to job seekers (normally employers are theservice’s source of revenue)",0,Human
30,"A persistent problem in artificial intelligence , is how to provide a software systemwith a model that it can use to reason about a particularsubject or domain.  A data model or ontology basically consists of classes to which the relevant objects might belong,relationships between classes, and attributes that objects inthat class can possess.  (For implementation of these ideaswithin programming languages, see classes and objectoriented programming. )For example, a business ontology might include classessuch as:, Entity—a business or person, Supplier—an Entity that provides wholesale goods orservices, Customer—an Entity that buys the company’s goodsor services, Contractor—an Entity that performs work for thecompany on contract",0,Human
31,"Ontologies can be used to provide guidance to a variety oftypes of programs (for example, see expert system, natural language processing, and software agent).  Thusif an automatic news summarizer program encounters astory that includes references to opposing lawyers and legalissues, it could apply an ontology that defines the likelyrelationship of the participants in the case. Creating useful ontologies is quite labor intensive interms of the human thinking and coding involved.  However, there have been substantial efforts in recent years tocreate anthologies for many fields, particularly in biologyand genetics.  The Web Ontology Language (OWL) is apopular tool for creating ontologies that can be used tomake Web content more understandable to programs ,. Meanwhile, an ambitious and long-running projectcalled Cyc (for Encyclopedia) under the direction of Douglas Lenat has been engaged in creating what amounts tovast ontologies for many of the domains included in everyday human life as well as specialized fields of knowledge.  Alarge portion of this work has been made available as opensource. ",0,Human
32,"According to Stallman and many other advocates, “opensource” software is not necessarily free.  What is requiredis that users receive the full source code (or have it readilyavailable for free or at nominal charge).  Users are free tomodify or expand the source code to create and distributenew versions of the software.  Following a legal mechanismthat Stallman calls “copyleft,” the distributor of opensource software must allow subsequent recipients the samefreedom to revise and redistribute.  However, not all software that is billed as open source follows all of Stallman’srequirements, including being copylefted.  Formally, opensource software is generally licensed according to variousversions of the General Public License (GPL).  The latestversion, GPL3, released in 2007, has been controversial. Among other things, it more aggressively attempts to prevent open-source software from being restricted or otherwise hampered by being combined with patented softwareor proprietary hardware. ",0,Human
33,"An operating system is an overarching program that manages the resources of the computer.  It runs programs andprovides them with access to memory (RAM), input/outputdevices, a file system, and other services.  It provides application programmers with a way to invoke system services, andgives users a way to control programs and organize files. The “core” functions include “booting” the system and initializing devices, process management(loading programs intro memory assigning them a share ofprocessing time), and allowing processes to communicatewith the operating system or one another ,. Multiprogramming systems often implement not only processes (running programs) but also threads, or sections ofcode within programs that can be controlled separately. A memory management scheme is used to organize andaddress memory, handle requests to allocate memory, freeup memory no longer being used, and rearrange memory tomaximize the useful amount ,. There is also a scheme for organizing data created orused by programs into files of various types ,.  Mostoperating systems today have a hierarchical file system thatallows for files to be organized into directories or foldersthat can be further subdivided if necessary",0,Human
34,"Designers of modern operating systems face a numberof continuing challenges:, security, in a world where nearly all computers arenetworked, often continuously ,, the tradeoff between powerful, attractive functionssuch as scripting and the security vulnerabilities theytend to present, the need to provide support for new applications suchas streaming audio and video ,, ease of use in installing new devices ,The continuing development of new user-interfaceconcepts, including alternative interfaces for the disabled and for special applications ,, the growing use of multiprocessing and multiprogramming, requiring coordination of processors sharingmemory and communicating with one another ,, distributed systems where server programs, clientprograms, and data objects can be allocated amongmany networked computers, and allocations continually adjusted or balanced to reflect demand on thesystem ,, the spread of portable, mobile, and handheld computers and computers embedded in devices such asengine control systems ,.  (Sometimes the choice isbetween devising a scaled-down version of an existing operating system and designing a new OS that isoptimized for devices that may have limited memoryand storage capacity. )",0,Human
35,"Generally speaking, the levels of precedence for mostlanguages are as follows:1.  scope resolution operators (specify local v.  globalversions of a variable)2.  invoking a method from a class, array subscript,function call, increment or decrement3.  size of (gets number of bytes in an object), addressand pointer dereference, other unary operators(such as “not” and complement); creation and deallocation functions; type casts 4.  class member selection through a pointer5.  multiplication, division, and modulus6.  addition and subtraction7.  left and right shift operators8.  less than and greater than9.  equal and not equal operators10.  bitwise operators (AND, then exclusive OR, inclusive OR)11.  logical operators (AND, then OR)12.  assignment statements",0,Human
36,"Today it is easy to optically scan text or graphics printed onpages and convert it into a graphical representation for storage in the computer ,.  However, a shape suchas a letter c doesn’t mean anything in particular as a graphic. Optical character recognition (OCR) is the process of identifying the letter or other document element that correspondsto a given part of the scanned image and converting it tothe appropriate character ,.  Ifthe process is successful, the result is a text document thatcan be manipulated in a word processor, database, or otherprogram that handles text.  Raymond Kurzweil (1948– )marketed the first commercially practicable general-purposeoptical character recognition system in 1978. ",0,Human
37,"Once the document page has been scanned into an imageformat, there are various ways to identify the characters. One method is to use stored templates that indicate the pattern of pixels that should correspond to each character.  Generally, a threshold of similarity is defined so that an exactmatch is not necessary to classify a character: The templatemost similar to the character is chosen.  Some systems storea set of templates for each of the fonts most commonly foundin printed text.  (Recognizing cursive writing is a much morecomplex process: See handwriting recognition. )A more generalized method uses structural features(such as “all t’s have a single vertical line and a shortercrossbar line”) to classify characters.  To analyze a character,the different types of individual features are identified andthen compared to a set of rules to determine the charactercorresponding to that particular combination of features. Sometimes thresholds or “fuzzy logic” are used to decidethe probable identity of a character. ",0,Human
38,"Jaguar, panther, tiger, and leopard—these and other namesof sleek big cats represent versions of Apple’s Macintoshoperating system, OS X (pronounced “OS 10”—see AppleCorporation and Macintosh).  Unlike the previous MacOS, OS X, while broadly maintaining Apple’s user interfacestyle ,, is based on a version of UNIXcalled OpenStep, developed by NeXT starting in the 1980s,.  OS X development began when Steve Jobsreturned as Apple CEO in 1997 ,and the company bought NeXT, acquiring the software.  Thefirst version, OS X 10. 0, or Cheetah, was released in 2001,but the system was not widely used until 10. 1 (Puma) wasreleased later the same year. At the core of OS X is a free and open-source version ofUNIX called “Darwin,” with a kernel called XNU.  On top ofthis Apple built a distinctive and subtly colorful user interface called Aqua and a new version of the Macintosh Finderfile and program management system",0,Human
39,"Today OS X includes a variety of useful software packages—some free and some optional.  These include iLife (digitalmedia management), iWork (productivity), and Front Row(home media center).  OS X10. 5 also includes Time Machine,an automatic backup system that can restore files (includingdeleted files) as well as earlier system settings. For software developers, OS X provides an integrateddevelopment environment called “Xcode,” which workswith modified open-source compilers for major programming languages, including C, C++, and Java.  Further,because OS X is UNIX-based, many UNIX and Linux programs can be recompiled to run on it.  Since mid-2005 Apple(and OS X) have been transitioning from the earlier IBM/Motorola processors to Intel processors.  This transition waslargely complete by 2007, though OS X 10. 5 (Leopard) stillprovides support for applications written for the PowerPC. OS X has been well received by critics, and together withits bundled software has made the Macintosh a popularplatform for users who want a seamless computing experience, particularly with regard to graphics and media. ",0,Human
40," With a parallel connection, however, the eight bitsof the byte are sent simultaneously, each along its own wire,so parallel ports are generally faster than serial ports.  Also,since the data is transmitted simultaneously, the protocolfor marking the beginning and end of each data byte is simpler.  On the other hand, parallel cables are more expensive(since they contain more wires) and are generally limitedto a length of 10 feet or so because of electrical interferencebetween the parallel wires. The original parallel interface for personal computerswas designed by Centronics, and a later version of this 36-pin connector remains popular today.  Later, IBM designed a25-pin version.  In addition to the wires carrying data, additional wires are used to carry control signals",0,Human
41,"After many years of effort researchers have been able tocreate systems that can recognize particular human faces,.  On the other hand, any normalsix-month-old child can effortlessly recognize familiarfaces (such as parents).  The fundamental task of turningraw data (whether from senses, instruments, or computerfiles) into recognizable objects or drawing inferences iscalled pattern recognition.  Pattern recognition is at theheart of many areas of research and application in computing ,. Despite the challenge in getting machines to do what comes naturally for biological organisms, the potentialpayoffs are immense. A pattern-recognition system begins with data, whetherstored or real-time (such as from a robot’s camera).  The firsttask in turning potentially billions of bytes of data intomeaningful objects is to extract features from what is likelya high proportion of redundant or irrelevant data.  (Withvisual images, this often involves finding edges that defineshapes. ) The extracted features are then classified to determine what objects they might represent.  This can be doneby comparing structures to templates or previously classified data or by applying statistical analysis to determine thelikely correlation of the new data to existing patterns ,. Pattern recognition often includes learning algorithmsas well; indeed, the field is often considered to be a subtopicof machine learning.  For example, classification systemscan be refined by “training” them and reinforcing successful determinations ,. ",0,Human
42,"The first stage in making computing available away fromthe office desk was the development of “portable” and thenlaptop computers in the 1980s ,. Laptops, however, are relatively heavy and bulky, and thusnot suitable for activities such as making notes at meetings or keeping track of appointments while on the go. The logical solution to that need was to develop a computer small enough to carry in a pocket or purse.  The firsthandheld computer to achieve widespread recognition wasApple’s Newton, which the company referred to as a “personal digital assistant. ” This term, usually abbreviated toPDA, became a generic category with the introduction ofthe Palm Pilot, which first appeared in 1996, followed bythe seemingly ubiquitous RIM Blackberry in 1999. ",0,Human
43,"The PDF specifications are open source, so anyone canwrite software to create or read documents in the format. PDF includes three elements: a subset of the PostScript pagedescription language ,, a system for specifying and embedding common fonts (or referring to otherfonts), and a system for “packaging” the text and graphicsdescriptions into a file in compressed form.  Later versionsof the PDF specification also allow users to interact withthe document, such as by filling in fields in a form or adding annotations to the text.  PDF also includes support fortags , and descriptors that can be used with programs such as screen readers for the blind. PDF also includes support for encrypting documents sothey can only be read with a password, and for controllingwhether the document can be copied or printed, though thisdepends on the user’s software understanding and obeyingthe restrictions. Although creating and editing PDF documents originally required the relatively expensive Adobe Acrobat software, there are now a number of free or low-cost editorsand other PDF utilities for Windows, Mac OS X, and Linux/UNIX platforms. ",0,Human
44,"The explosive growth of the World Wide Web has confronted programmers with the need to find ways to link databases and other existing resources to Web sites.  The specifications for such linkages are found in the Common Gateway Interface ,.  However, the early facilities for writing CGI scripts were awkward and often frustrating to use. Back in 1986, UNIX developer Larry Wall had created a language called Perl (Practical Extraction and Report Language).  There were already ways to write scripts for simple data processing , as well as a handy pattern-manipulation language ,.  However, Wall wanted to provide a greater variety of functions and techniques for finding, extracting, and formatting data.  Perl attracted a following within the UNIX community.  Since much Web development was being done on UNIX-based systems by the mid- and late-1990s, it was natural that many webmasters and applications programmers would turn to Perl to write their CGI scripts. As with many UNIX scripting languages, Perl’s syntax is broadly similar to C.  However, the philosophy behind C is to provide a sparse core language with most functionality being handled by standard or add-in program libraries.  Perl, on the other hand, starts with most of the functionality of UNIX utilities such as sed (stream editor), C shell, and awk, including the powerful regular expressions familiar to UNIX users.  The language also includes a “hash” data type (a collection of paired keys and values) that makes it easy for a program to maintain and check lists such as of Internet hosts and their IP addresses ,. ",0,Human
45,"In today’s health care environment patients often have only a few minutes to ask their doctor important questions about their condition and possible treatments.  Patients often feel they have been left on their own when it comes to obtaining detailed information.  According to surveys by the Pew Internet & American Life Project, by the end of 2005 about 20 percent of Web users were reporting that the Internet “has greatly improved the way they get information about health care. ” Further, 7 million users had reported that Web sites had “played a crucial or important role in coping with a major illness. ”A variety of Web sites ranging from comprehensive and excellent to dubious (at best) offer health-related information.  In evaluating them, it is important to determine who sponsors the site and what is the source of the information provided.  The very extensive WebMD site, for example, is reviewed for accuracy by an independent panel of experts.  One of the foremost medical institutions, the Mayo Clinic, also has an authoritative site.  The site OrganizedWisdom. com offers a search engine that emphasizes information that has been reviewed by doctors for accuracy, while eliminating low-quality or duplicative results. Even if information is accurate, however, users may often lack the necessary background or context for interpreting it correctly.  Understanding the results of medical studies, for example, requires some knowledge of how studies are designed, the population used, and the statistical significance and applicability of the results.  As a practical matter, therefore, patients should not make any major decisions about diet, medication, or treatment options without consulting a medical professional.  Attempts at self-diagnosis can be particularly prob",0,Human
46,"When modern digital computing emerged in the 1940s, it evolved from two roots: engineering (particularly electrical engineering) and mathematics.  The goals of the earliest computer designers were focused naturally enough on computing, although several early thinkers , had already begun to think of computers as symbol-processing and knowledgeretrieving machines, not just number crunchers. As computer scientists began to become more concerned about the structure of data and the modeling of real-world objects in computer languages ,, they began to wrestle with some areas long familiar to philosophers.  As data structure involved into knowledge representations, epistemology (the philosophical investigation of the meaning and accessibility of knowledge) became more relevant, particularly in developing systems for artificial intelligence and machine learning.  Also relevant is ontology (the nature and relationship of entities—see ontologies and data models), particularly with regard to the modern effort to encode relationships between items of knowledge into Web pages ,",0,Human
47,"Just about anyone with an e-mail account has received messages purporting to be from a bank, a popular e-commerce site such as Amazon or eBay, or even a government agency.  Typically the message warns of a problem (such as a suspended account) and urges the recipient to click on a link in the message.  If the user does so, what appears to look like the actual site of the relevant institution is actually a “spoof,” or fake site.  If the user goes on to enter information such as account numbers or passwords in order to fix the “problem,” the information actually goes to the operator of the fake site, where it can be used for fraudulent purchases or even impersonation ,.  The bogus site can also attempt to download viruses, spyware, keyloggers, or other forms of “malware” to the unwitting user’s computerThis all-too-common scenario is called “phishing,” alluding to “fishing” for unwary users with various sorts of bait, with the f changed to ph in keeping with traditional hacker practice.  Phishing is similar to other techniques for manipulating people through deception, fear, or greed that hackers often refer to as “social engineering. ” Unlike oneon-one approaches, however, phishing relies on the ability to send large quantities of e-mail at virtually no cost ,, the availability of simple techniques for disguising both e-mail addresses and Web addresses (URLs), and the ease with which the appearance of a Web site can be convincingly replicated. Although e-mail is the most common “hook” for phishing, any form of communication, including text or instant messages, can be used.  Recently sites such as MySpace have become targets for automated phishing expeditions that changed links on pages to point to fraudulent sites ",0,Human
48,"Wary users have a number of ways to reduce their chance of being “phished. ” Some signs of bogus messages include:, The message is addressed generically (“dear PayPal user”) or to the user’s e-mail address rather than the account name. , The text of the message contains spelling errors or poor grammar. , The URL shown for a link in the message (perhaps via a “tool tip”) does not match the institution’s real Web address. Fortunately there are ways in which software can help detect and block most phishing attempts.  A good spam filter is the first line of defense and can block many phishing messages from getting to the user in the first place.  Anti-phishing features are also increasingly included in Web browsers, or available as plug-ins.  Thus “blacklists” of known phishing sites can be checked in real time and warnings given, or the site’s address can be blocked from access by the system.  Web sites can also introduce an added layer of security: Bank of America, for example, asks users to select and label one of several images offered by the bank.  The image and label are subsequent displayed as part of the log-in process.  If the user does not see the image and the user’s label, then the site is presumably not the real bank site",0,Human
49,"The PHP processor parses only the code within the delimiters <? and ?>.  (An alternative set of delimiters is <script language =‘php’> </script>. Besides being embedded in HTML pages, PHP can be used interactively at the command line, where it has replaced older languages such as awk, Perl, or shell scripting for many users.  PHP can also be linked to user-interface libraries (such as GTK+ for Linux/UNIX) to create applications that run on the client machine rather than the server. PHP has a basic set of data types plus one called “resource” that represents data processed by special functions that return images, text files, database records, and so on.  Additionally, PHP5 provides full support for objects, including private and protected member variables, constructors and destructors, and other features similar to those found in C++ and other languages. There are numerous libraries of open-source objects and functions that enable PHP scripts to perform common Internet tasks, including accessing database servers (such as MySQL) as well as extensions to the language to handle popular Web formats such as Adobe Flash animation.  Programmers have access to a wide range of PHP resources through PEAR (the PHP Extension and Application Repository). The combination of sophisticated features and easy interactive scripting has made PHP the language of choice for many Web developers, who use it as part of the group of technologies called LAMP, for Linux, Apache (Web server), MySQL (database), and PHP. ",0,Human
50,"Because of its many practical features and its availability for the popular IBM 360 mainframes, PL/I enjoyed considerable success in the late 1960s and 1970s.  The language was later ported to most major platforms and operating systems.  When personal computers came along, PL/I became available for IBM’s OS/2 operating system as well as for Microsoft’s DOS and Windows, although the language never really caught on in those environments. Computer scientists such as structured programming guru Edsger Dijkstra decried PL/I’s lack of a clear, welldefined structure.  In his Turing Award Lecture in 1972, Dijkstra opined that “I absolutely fail to see how we can keep our growing programs firmly within our intellectual grip when by its sheer baroqueness the programming language—our basic tool, mind you!—already escapes our intellectual control. ” (See Dijkstra, Edsger. )On a practical level the sheer number of features in the language meant that truly mastering it was a lengthy process.  A language like C, on the other hand, had a much simpler “core” to master even though it was less versatile.  PL/I also tended to retain the mainframe associations from its birth at IBM, while C grew up in the world of minicomputers and the UNIX community and proved more suitable for PCs.  Nevertheless, PL/I provided many examples that language designers could use in attempting to design better implementations. ",0,Human
51,"By the mid-1990s, Intel was promoting a standard for the automated detection and configuration of devices.  Known as Plug and Play (PnP), this standard was incorporated in versions of Microsoft Windows starting with Windows 95 ,.  The required hardware support soon appeared on PC motherboards and expansion cards. With Plug and Play the user simply connects a printer, scanner, or other device to the PC.  Windows detects that a device has been connected and queries it for its official name and other information.  If necessary, Windows can then prompt the user for a disk containing the appropriate driver or even search for a driver on a Web site. The concept of Plug and Play extends beyond the Windows world, however.  In recent years there has been interest in developing a Universal Plug and Play (UPnP) protocol by which a variety of devices could automatically configure themselves with any of a variety of different networks.  This would be particularly helpful for home users who are increasingly setting up small networks so they can share broadband Internet connections, as well as the growing number of users who want their desktop PC to work with handheld (palm) computers and other devices.  Microsoft supports UPnP in versions of Windows starting with ME and XP. ",0,Human
52,"A number of applications programs include the ability for third-party developers to write small programs that extend the main program’s functionality.  For example, thousands of “filters” (algorithms for transforming images) have been written for Adobe Photoshop.  These small programs are called plug-ins because they are designed to connect to the main program and provide their service whenever it is desired or required. Perhaps the most commonly encountered plug-ins are those available for Web browsers such as Firefox, Netscape, or Internet Explorer.  Plug-ins can enable the browser to display new types of files (such as multimedia).  Many standard programs for particular kinds of files are now provided both as stand-alone applications and as browser plug-ins.  Examples include Adobe (PDF document format), Apple QuickTime (graphics, video, and animation), RealPlayer (streaming video and audio), and Macromedia Flash (interactive animation and presentation).  These and many other plug-ins are offered free for the downloading, in order to increase the number of potential users for the formats and thus the market for the development packages. One of the most useful plug-ins found in most browsers is one that allows the browser to run Java applets ,.  In turn, Java is often used to write other plug-ins. Beyond such traditional workhorses, a number of innovative browser plug-ins have appeared, particularly for the increasingly popular Firefox browser.  For example, there are plug-ins that enable the user to view and work with the HTML and other elements of the page being viewed.  Another popular area is plug-ins that make it easier to capture and organize material from Web pages, going well beyond the standard favorites or bookmark facility. ",0,Human
53,"Podcasting (from iPod plus broadcasting) lets users subscribe to and automatically download regularly distributed content (such as radio broadcasts) over the Internet.  The media files can be stored on an Apple iPod or other media player ,, personal computer, or other device ,.  Podcasting became popular starting around 2004–05 and has become widely used by individuals and organizations. Typically, files to be podcast are put on a Web server.  The URLs for the files and other information (such as episode titles) is provided in files called feeds, using a format such as RSS or Atom ,.  The user installs client software (such as iPodder), browses the feeds (such as through an online directory), and decides what to subscribe to.  The software then periodically checks the feeds, obtains the URLs of the latest files, and downloads them automatically.  The software can, if desired, then transfer the downloaded files to a portable media player, such as over a USB connection",0,Human
54,"There are many sources of podcasts.  News organizations can provide regular audio or video podcasts as a supplement to regular text material.  Podcasting also offers a way for a small news organization or independent journalist to build an audience using equipment as simple as a microphone and perhaps a video camera.  Podcasts also provide a way for political organizations to keep in touch with supporters (and perhaps supply them with talking points).  Any source of periodically distributed audio or video can be a candidate for podcasting.  These include class lectures, corporate communications, and even religious services",0,Human
55,"Early computer printers were limited to one or a few built-in fonts, either stamped on typewriter style keys on daisy wheels, or stored as patterns in the printer’s software (with dot matrix printers).  In the mid-1970s, when Xerox researchers were developing the laser printer, they realized they needed an actual programming language that could describe fonts, graphics, and other elements that could be printed on the more versatile new printers.  PARC researchers developed InterPress; meanwhile two of them, John Warnock and Chuck Geschke, founded their own company in 1982 ,.  They then created a more streamlined version of InterPress that they called PostScript.  The first printer to include built-in PostScript capability was Apple’s LaserWriter, in 1985.  PostScript soon became the standard for a burgeoning industry ,. Because PostScript is an actual programming language (for a somewhat similar language, see Forth), software such as word processors can include functions that turn a text document into a PostScript document, ready for printing.  A PostScript interpreter in the printer (or even in another application) interprets the PostScript commands to re-create the document.  The commands specify rasters (combinations of straight lines and curves), which can be scaled and transformed to provide the specified output, including fonts, which can be enhanced by including “hints” to help the system identify key features.  This processor is thus sometimes called a Raster Image Processor (RIP)",0,Human
56,"Whether at a business meeting or a scientific conference, the use of slides or transparencies has been largely replaced by software that can create a graphic presentation.  Generally, the user creates a series of virtual “slides,” which can consist of text (such as bullet points) and charts or other graphics.  Often there are templates already structured for various types of presentations, so the user only needs to supply the appropriate text or graphics.  There are a variety of options for the general visual style, as well as for transitions (such as dissolves) between slides.  Another useful feature is the ability to time the presentation and provide cues for the speaker.  Finished presentations can be shown on a standard monitor screen (if the audience is small) or output to a screen projectorMicrosoft PowerPoint is the most widely used presentation program.  It includes the ability to import Excel spreadsheets, Word documents, or other items created by Microsoft Office suite applications.  The user can switch between outline view (which shows the overall structure of the presentation) to viewing individual slides or working with the slides as a collection. There are a number of alternatives available including Apple’s Keynote and Open Office, which includes a presentation program comparable to PowerPoint.  Another alternative is to use HTML Web-authoring programs to create the presentation in the form of a set of linked Web pages.  (PowerPoint and other presentation packages can also convert their presentations to HTML. ) Although creating presentations in HTML may be more difficult than using a proprietary package and the results may be somewhat less polished, the universality of HTML and the ability to run presentations from a Web site are strong advantages of that approach. ",0,Human
57,"The large computers that first became available in the 1950s , used “line printers. ” These devices have one hammer for each column of the output.  A rapidly moving band of type moves under the hammers.  Each hammer strikes the band when the correct character passes by.  Printing is therefore done line by line, hence the name.  Line printers were fast (600 lines per minute or more) but like the mainframes they served, they were bulky and expensive. The typewriter offered another point of departure for designing printers.  A few early computers such as the BINAC (an offshoot of ENIAC) used typewriters rigged with magnetically controlled switches (solenoids).  However, a more natural fit was with the Teletype, invented early in the 20th century to print telegraph messages.  Since the Teletype is already designed to print from electrically transmitted character codes, it was easy to rig up a circuit to translate the contents of computer data into appropriate codes for printing.  (Since the Teletype could send as well as receive messages, it was often used as a control terminal for computer operators or for time-sharing computer users into the 1970s. )The daisy-wheel printer was another typewriter-like device.  It used a movable wheel with the letters embedded in slim “petals” (hence the name).  It was slow (about 10 characters a second), noisy, and expensive, but it was the only affordable alternative for early personal computer users who required “letter-quality” output. ",0,Human
58,"The dot-matrix printer, which came into common use in the 1980s, uses a different principle of operation than typewriter-style printers.  Unlike the latter, the dot-matrix printer does not form solid characters.  Instead, it uses an array of magnetically controlled pins (9 pins at first, but 24 on later models).  Each character is formed by pressing the appropriate pins into a ribbon that pushes into the paper, leaving a pattern of tiny dots. Besides being relatively inexpensive, dot-matrix printers are versatile in that a great variety of character styles or fonts can be printed ,, either by loading different sets of bitmaps.  Likewise, graphic images can also be printed.  However, because the characters are made of tiny dots, they don’t have the crisp, solid look of printed type",0,Human
59,"Good project management software provides many tools for the purpose.  Available charts and reports often include:,? Gantt charts that use bars to show the duration and percentage of completion of the various overlapping subprojects or tasks. , PERT (Program Evaluation and Review Technique) charts that show each subproject or task as a rectangular “node” with information about the task.  The connections between nodes show the relationships (dependencies) between the items.  PERT charts are usually used at the beginning stages of planning. , Analysis tools that show critical paths and bottlenecks (places where one or more tasks falling behind might threaten large portions of the project).  Generally, the more preceding items a task is dependent on, the more likely that task is to fall behind. , Tools for estimating the probability for completion of a given task based on the probabilities of tasks it is dependent on, as well as other factors such as the likelihood of certain resources becoming available. , A system of alerts or “stoplights” that show slowdowns, potential problems, or areas where work has stopped completely.  These can be set to be triggered when various specified conditions occur. , Integration between project management and budget reporting so tasks and the project as a whole can be monitored in relation to budget constraints. , Integration between the project management software and individual schedules kept in PIM software such as Microsoft Outlook or in handheld computers (PDAs) such as the PalmPilot. , Integration between project management and software for scheduling meetin",0,Human
60,"Computing is a complex, pervasive, and increasingly vital human activity.  It is not surprising that human psychology can play an important role in many aspects of computer use. Since the 1960s psychology (in particular see cognitivescience) has contributed to the structuring of interaction between computer systems and users ,.  It is important to note the significant differences between how computers and humans perceive and process information: computers are extremely fast in processing in a highly structured setting (e. g. , a program).  The human brain, on the other hand, while thousands of times slower, is thus far greatly superior in coping with loosely structured data through pattern recognition, the making of analogies, and generalization.  A number of researchers , have promoted the idea of creating a human-computer synergy where the structure of the system takes advantage of both the machine’s computational and data-retrieval abilities and the human user’s ability to work with the larger picture.  Such research is continuing as autonomous software , and is beginning to interact with Web user",0,Human
61,"The Internet and its perception as a shared cyberspace adds new dimensions to the psychology of computing.  In fact, the emphasis here is not on computation per se but on the representation of ideas and images, communication, social interaction, and identity.  In particular, pioneering work , has illuminated ways in which online interactions affect identity and sense of self—even encouraging the assumption of multiple identities ,.  Indeed, virtual worlds such as Second Life offer new ways to study the formation of communities and social interactions. On the positive side, it has been argued that cyberspace has encouraged people (particularly adolescents) to experiment with new identities in a relatively safe environment, but lack of inhibition and experience can lead to risky behavior such as involvement with sexual predators.  The very fact that many people (particularly the young) may spend several hours a day or more immersed in the online world has also led to concerns; some psychologists have even suggested that “Internet addiction disorder” (IAD) be included as an official mental disorder similar to compulsive gambling.  However, as of 2007, the American Medical Association has not recommended that IAD be classified as a mental disorder, and the American Society of Addiction Medicine has resisted such a status.  Generally, excessive or inappropriate use of the Internet has been seen as a symptom of more traditional diagnoses such as obsession or compulsion. ",0,Human
62,"Python is particularly useful for system administrators, webmasters, and other people who have to link various files, data source, or programs to perform their daily tasks.  The language currently has a small but growing (and quite enthusiastic) following. Without the semicolons and braces found in C and related languages, Python looks rather like BASIC.  Also note that the type of input data doesn’t have to be declared.  The runtime mechanism will assume it’s numeric from the expression found in the print statement.  Python programs thus tend to be shorter and simpler than C, Java, or even Perl programs.  The simple syntax and lack of data typing does not mean that Python is not a “serious” language, however.  Python contains full facilities for object-oriented programming, for example. Python programs can be written quickly and easily by trying commands out interactively and then converted the script to bytecode, a machine-independent representation that can be run on an interpreter designed for each machine environment.  Alternatively, there are translation programs that can convert a Python script to a C source file that can then be compiled for top speed. ",0,Human
63,"By combining mirroring, error correction, and/or striping, different “levels” of RAID can be implemented to suit different needs.  There are various trade-offs: Striping can increase access speed, but uses more storage space and, by increasing the number of disks, also increases the chance that one will fail.  Implementing error correction can make failure recoverable, but slows data access down because data has to be read from more than one location and compared. The most commonly used RAID levels are:, RAID 0—striping data across disks, higher speed but no error correction; failure of any disk can make data unrecoverable, RAID 1—mirroring (data stored on at least two disks), data intact as long as one disk is still operating, RAID 3 and 4—striping plus a dedicated disk for parity (error checking), RAID 5—striping with distributed parity; data can be restored automatically after a failed disk is replaced, RAID 6—like RAID 5 but with parity distributed so that data remains intact unless more than two drives failIn actuality, RAID configurations can be very complex, where different levels can be “layered” above one another, with each treating the next as a virtual drive, until one gets down to the actual hardware.  Although RAID is often implemented using a physical (hardware) controller, operating systems can also create a virtual RAID structure in software, interposed between the logical drive as seen by the read/write routines and the physical drives. ",0,Human
64,"Back in the days of mechanical clocks, curious kids would sometimes take a clock apart to try to figure out how it worked.  A few were even able to reassemble the clock correctly—these youngsters were likely to become engineers! With software, reverse engineering is the process of “taking apart” software and analyzing its operation without having access to the program code itself.  Among other possibilities, reverse engineering may allow one to:, provide equivalent functions without violating copyright laws, emulate one operating system within another ,, determine a file format so other programs can use it as well (interoperability), document the operation of a program whose documentation is lost or no longer available, determine whether a competing product violates one’s patents or copyrights",0,Human
65,"Passive RFID tags have no power supply; the power induced by the reading signal is used to transmit the response.  Because this power is very small, passive tags can only be read at distances from about 4 inches (10 cm) to a few yards (meters), depending on the antenna size and type.  The main advantage of passive tags is that the lack of a battery makes them small, lightweight, and inexpensive, making them ideal for attaching to merchandise (they have also been embedded under the skin of pets and, in a few cases, even people).  Smart cards for use in transit systems and similar applications are also passive; the system is activated by “tagging” or bringing the card near the reader. Active RFID tags have their own battery.  Their advantage is that they are able to initiate communication with the reader, and the signal they send is much stronger, more reliable, and with greater range (up to about 1,500 feet [500 m]).  The stronger signal allows for communication in rougher environments (such as outdoors for tracking cattle or shipping containers). ",0,Human
66,"Current uses for RFID tags and cards of various types include:, automatic fare payments systems for transit systems, automatic toll payments for bridges and turnpikes, automatic book checkout systems for libraries, where it reduces repetitive strain injury (RSI) in staff and simplifies checking shelves, student ID cards, passports (RFID has been included in new U. S.  passports since 2006), tracking cattle, including determining the origin of unhealthy animals, identification chips placed beneath the skin of pets, experimental human RFID implants (pioneered by British computer scientist Kevin Warwick) and now used by VIP customers in a few nightclubs, tracking goods from original shipment to inventory (Wal-Mart now requires its major suppliers to include RFID labels with shipments), scientific sensors, such as seismographic instruments",0,Human
67,"The benefits of RFID technology are numerous: better inventory control ,; more secure passports and other forms of ID; faster, easier access to transportation systems; and potentially, the avoidance of mishaps in hospitals, such as the wrong patient receiving a drug or procedure. However, there are privacy and security concerns that remain to be fully resolved.  The primary threat is that unauthorized persons could illicitly obtain information or track people or goods, for purposes ranging from simple larceny to identity theft.  Privacy rights organizations have also raised concerns that information about consumer purchases could be used for unwanted marketing (or sold to third parties), while information about a library patron’s reading habits could trigger unwarranted government investigations in the name of fighting terrorism. There is an incentive to produce RFID cards and tags that are resistant to unauthorized reading or tampering.  A cryptographic protocol can be used such that no information will be sent or received unless the reader and tag “know” the correct keys.  Another possibility is to create a device that can “jam” reading attempts in the device’s vicinity, perhaps protecting a customer’s grocery cart from being scanned.  Finally, RFID cards can be put inside in a sleeve of material that blocks the signals.  However, cryptographic and other security technologies raise the cost of RFID devices and may make them impracticable for some applications. In September 2006 the National Science Foundation awarded a $1. 1 million grant to the RFID Consortium for Security and Privacy to study potential risks and safeguards for the technology.  That same year a group of major corporations together with the National Consumers League released a draft set of standards and guidelines for best practices in using RFID, with broader scope than the existing EPC (electronic product code) standard",0,Human
68,"Programmers and managers of software development are generally aware of the need for software to properly deal with erroneous data ,.  They know that any significant program will have bugs that must be rooted out ,.  Good software engineering practices and a systematic approach to assuring the reliability and quality of software can minimize problems in the finished product ,.  However, serious bugs are not always caught, and sometimes the consequences can be catastrophic.  For example, in the Therac 25 computerized X-ray cancer treatment machine, poorly thought-out command entry routines plus a counter overflow resulted in three patients being killed by massive X-ray overdoses.  The overdoses ultimately occurred because the designers had removed a physical interlock mechanism they believed was no longer necessary. Any computer application is part of a much larger environment of humans and machines, where unforeseen interactions can cause problems ranging from inconvenience to loss of privacy to potential injury or death.  Seeing these potential pitfalls requires thinking beyond the specifications and needs of a particular project.  For many years the Usenet newsgroup comp. risks (and its collected form, Risks Digest) have chronicled what amounts to an ongoing symposium where knowledgeable programmers, engineers, and others have pointed out potential risks in new technology and suggested ways to minimize them",0,Human
69,"In 1921, the Czech playwright Karel Capek wrote a play called R. U. R.  or Rossum’s Universal Robots.  Robot is a Czech word that has been translated as work(er), serf, or slave.  In the play the robots, which are built by factories to work in other factories, eventually revolt against their human masters. During the 1960s, real robots began to appear in factory settings ,.  They were an outgrowth of earlier machine tools that had been programmed by cams and other mechanisms.  An industrial robot is basically a movable arm that ends in a “hand” called an end effector.  The arm and hand can be moved by some combination of hydraulic, pneumatic, electrical, or mechanical means.  Typical applications include assembling parts, welding, and painting.  The robot is programmed for a task either by giving it a detailed set of commands to move to, grasp, and manipulate objects, or by “training” the robot by moving its arm, hand, and effectors through the required motions, which are then stored in the robot’s memory.  By the early 1970s, Unimation, Inc.  had created a profitable business from selling its Unimate robots to factories. The early industrial robots had very little ability to respond to variations in the environment, such as the “work piece” that the robot was supposed to grasp being slightly out of position.  However, later models have more sophisticated sensors to enable them to adjust to variations and still accomplish the task.  The more sophisticated computer programs that control newer robots have internal representations or “frames of reference” to keep track of both the robot’s internal parameters (angles, pressures, and so on) and external locations in the work area",0,Human
70,"Industrial robots work in an extremely restricted environment, so their world representation can be quite simple.  However, robots that can move about in the environment have also been developed.  Military programs have developed automatic guided vehicles (AGVs) with wheels or tracks, capable of navigating a battlefield and scouting or attacking the enemy ,.  Space-going robots including the Sojourner Mars rover also have considerable onboard “intelligence,” although their overall tasks are programmed by remote commands. Indeed, the extent to which mobile robots are truly autonomous varies considerably.  At one end is the “robot” that is steered and otherwise controlled by its human operator, such as law enforcement robots that can be sent into dangerous hostage situations.  (Another example is the robots that fight in arena combat in the popular Robot Warsshows. )",0,Human
71,"Moving toward greater autonomy, we have the “service robots” that have begun to show up in some institutions such as hospitals and laboratories.  These mobile robots are often used to deliver supplies.  For example, the HelpMate robot can travel around a hospital by itself, navigating using an internal map.  It can even take an elevator to go to another floor. Service robots have had only modest market penetration, however.  They are relatively expensive and limited in function, and if relatively low-wage more versatile human labor is available, it is generally preferred.  For now mobile robots and service robots are most likely to turn up in specialized applications in environments too dangerous for human workers, such as in the military, law enforcement, handling of hazardous materials, and so on. ",0,Human
72,"IBM did succeed in creating RPG (Report Program Generator), a language designed to make it easier for programmers (including beginners) to generate business reports. Most COBOL programs read data, perform tests and calculations, and print the results.  RPG, first released in 1964 for use with the new System/360 mainframe and the smaller System/3, simplifies this process and eliminates most writing of program code statements. A “classic” RPG program is built around the “RPGcycle,” consisting of three stages.  During the input stage, the input device(s), file type, access specifications, and data record structure are specified.  (These specifications can be quite elaborate. ) The heart of the program specifies calculations to be performed with the various data fields, while the output section specifies how the results will be laid out in report form, including such things as headers, footers, and sections. Subsequent versions of RPG added more features.  RPGIV, released in 1994, includes the ability to define subroutines, for example.  IBM has also released VisualAge RPG, which allows for the creation and running of RPG programs in the Microsoft Windows environment.  There are also tools for interfacing RPG programs with various database systems and to use RPG for writing Web-based (CGI) programs",0,Human
73,"Web sites such as news providers and blogs , are constantly posting new material.  While readers can periodically visit a site to look for new material, an increasingly popular option is to subscribe to a “Web feed” and receive the latest information automatically.  The most commonly used tool for Web feeds is RSS, which can stand for Really Simple Syndication, Rich Site Summary, or RDF Site Summary, depending on the format used. The data in an RSS feed can include article titles, summaries, excerpts (such as the first paragraph), or the complete article or posting.  Feeds can also include multimedia such as graphics, video, or sound.  The data (and any linked material) is formatted using standard markup elements ,.  As part of the process of setting up a feed on the Web server, the feed is “published” so that it can be found and read using a client program called a reader or aggregator (the latter can combine feeds or organize them in a newspaper-like format for convenience).  RSS readers can be stand-alone applications or be included with many modern Web browsers and e-mail clients.  Alternatively, Webbased readers or aggregators such as NewsGator Online can allow feeds to be read using any Web browser.  Readers of Web pages can find RSS feeds by looking for a “subscribe” icon or the words RSS or XML.  Specialized search engines such as Bloglines can also help users find interesting feeds.  Additionally, information on the server can also be used by software to automatically deliver the latest content",0,Human
74,"Forerunners of RSS go back to the mid-1990s, with RDF Site Summary first appearing in 1999 for use on Netscape’s portal.  The adoption of RSS by the New York Times in 2002 greatly aided the popularization of the format, as did the growing number of blogs that needed a way for contributors and readers to keep in touch.  Today Web browsers such as Internet Explorer, Mozilla Firefox, and Safari support RSS.  File-sharing services such as BitTorrent can be combined with RSS to deliver content automatically to users’ hard drives.  An offshoot of RSS called Atom has been less widely adopted, but offers better compatibility with XML standards and better management of multimedia content",0,Human
75,"Rich Text Format was developed in the later 1980s by programmers at Microsoft.  Its purpose is to allow for interchange of documents between Microsoft Word and other software, while preserving the original formatting. An RTF file is itself a plain text file containing the document text enclosed in control codes that determine the formatting. Although RTF is an 8-bit format, special escape sequences can be used to specify 16-bit Unicode characters, such as for non-Roman alphabets. Libraries and utilities are available for reading and writing RTF from most popular programming languages, including Perl, PHP, and Ruby. In practice, RTF created by word processors tends to contain many control codes needed to ensure compatibility with older programs, making the files bulky and not practicable to edit directly.  However, saving a file in RTF is a good way to ensure that a document can be used by recipients who may have, for example, older versions of Word. ",0,Human
76,"Ruby is a versatile yet consistent programming language that has become popular in recent years, particularly for Web development.  Designed by Yukihiro Matsumoto and first released in 1995, Ruby has a compact syntax familiar to many users of Perl and other scripting languages ,, avoiding, for example, the need to declare variable types.  However, Ruby is also a thoroughgoing object-oriented language somewhat like Smalltalk ,.  Matsumoto has stressed that the design of the language is intended to stress being natural and enjoyable for the programmer, rather than focusing on the needs of the machine",0,Human
77,"The most popular programming environment for Ruby is Ruby on Rails, an open-source application framework aimed particularly at writing programs that connect Web sites to databases.  The framework is based on the model view controller approach (separating data access and logic from the user interface) and includes “scaffolding” that can be quickly filled in to provide data-driven Web sites with basic functionality.  Developers can also create plug-ins to extend the built-in packages",0,Human
78,"SAP (NYSE symbol: SAP) is a German acronym for Systeme, Anwendungen, und Produkete in der Datenverarbeitung (“Systems, Applications, and Products in Data Processing”).  Five former IBM engineers in Germany founded the company in 1972. Although unfamiliar to the American public, unlike IBMand Microsoft, SAP is the world’s largest business software company, and fourth-largest software provider in general (behind Microsoft, IBM, and Oracle).  The company operates worldwide through three geographical divisions. ",0,Human
79,"SAP specializes in Enterprise Resource Planning (ERP), enhancing a corporation’s ability to manage its key assets and needs and to plan for the future.  This software consists of three tiers: the database, an application server, and the client.  Early versions of this software were designed to run on mainframes.  Other major products include:, SAP NetWeaver, which integrates all other SAP modules using modern open-standard Web technologies ,, Customer Relationship Manager ,, Supply Chain Management ,, Supplier Relationship Management, Human Resource Management System, Product Lifestyle ManagementExchange Infrastructure, Enterprise Portal, SAP Knowledge Warehouse",0,Human
80,"SAP has recognized for some time that while its base of large Fortune 500 companies has given it steady income, changing trends in business have been limiting the software giant’s growth.  In particular, the trend has been toward smaller, simpler, more scalable applications that can be integrated with modern Web services.  In September 2007 SAP announced SAP Business ByDesign, a flexible set of enterprise management services that are delivered over the Web.  However, it remains to be seen how well SAP will be able to compete with more agile companies such as NetSuite and Salesforce. com, and whether the company will be able to upgrade its existing large company user base without disaffecting it. SAP’s major competitor in the United States is Oracle ,, which has sued SAP in 2007 for unfairly downloading and using patches and support materials from Oracle and using them to support former Oracle customers.  SAP and Oracle have generally had quite different growth strategies: SAP grows by expanding and extending its own products, while Oracle has grown mainly through acquiring other companies.  However, in October 2007 SAP acquired Business Objects, a leader in “business intelligence” systems, for $6. 8 billion.  This may signal SAP’s willingness to engage in further strategic acquisitions",0,Human
81,"In order for a computer to work with information, the information must be digitized—converted to data that application programs can recognize and manipulate ,.  Computer users have thus been confronted with the task of converting millions of pages of printed words or graphics into machine-readable form.  Since it is expensive to re-key text (and impractical to redraw images), some way is needed to automatically convert the varying shades or colors of the text or images into a digitized graphics image that can be stored in a file. This is what a scanner does.  The scanner head contains a charge-coupled device (CCD) like that used in digital cameras ,.  The CCD contains thousands or millions of tiny regions that can convert incoming light into a voltage level.  Each of these voltage levels, when amplified, will correspond to one pixel of the scanned image.  (A color scanner uses three different diodes for each pixel, each receiving light through a red, green, or blue filter. )",0,Human
82,"The operation of the head depends on the type of scanner.  In the most common type, the flatbed scanner, a motor moves the head back and forth across the paper, which lies facedown on a glass window.  In a sheet-fed scanner, the head remains stationery and the paper is fed past it by a set of rollers.  Finally, there are handheld scanners, where the job of moving the scanner head is performed by the user moving the scanner back and forth over the page. ",0,Human
83,"The resolution of a scanner depends on the number of pixels into which it can break the image.  The color depth depends on how many bits of information that it can store per pixel (more information means more gradations of color or gray).  Resolutions of 2,400 dots per inch (dpi) or more are now common, with up to 36 bit color depth, allowing for about 68. 7 billion colors or gradations ,Besides considerations of resolution and color depth, the quality of a scanned image depends on the quality of the scanner’s optics as well as on how the page or other object reflects light.  As anyone who has browsed eBay listings knows, the quality of scans can vary considerably.  Most scanners come with software that allows for the scanner to be controlled and adjusted from the PC, and image-editing software can be used to further adjust the scanned image",0,Human
84,"These general principles also apply to systems where more than one processor is available ,, but there is the added complication of deciding where the scheduling program will be run.  In a multiprocessing system that has one “master” and many “slave” processors, the scheduling program runs on the master processor.  This arrangement is simple, but it means that when a slave processor wants to schedule a program it must wait until the scheduling program gets its next time-slice on the master processor. One alternative is to allow any processor that has free time to run the scheduling algorithm.  This is harder to set up because it requires a mechanism to make sure two processors do not try to run the scheduling program at the same time, but it smoothes out the bottleneck that would arise from relying on a single processor. ",0,Human
85,"o trends in recent years have changed the emphasis in scheduling algorithms.  One is the continuing drop in price per unit of processing power and memory.  This means that maximum efficiency in using the hardware can often give way in favor of catering to the user’s convenience and perceptions by giving more priority to interaction with the user.  The other development is the growing use of systems where much of the burden of graphics and interactivity is placed on the user’s desktop, thus simplifying the complexity of sch",0,Human
86,"From microbiology to plasma physics, modern science would be impossible without the computer.  This is not because the computer has replaced the scientific method of observation, hypothesis, and experiment.  Modern scientists essentially follow the same intellectual procedures at did Galileo, Newton, Darwin, and Einstein.  Rather, understanding of the layered systems that make up the universe has now reached so complex and detailed a level that there is too much data for an individual human mind to grasp.  Further, the calculations necessary to process the data usually can’t be performed by unaided humans in any reasonable length of time.  This can be caused either by the inherent complexity of the calculation , or the sheer amount of data (as in DNA sequencing; see bioinformatics and data mining)",0,Human
87,"Even if scientists have a basic understanding of a system, it may be hard to determine what the overall results of the interaction of the many particles (or other elements) in the system will be.  This is true, for example, in the analysis of events taking place in nuclear reactors.  Fortunately computers can apply the laws of the system to each of many particles and determine the resulting actions from their aggregate behavior ,.  Simulation is particularly important in fields where actual experiments are not possible because of distance or time.  Thus, a hypothesis about the formation of the universe can be tested by applying it to a set of initial conditions believed to reflect those at or near the time of the big bang. However, even the most skilled scientists have trouble relating numbers to the shape and interaction of real-world objects.  Computers have greatly aided in making it possible to visualize structures and phenomena using high-resolution 3D color graphics ,.  Features of interest can be enhanced, and arbitrary (“false”) colors can be used to visually show such things as temperature or blood flow.  These techniques can also be used to create interactive models where scientists can, for example, combine molecules in new ways and have the computer calculate the likely properties of the result.  Finally, computer visualization and modeling can be used both to teach science and to give the general public some visceral grasp of the meaning of scientific theories and discoveries",0,Human
88,"By the mid-1990s, many thousands of pages were being added to the World Wide Web each day ,.  The availability of graphical browsing programs such as Mosaic, Netscape, and Microsoft Internet Explorer , made it easy for ordinary PC users to view Web pages and to navigate from one page to another.  However, people who wanted to use the Web for any sort of systematic research found they needed better tools for finding the desired information. There are basically three approaches to exploring the Web: casual “surfing,” portals, and search engines.  A user might find (or hear about) an interesting Web page devoted to a business or other organization or perhaps a particular topic.  The page includes a number of featured links to other pages.  The user can follow any of those links to reach other pages that might be relevant.  Those pages are likely to have other interesting links that can be followed, and so on.  Most Web users have surfed in this way: It can be fun and it can certainly lead to “finds” that can be bookmarked for later reference.  However, this approach is not systematic, comprehensive, or efficient. Alternatively, the user can visit a site such as the famous Yahoo! started by Jerry Yang and David Filo ,.  These sites specialize in selecting what their editors believe to be the best and most useful sites for each topic, and organizing them into a multilevel topical index.  The portal approach has several advantages: The work of sifting through the Web has already been done, the index is easy to use, and the sites featured are likely to be of good quality.  However, even Yahoo!’s busy staff can examine only a tiny portion of the estimated 1 trillion or so Web pages being presented on about 175 million different Web sites (as of 2008).  Also, the sites selected and featured by portals are subject both to editorial discretion (or bias) and in some cases to commercial interest. ",0,Human
89,"The ever-growing World Wide Web consists of billions of linked HTML documents (and other resources), but most of the links contain no information about why the linkage has been made or what it might mean.  Services such as Google can automatically trace the links and index each page , with the aid of “metadata” such as keywords that summarize page content.  However, discovering the relationships between data items on pages, or between pages—and their meaning, or semantics—requires human scrutiny. In his 1999 book Weaving the Web, World Wide Web creator Tim Berners-Lee , described a new way in which Web pages might be organized in the future:I have a dream for the Web [in which computers] become capable of analyzing all the data on the Web—the content, links, and transactions between people and computers.  A “Semantic Web,” which should make this possible, has yet to emerge, but when it does, the day-to-day mechanisms of trade, bureaucracy and our daily lives will be handled by machines talking to machines.  The “intelligent agents” people have touted for ages will finally materialize. In other words, by encoding definitions of objects and their relationships into the text of Web pages, programs , can be written to use this information to answer sophisticated questions such as “which devices from this vendor use open-source software?”",0,Human
90,"The semantic Web is not something that can appear overnight—after all, it will take considerable human effort to encode the information needed for machines to understand Web resources, and additional effort to code the application programs that will take advantage of that information.  However, the potential payoff is huge, allowing both human and automated searchers to tackle much more sophisticated tasks. For example, the University of Maryland is developing a prototype semantic search engine called Swoogle.  It can extract information and determine relationships between documents that include RDF or OWL elements.  Swoogle can also help users find appropriate ontologies for exploring a subject ,. Much research needs to be done.  For example, there is the problem of deriving a measure of “reliability” or “trust” based on the data sources used to answer the query, which may be scattered all over the world and represent very different kind",0,Human
91,"A growing number of people 50 and older have been learning how to use computer technology and especially applications such as e-mail and Web browsing.  However, a substantial number of seniors have expressed reluctance to join the digital world—as of January 2006, the Pew Internet & American Life Project found that only 34 percent of persons 65 and over were online.  Some reasons why seniors have avoided the technology include the following:, the belief that it would be too hard to learn to use it, uncertainty about what can be done online and whether it is worth the effort, fear of well-publicized dangers such as viruses and identity theft, the expense of a personal computer and Internet accessFortunately a number of these factors are gradually being ameliorated.  There are numerous books and courses (such as at adult education or senior centers) that introduce the essentials of computing to seniors.  Properly installed security and filtering software, together with some user education, can minimize the chances of being victimized online.  Finally, Internet-capable PCs are now available for around $300 or less, though the cost of broadband access has not fallen as rapidly as that of hardware. ",0,Human
92,"There are basically two ways to move data from a computer to or from a peripheral device such as a printer or modem.  A byte (8 bits) of data can be moved all at once, with each bit traveling along its own wire ,.  Alternatively, a single wire can be used to carry the data one bit at a time.  Such a connection is called a serial port. The serial port receives data a full byte at a time from the computer bus and uses a UART (Universal Asynchronous Receiver-Transmitter) to extract the bits one at a time and send them through the port.  A corresponding circuit at the other end accumulates the incoming bits and reassembles them into data bytes. The data bits for each byte are preceded by a start-bit to signal the beginning of the data and terminated by an stopbit.  Depending on the application, an additional bit may be used for parity ,.  Devices connected by a serial port must “negotiate” by requesting a particular connection speed and parity setting.  Failure to agree results in gibberish being received. ",0,Human
93,"The official standard for serial transmission is called RS232C.  It defines various additional pins to which wires are connected, such as for synchronization (specifying when the device is ready to send or receive data) and ground.  Physically, the old-style connectors are called DB-25 because they contain 25 pins (many of which are not used).  Most newer PCs have DB-9 (i. e.  nine pin) connectors.  A “gender changer” can be used in cases where two devices both have male connectors (with pins) or female connectors (with corresponding sockets). Because they use a single data transmission line and include error-correction, serial cables can be longer than parallel cables (25 feet or more, as opposed to 10–12 feet).  Serial transmission is generally slower (at up to 115,200 bits/second) than parallel transmission.  Serial connections have generally been used for such devices as modems (whose speed is already limited by phone line characteristics), keyboards, mice, and some older printers.  Today the faster and more flexible USB , is replacing serial connections for many devices including even keyboards",0,Human
94,"In 1982, Andrew Fuegelman created a program called PC-Talk.  This program provided a better way for users with modems to connect to the many bulletin board systems that were starting to spring up.  Fluegelman was familiar with the common practice of public radio and TV broadcasters of soliciting pledge payments to help support their “free” service.  He decided to do something similar with his program.  He distributed it to many bulletin boards, where users could download it for free.  However, he asked users who liked the program and wanted to continue to use it to pay him $25. Fluegelman dubbed his method of software distribution “freeware” (because it cost nothing to try out the program).  Other programmers began to use the same method with their own software.  This included Jim Knopf, author of the PC-File database program, and Bob Wallace, who offered PC-Write as a full-featured alternative to expensive commercial word processing program.  Because Fluegelman had trademarked the term freeware, these other authors began to call their offerings shareware. Today freeware means software that can be downloaded at no cost and for which there is no charge for continued use.  The program may be redistributed by users as long as they don’t charge for it",0,Human
95,"To see a simple shell in action, a Windows user need only bring up a command prompt, type the word dir, and press Enter.  A shell called command. com provides the user interface for users of IBM PC-compatible systems running MS-DOS.  The command processor displays a prompt on the screen.  It then interprets , the user’s commands.  If the command involves one of the shell’s internal operations (such as “dir” to list a file directory), it simply executes that routine.  For example the command:dir temp /pwould be interpreted as a call to execute the dir function, passing it the name “temp” (a directory) and the /p, which dir interprets as a “switch” or instruction telling it to pause the directory listing after each screenful of text.  If the command is an external MS-DOS utility such as “xcopy” (a file copying program), the shell runs that program, passing it the information (mainly file names) from the command line.  Finally, the shell can run any other executable program on the system.  It is then that program’s responsibility to interpret and act upon any additional information that was provided. MS-DOS also has the ability for the command. com shell to read a series of commands stored in a text file called a batch file, and having the *. bat (batch) extension.  This allowed for rudimentary scripting of system housekeeping operations or other routine tasks ,. ",0,Human
96,"A simulation is a simplified (but adequate) model that represents how a system works.  The system can be an existing, real-world one, such as a stock market or a human heart, or a proposed design for a system, such as a new factory or even a space colony. If a system is simple enough (a cannonball falling from a height, for example), it is possible to use formulas such as those provided by Newton to get an exact answer.  However, many real-world systems involve many discrete entities with complex interactions that cannot be captured with a single equation.  During the 1940s, scientists encountered just this problem in attempting to understand what would happen under various conditions in a nuclear reaction. Together with physicist Enrico Fermi, two mathematicians, John von Neumann , and Stanislaw Ulam, devised a new way to simulate complex systems.  Instead of trying fruitlessly to come up with some huge formula to “solve” the whole system, they applied probability formulas to each of a number of particles—in effect, “rolling the dice” for each one and then observing their resulting distribution and behavior.  Because of its analogy to gambling, this became known as the Monte Carlo method.  It turned out to be widely useful not only for simulating nuclear reactions and particle physics but for many other activities (such as bombing raids or the spread of disease) where many separate things behave according to probabilities. ",0,Human
97,"Simulations and simulation techniques are used for a tremendous range of applications today.  Besides helping with the understanding of natural systems in physics, chemistry, biology, or engineering, simulation techniques are also applied to human behavior.  For example, the behavior of consumers or traders in a stock market can be explored with a simulation based on game theory concepts.  Artificial intelligence techniques (such as expert systems) can be used to give the individual “actors” in a simulation more realistic behavior. Simulations are often used in training.  A modern flight simulator, for example, not only simulates the aerodynamics of a plane and its response to the environment and to control inputs, but detailed graphics (and simulated physical motion) can make such training simulations feel very realistic, if not quite to Star Trek holodeck standards.  Whether for flight, military exercises, or stock trading, simulations can provide a much wider range of experiences in a relatively short time than would be feasible (or safe) using the real-world activity.  Simulations can also play an important part in testing software or systems or in predicating the results of business decisions or strategies. Simulations are also frequently sold as entertainment.  Many commercial strategy and role-playing games as well as vehicle simulators contain surprisingly complex simulations that make the games both absorbing and challenging ,.  Such games can also have considerable educational value. ",0,Human
98,"Some typical features of a smart building include the following:, lighting that is controlled by time of day, scheduling, and occupancy sensors, temperature and air-flow sensors to determine the amount of cooling, heating, or fresh air needed, controls for central heating, hot water, and air conditioning systems, optimizing efficiency and minimizing energy use, alarms for intrusion, fire, carbon monoxide/dioxide, and other hazards, alarms indicating failure or unsafe operating conditions for various devices, integration of alarm and status messages with communications systems, enabling users to receive them by e-mail, text message, phone, or other means",0,Human
99,"The smart card is the next generation of transaction devices.  Magnetically coded credit, debit, and ATM cards have been in use for many years.  These cards contain a magnetic strip encoded with a small amount of fixed data to identify the account.  All the actual data (such as account balances) is kept in a central server, which is why credit cards must be validated and transactions approved through a phone (modem) link.  Some magnetic strip cards such as those used in rapid transit systems are rewritable, so that, for example, the fare for the current ride can be deducted.  Telephone cards work the same way.  Nevertheless, these cards are essentially passive tokens containing a small amount of data.  They have little flexibility. However, since the mid-1970s it has been possible to put a microprocessor and rewritable memory into a card the size of a standard credit card.  These smart cards can store a hundred or more times the data of a magnetic strip card.  Further, because they have an onboard computer ,, they can interact with a computer at the point of service, exchanging and updating information",0,Human
100,"Besides the microprocessor and associated circuitry, the smart card contains a small amount of RAM (random access memory) to hold “scratch” data during processing, as well as up to 64 kB of ROM (read-only memory) containing the card’s programming instructions.  The program is created on a desktop computer and written to the ROMthat is embedded in the card.  Finally, the card includes up to 64 kB of EEPROM (Electrically Erasable Programmable Read Only Memory) for holding account balances and other data.  This memory is nonvolatile (meaning that no power is needed to maintain it), and can be erased and rewritten by the card reader. “Contact” cards must be swiped through the reader and are most commonly used in retail, phone, pay TV, or health care applications.  “Contactless” cards need only be brought into the proximity of the reader, which communicates with it via radio signals or a low-powered laser beam.  Contactless cards are more practical for applications such as collecting bridge tolls ,. The card reader (or terminal) at the point of sale contains its own computer, which runs software that requests particular services from the card’s program, including providing identifying information and balances, updating balances, and so on. ",0,Human
101,"Some of the major smartphone manufacturers and their operating systems include the following:, Symbian (Symbian OS), used by Nokia, Motorola, Samsung, and others, Windows Mobile (enhanced Windows CE), popular in phones used in Asia, Blackberry (RIM), the popular PDA/smartphone, Linux, used as the base on which to build a variety of PDA/phone operating systems, including products from Motorola, Palm, and Nokia (Maemo), OS X (Apple), used in Apple’s innovative and very popular iPhone",0,Human
102,"Originally standing for Simple Object Access Protocol, but now no longer an acronym, SOAP is a standard way to access Web services ,.  In today’s Web, where what appears to users to be a single site or application is usually built from many services, such a facility is essential. Prior to SOAP, Web applications usually communicated through remote procedure calls (RPC).  However there were problems with compatibility of applications running under different operating systems (and perhaps using different programming languages), as well as security problems that often led to such facilities being blocked. SOAP, on the other hand, uses the same HTTP recognized by all Web servers and browsers ,—indeed, it can also use secure HTTP (https). A SOAP request (or message) is an ordinary XML file , that includes an “envelope” element specifying it to be a SOAP message, an optional header, a body element containing the information pertaining to the function or transaction requested, and an optional fault element to specify error processing.  After receiving the message, the destination server returns a message providing the requested information. ",0,Human
103,"Today, millions of people—middle, high school, and college students, but increasingly adults as well—have pages on popular Web sites such as MySpace and Facebook.  These sites are significant examples of social networking: the use of Web sites and communications and collaboration technology to help people find, form, and maintain social relationships. The origins of social networking can be traced to online venues that arose in the 1970s and 1980s, notably Usenet and, later, online chat boards ,.  In the late 1990s social networking Web sites began to appear, including Classmates. com (helping people find and communicate with former schoolmates) and SixDegrees. com, which emphasized “knows someone who knows someone who .  .  . ” kinds of links. By the mid-2000s the two biggest sites were Facebook and MySpace.  Founded in 2006 by Mark Zuckerberg, Facebook was originally restricted to Harvard students, but eventually became open to any college student, and then high schools and even places of employment.  (The name comes from a book given to incoming students in some schools to familiarize them with their peers. ) As of late 2007 Facebook had more than 55 million active members and had become the seventh most visited of all Web sites",0,Human
104,"Social scientists can use a variety of software throughout the research process.  For example, researchers might use the following:, Web and bibliographical search tools to find existing research on their topic, note-taking and concept-diagramming (“mind-mapping”) software, software to conduct polls or surveys and compile the results, social networking analysis to better understand a group’s structure and dynamics, statistical analysis tools to analyze the findings ,, map-based systems for studying geographical aspects ,, modeling software to simulate the mechanism being studied, using mathematical techniques such as the Monte Carlo and Markov-Chain methods",0,Human
105,"In general, the overall steps in developing a program are:Detailed specification of what the program will be required to do.  This can include developing a prototype and getting user’s reaction to it. , Creation of a suitable program architecture—algorithm(s) and the data types, objects, or other structures needed to implement them ,. , Coding—writing the program language statements that implement the structure. , Verification and testing of the program using realistic data and field testing ,. ,? Maintenance, or the correction of errors and adding of requested minor features (short of creating a new version of the program)",0,Human
106,"Sony Corporation (NYSE symbol: SNE) is the electronics business unit of Sony Group, a large Japanese multinational company that plays a leading role in worldwide electronics, games, and entertainment media (movies and music), introducing and shaping many now-familiar standards. The company traces its origin to a radio repair shop started by Masaru Ibuka in a bombed-out building in Tokyo in 1945.  He was soon joined by Akio Morita, and the men started an electronics company whose name translates in English to Tokyo Telecommunications Engineering Corporation.  They started by building tape recorders, but in the early 1950s the two entrepreneurs were among the earliest to realize the potential of the transistor, marketing transistor radios starting in 1956.  The devices essentially established the modern consumer electronics field, perfectly fitting with a new music fad among American teenagers—rock and roll. With their marketing success, Ibuka and Morita realized that they needed a simple, catchy name that would appeal to Americans and other non-Japanese customers.  In 1958 they came up with Sony.  Although the name did not exist in any language (and thus could be made proprietary), “Sony” evokes English words such as “sound” and “sonic. ” (It also resembled a Japanese slang phrase “sony-sony,” for something like what we would call “geeks” or “nerds” today. )",0,Human
107,"the company’s successful consumer products have included the following:, Trinitron tubes for televisions and computer monitors (no longer sold in the United States), Walkman portable music player (1979), 3. 5? floppy disk (1983), which flourished until the later 1990sSony? ? ? ? 445, Discman CD-based music player (1984), Handycam camcorder and Video format (1985), Digital audio tape, or DAT (1987), Blu-ray optical discSony would also become a major player in the console gaming market ,.  In 1994 the company introduced the PlayStation, followed by later models in 2000 and 2006.  Sony is also a significant seller of digital cameras, including the Mavica floppy disc (later CD), since discontinued.  The company also introduced its proprietary “memory stick” for storage",0,Human
108,"The simplest and least efficient kind of sort is called the selection sort.  Rather like a bridge player organizing a hand, the selection sort involves finding the record with the lowest key and swapping it with the first record, then scanning back through for the next lowest key and swapping it with the second record, and so on until all the records are sorted.  While this uses memory very efficiently (since the records are sorted in place), it is not only slow, but also gets worse fast.  That is, the time taken to sort n records is proportional to n2. The selection approach suffers because on each pass the sort determines not only the record with the lowest key but 446? ? ? ? sorting and searchingthe one with the next lowest key.  However, that information is not retained.  The heapsort, invented by John Williams in 1964, uses a binary tree to store a heap of sorted records ,.  Once the heap is built, the tree nodes can be used to store record numbers in a corresponding array that will represent the sorted database.  The heapsort is efficient because no records are physically moved, and the only memory needed is for the heap and array.  The heapsort is generally considered the fastest and most reliable general-purpose sorting algorithm, with a maximum running time of log n",0,Human
109,"The bubble sort is based on making comparisons and swaps.  It makes the most convenient comparison possible: each record with its neighbor.  The algorithm looks at the first two records.  If the second has a lower key than the first, the records are swapped.  The procedure continues with the second and third records, then the third and fourth, and so on through all the records, swapping pairs of adjacent records whenever they are out of order.  After one pass the record with highest key will have “bubbled up to” the end of the list.  The procedure is then repeated for all but the last record until the two highest records are at the end, and so on until all the records are sorted.  Unfortunately, the number of comparisons and swaps that must be made makes the bubble sort as slow as the selection sort. ",0,Human
110,"The quicksort improves on the basic bubble sort by first choosing a record with a key approximately midway between the lowest and highest.  This key is called the pivot.  The records are then moved to the left of the pivot if they are lower than it, and to the right if higher (that is, the records are divided into two partitions).  The process is then repeated to split the left side with a new pivot, and then the right side likewise.  This is continued until the partition size is one, and the records are now all sorted.  (Because of this repeated partitioning, quicksort is usually implemented using a procedure that calls itself repeatedly—see recursion. )Devised by C.  A.  R.  Hoare in 1962, quicksort is much faster than the bubble sort because records are moved over greater distances in a single operation rather than simply being exchanged with their neighbors.  Assuming an appropriate initial pivot value is chosen, running time is proportional to the logarithm of n rather than to the square of n. The difference becomes dramatic as the size of the database increases",0,Human
111,"The bubble sort and quicksort are designed to work with records that are in random order.  However, in many applications a database grows slowly over time.  At any given time the existing database is already sorted, so it hardly makes sense to have to resort the whole database each time a new record is added. Instead, an insertion sort can be used.  In its simplest form, the algorithm looks sequentially through the sorted records until it finds the first record whose key is higher than that of the new record.  The new record can then be inserted just before that record, much like the way a bridge player might organize the cards in a hand.  (Since inserting a record and physically moving all the higher records up in memory can be time-consuming, a linked list of key values and associated record number is often used instead.  (See list processing. ) That way only the links need to be changed rather than any records being moved. The insertion sort was improved by Donald L.  Shell in 1959.  His “shellsort” takes a recursive approach (like that in the quicksort), and applies the insertion sort procedure to successively smaller partitions. Another improvement on the insertion sort is the mergesort.  As the name implies, this approach begins by creating two small lists of sorted records (using a simple comparison algorithm), then merging the lists into longer lists.  Merging is accomplished by looking at the two keys on the top of two lists and taking whichever is lowest until the lists are exhausted.  The merge sort also lends itself to a recursive approach, and it is comparable in speed and stability to the heapsort",0,Human
112,"All of the sorting algorithms discussed so far rely upon some form of comparison.  However, it also possible to sort records by calculating their relative positions or distribution ,.  In its simplest form, an array can be created whose range of indexes is equal to 1 to the maximum possible key value.  Each key is then stored in the index position equal to its value (that is, a record with a key of 2314 would be stored in the array at position Array[2314].  This procedure works well, but only if the keys are all integers, the range is small enough to fit in memory, and there are no duplicate keys (since a duplicate would in effect overwrite the record already stored in that position). A more practical approach is to use a formula (hash function) that should create a unique hash value for each key.  The function must be chosen to minimize “collisions” where two keys end up with the same hash value, which creates the same problem as with duplicate keys.  A hash sort is quite efficient within those constraints",0,Human
113,"There are a number of ways that sound can be sampled, stored, or generated digitally ,.  Here we will look at some of the most popular sound file formats. WAVThe WAV (wave) file format is specific to Microsoft Windows.  It essentially stores the raw sample data that represents the digitized audio content, including information about the sampling rate (which in turns affects the sound quality).  Since WAV files are not compressed, they can consume considerable disk space. AIFFAIFF stands for Audio Interchange File Format, and is specific to the Apple Macintosh and to Silicon Graphics (SGI) platforms.  Like WAV, it stores actual sound sample data.  A variant, AIFF-C, can store compressed sound. AUThe AU (audio) file format was developed by Sun Microsystems and is used mainly on UNIX systems, and also in Java programming. MIDIMIDI stands for Musical Instrument Digital Interface.  Unlike most other sound formats, MIDI files don’t represent sampled sound data.  Rather, they represent virtual musical instruments that synthesize sound according to complex algorithms that attempt to mirror the acoustic characteristics of real pianos, guitars, or other instruments.  Since MIDI is like a “score” for the virtual instruments rather than storing the sounds, it is much more compact than sampled sound formats.  MIDI is generally used for music composition rather than casual listening. MP3MP3 is actually a component of the MPEG (Moving Picture Expert Group) multimedia standard, and stands for MPEG1 Audio Layer 3.  It is now the most popular sound format, using compression to provide a balance of sound quality",0,Human
114,"While spam can appear in any communications medium (including chat, instant messaging, and even blogs), the most prevalent type is e-mail spam, which costs U. S.  businesses billions of dollars a year in processing expenditures, lost time, and damage caused by malicious software (malware) for which spam can be either a delivery vehicle or an inducement.  In 2007 an estimated 90 billion spam messages were sent each day. The fundamental driving force of spam is the fact that, given one has Internet access, sending e-mail costs essentially nothing, no matter how many messages are sent.  Thus even if only a tiny number of people respond to a spam solicitation (such as for sexual-enhancement products), the result is almost pure profit for the spammer. Besides directly making fraudulent solicitations for products that are ineffective, counterfeit, or nonexistent, spam carries two other dangers: inducements to click to visit fake Web sites , and attachments containing viruses or other dangerous software ,",0,Human
115,"Ways to stop the spread of spam include the following:, e-mail filtering software, using a combination of text analysis by keyword or statistical correlation , and lists of Internet locations (domains) associated with spamming; filtering can be done both by service providers and individual users, or collaboratively, tightening the technical requirements for messages to be accepted by mail servers (much spam has poorly formatted headers), improving techniques for blocking the viruses used by spammers to set up their bots—see computervirus and firewall, attempting to shut down the infrastructure that supports spam operations, such as hosts who allow e-mail, and sellers of spamming software and illicitly gathered address lists",0,Human
116,"Spyware and adware are two pervasive threats to computer users.  Both are programs that are installed more or less surreptitiously, often accompanying an attractive-looking “free” software package or media download.  Depending on how widely it is defined, as many as eight out of 10 PCs may be infected by some sort of spyware.  Signs of infection can include the system slowing down or periodically freezing, Web browsers that fail to display the expected home page or search results, and the appearance of numerous unwanted pop-up windows (a sign of adware). Ranging from least to most harmful, spyware and adware can do the following:, Display annoying advertising that can clog up the screen or cover up information (some adware can also be spyware that uses information about the user to target advertising), Track Web browsing to provide information to sell to marketers ,, Obtain personal information for use in identity theft, Install keyloggers (programs that record keystrokes, such as passwords being entered) or other “back door” or “trojan” programs",0,Human
117,"Growing concern about spyware has prompted the use of antispyware programs such as Ad-Aware and Spybot-Search & Destroy, as well as a free program from Microsoft.  Antispyware programs are also being included in popular security suites from companies such as Symantec and McAfee.  The programs work similarly to antivirus programs, watching for suspicious behavior or “signatures” matching known spyware or adware.  Depending on the program, the spyware can be blocked from executing at all or removed from the system. The software varies considerably in effectiveness, so users may have to run several different programs to completely remove an “infestation. ”Spyware has been generally given a lower priority than viruses or even spam.  When challenged, spyware makers generally claim that the user authorized its installation (at least implicitly) by installing the utility or other software that contains it.  Although antispyware legislation has been introduced in Congress, it has not passed as of mid-2008.  However, state officials such as former New York State Attorney General Eliot Spitzer successfully sued a spyware company, winning a $7. 5 million settlement",0,Human
118,"A stack is simply a list that represents successive locations in memory into which data can be inserted.  The operation of a stack can be visualized as being rather like the springloaded platform onto which dishes are stacked for washing in some restaurants.  As each dish (number) is added, the stack is “pushed. ” Because only the item “on top” (the last one added) can be removed (“popped”) at any given time, a stack is described as a LIFO (last in, first out) structure.  (Note that this is different from a queue, where items can be added or removed from either end [see queue]. )Stacks are useful whenever nested items must be tracked.  For example, a procedure might call a procedure that in turn calls another procedure.  The stack can keep track of the parameters (as well as the calling address) for each pending procedure. Stacks can also be used to evaluate nested arithmetic expressions.  ",0,Human
119,"Web users increasingly have access to such content as news broadcasts, songs, and even full-length videos.  The problem is that the user must receive the content in real time at a steady pace, not in sputters or jerks.  However, factors such as load on the Web server and network congestion between the server and user can cause delays in transmission.  One way to reduce the problem would be to compress the data ,.  However, excessive compression would compromise audio or picture quality to an unacceptable extent.  Fortunately, a technology called streaming offers a way to smooth out the transmission of large amounts audio or video content ,. When a user clicks on an audio or video link, the player software (or Web browser plug-in) is loaded and the transmission begins.  Typically, the player stores a few seconds of the transmission ,, so any momentary delays in the transmission of data packets will not appear as the data starts to play.  Assuming the rate of transmission remains sufficient, enough data remains in the buffer so that data can be “fed” to the playing software at a steady pace.  If, however, there is too much delay due to network congestion, the playback will pause while the player refills its buffer",0,Human
120,"Founded in 1982, Sun Microsystems (NASDAQ symbol: JAVA) has played an important role in the development of computer workstations and servers, UNIX-based operating systems, and the Java programming language ,. During the 1980s, Sun was known mainly for its workstations for programmers and graphics professionals, running on its own SPARC series microprocessors.  However, 460? ? ? ? structured programmingby the 1990s the growing power of regular desktop PCs was reducing the need for special-purpose workstations.  As the Web grew starting in the 1990s, Sun’s line of multiprocessing Web servers became quite successful, though the “dotbust” of the early 2000s cut revenues. One of Sun’s founders was a key developer of UNIXsoftware ,.  Sun developed its own version of UNIX (SunOS) for its workstations in the 1980s, and then joined with AT&T to develop the widely used UNIX System V Release 4, which in turn became the basis for Sun’s new operating system, Solaris.  (Sun has also supported the use of Linux on its hardware. )",0,Human
121,"Supercomputers are always more expensive and somewhat less reliable than standard computers, so they are used only when necessary.  As the power of standard computers continues to grow, applications that formerly required a multimillion-dollar supercomputer can now run on a desktop workstation (a good example is the creation of detailed 3D graphics). On the other hand, there are always applications that will soak up whatever computing power can be brought to bear on them.  These include analysis of new aircraft designs, weather and climate models, the study of nuclear reactions, and the creation of models for the synthesis of proteins.  The neverending battle of organizations such as the National Security Agency (NSA) to monitor worldwide communications and crack ever-tougher encryption also demands the fastest available supercomputers ,. ",0,Human
122,"The term supply chain management was developed in the 1980s to refer to the systematic efforts to improve the efficiency and reliability of this vital business activity.  Although the details will vary with the industry, a supply chain can include the following activities:, obtaining the raw materials or components needed for the product, manufacturing finished products, marketing the product, distributing the product to retailers or other outlets, servicing the product and supporting customers, (increasingly) providing for the ultimate recycling or disposal of the product",0,Human
123,"A system administrator is the person responsible for managing the operations of a computer facility to ensure that it runs properly, meets user needs, and protects the integrity of users’ data.  Such facilities range from offices with just a few users to large campus or corporate facilities that may be served by a large staff of administrators. The system administrator’s responsibilities often include:, setting up accounts for new users, allocating computing resources (such as server space) among users, configuring the file, database, or local area network (LAN) servers, installing new or upgraded software on users’ workstations, keeping up with new versions of the operating system and networking software, using various tools to monitor the performance of the system and to identify potential problems such as device “bottlenecks” or a shortage of disk space, ensuring that regular backups are made, configuring network services such as e-mail, Internet access, and the intranet (local TCP/IP network), using tools such as firewalls and virus scanners to protect the system from viruses, hacker attacks, and other security threats ,, providing user orientation and training, creating and documenting policies and procedures",0,Human
124,"The systems analyst serves as the bridge between the needs of the user and the capabilities of the computer system.  The systems analyst goes into action when users request that some new application or function be provided (usually in a corporate computing environment). The first step is to define the user’s requirements and to prepare precise specifications for the program.  In doing so, the systems analyst is aided by methodologies developed by computer scientists over the last several decades ,.  Often flowcharts or other aids are used to help visualize the operation of the program ,. After communicating with the user, the systems analyst must then communicate with the programmers, helping them understand what is needed and reviewing their work as they begin to design the program.  Although the systems analyst may do little actual programming, he or she must be familiar with programming tools and practices.  This may make it possible to suggest existing software or components that could be adapted instead of undertaking the cost and time involved with creating a new program.  As a program is developed, systems analysts are often responsible for designing tests to ensure that the software works properly ,",0,Human
125,"Applications programmers write programs to help users work better, while systems programmers write programs to help the computer itself work better ,.  Systems programmers generally work for companies in the computer industry that develop operating systems, network facilities, program language compilers and other software development tools, utilities, and device drivers.  However, systems programmers can also work for applications developers to help them interface their programs to the operating system or to devices ,. Modern operating systems are highly complex, so systems programmers tend to specialize in particular areas.  These might include device drivers, software development tools, program language libraries, applications programming interfaces (APIs), and utilities for monitoring system conditions and resources.  Systems programmers develop the infrastructure needed for networking, as well as multiple-processor computers and distributed computing systems.  Systems programmers also play a key role when an application program must be “ported” to a different platform or simply modified to run under a new version of the operating system",0,Human
126,"As the name suggests, a tablet PC is a small computer about the size of a notebook (not to be confused with a “notebook PC,” which is a small, light laptop).  The user can write on the screen with a stylus to take notes (for similar functionality, see graphics tablet), draw, and make selections with stylus or fingertip. If the user writes on the screen, software converts the writing to the appropriate characters and stores them in a file ,.  As with some PDAs, there may also be a system of shorthand “gestures” that can be used to write more quickly.  Alternatively, the user can type with stylus or fingertips on a “virtual keyboard” displayed on the screen ,. A more versatile and natural interface is becoming available: “multitouch,” pioneered by the Apple iPhone and Microsoft Surface, can recognize multiple motions and pressure points simultaneously.  This allows the user to, for example, flick the finger to “turn a page” or use a pinching motion to “pick up” an object. Applications for tablet PCs include many PDA-type applications ,, field note taking, inventory, and other tasks that require a device that is not encumbering.  Because of its compactness, a tablet PC can also be a good reader for ebooks ,. ",0,Human
127,"An interesting variant is the Internet tablet, best known in Nokia’s N-series.  These are smaller and lighter than a tablet PC.  The Nokia N810, for example, has a slide-out keyboard as well as a virtual screen keyboard.  The most notable feature is the Internet browser and related applications, such as e-mail and instant messaging, and built-in wireless connections ,.  Although there is no phone, Internet-based services such as Skype can be used to place calls, or a Bluetooth-equipped mobile phone.  The Nokia series uses a variant of Linux and can run a large variety of open-source applications",0,Human
128,"Anyone who has seen computers in old movies is familiar with the row of large, freestanding tape cabinets with their spinning reels of tape.  The visual cue that the computer was running consisted of the reels thrashing back and forth vigorously while rows of lights flashed on the computer console.  Magnetic tape was indeed the mainstay for data storage in most large computers , in the 1950s through the 1970s. In early mainframes the main memory (corresponding to today’s RAM chips) consisted of “core”—thousands of tiny magnetized rings crisscrossed with wires by which they could be set or read.  Because core memory was limited to a few thousand bytes (kB), it was used only to hold the program instructions , and to store temporary working data while the program was running. The source data to be processed by the program was read from a reel of tape on the drive.  If the program updated the data (rather than just reporting on it), it would generally write a new tape with the revised data.  In large facilities a person called a tape librarian was in charge of keeping the reels of tape organized and providing them to the computer operators as needed. ",0,Human
129,"By the 1990s, PC users generally used tapes only for making backups.  A typical backup tape drive uses DAT (digital audio tape) cartridges that hold from hundreds of megabytes to several gigabytes of data.  Most drives use a rotating assembly of four heads (two read and two write) that verify data as it’s being written.  As a backup medium, tape has a lower cost per gigabyte than disk devices.  It is easy to use and can be set up to run unattended (except for periodically changing cartridges). However, since tapes are written and read sequentially, they are not convenient for restoring selected files ,.  Many smaller installations now prefer using a second (“mirror”) hard drive as backup, using disk arrays , or using recordable CDs or optical drives for smaller amounts of data ,. Many large companies and government agencies have thousands of reels of tape stored away in their vaults since the 1960s, including data returned from early NASA space missions.  As time passes, it becomes increasingly difficult to guarantee that this archived data can be successfully read.  This is due both to gradual deterioration of the medium and the older data formats becoming obsolete ,. ",0,Human
130,"Tcl includes a number of extensions that, for example, provide access to popular database formats such as MySQL and can interface with other programming languages such as C++ and Java.  The most widely used extension is Tk, which provides a library for creating user interfaces for a variety of operating systems and languages such as Perl, Python, and Ruby. Tcl has been described as a “glue” to connect existing applications.  It is relatively easy to write and test a script interactively (often at the command line), and then insert it into the code of an application.  When the application runs, the Tcl interpreter runs the script, whose output can then be used by the main application ,",0,Human
131,"The header information also includes:, The total length of the packet.  In theory packets can be as large as 65 kbytes; in practice they are limited to a smaller maximum. , An identification number that can be used if a packet is broken into smaller pieces for efficiency in transmission.  This allows the packet to be reassembled at the destination. , A “time to live” value that specifies how many hops (movements from one intermediate host to another) the packet will be allowed to take.  This is reduced by 1 for each hop.  If it reaches 0, the packet is assumed to have gotten “lost” or stale, and is discarded. , A protocol number (the protocol is usually TCP, see below). , A checksum for checking the integrity of the header itself (not the data in the packet). , The source and destination addresses. The source and destination are given as IP addresses, which are 32 bits long and typically written as four sets of up to three numbers each—for example, 208. 162. 106. 17",0,Human
132,"Most software companies now have Web sites that include a support section that offers services such as, Frequently Asked Questions (FAQ) files with answers to common problems. , A searchable “knowledge base” of articles relating to various aspects of the software, including compatibility with other products, operating system issues, and so on. , Forms or e-mail links that can be used to submit questions to the company.  Typically questions are answered in one or two working days. , A bulletin board where users can share solutions and tips relating to the software. Web sites for publications such as PC Magazine and ZDNet also offer articles and other resources for working with the various versions of Microsoft Windows and popular applications. ",0,Human
133,"As millions of people became new computer users during the 1980s, a thriving computer book publishing industry offered users a more user-friendly approach than that usually provided in the manuals issued by the software companies.  The “Dummies” books, offering bite-sized servings of information written in a breezy style and accompanied by cartoons, eventually spread beyond computers into hundreds of other fields and the format was then copied by other publishers.  Publishers such as Sams, Coriolis, and particularly O’Reilly have aimed their offerings at more experienced users, programmers, and multimedia developers. Computer trade books are often written by experienced developers and systems programmers who can offer advanced knowledge and “tips and tricks” to their less experienced colleagues.  Since many technical “gurus” are not experienced writers, the best results often come from collaboration between the expert and an experienced technical writer and/or editor who can review the material for completeness, organization, and clarity. In recent years there has been some contraction in the computer book industry.  This has arisen from several sources: improved on-line help included in products; the dominance of many applications areas by a handful of products; and fewer people needing beginner-level instructions",0,Human
134,"Many technical writers work within software companies or in the information systems departments of other corporations, universities, or government agencies.  Their work is generally more highly structured than that of the manual or book writer.  As part of a development team, a technical writer may be in charge of creating documentation describing the data structures, classes, and functions within the program.  This task is aided by a variety of tools including facilities for extracting such information automatically from C++ or Java programs.  The writer may also be responsible for maintaining logs that show each change or addition made to the program during each compiled version or “build. ”This type of technical writing requires detailed knowledge of operating systems, programming languages, software development tools, and software engineering methodology.  It also requires the ability to work well as part of a team, often under conditions of high pressure. ",0,Human
135,"Major policy issues involving information technology industries include:, foreign trade and the protection of intellectual property ,, attempts to reform the patent system to prevent what is seen as dubious and expensive litigation, the need for an increasing number of trained workers and providing a sufficient number of visas for foreign workers ,, preserving equal access to the Internet ,, which pits content providers against telecommunications companies, promoting the development of a next-generation Internet infrastructure (“Internet 2”)government support for computer research (such as through the National Science Foundation)—see government funding of computer research, favorable treatment of online businesses with regard to taxation (often objected to by traditional brickand-mortar businesses)—see e-commerce, laws against computer-related fraud and other crime ,, Privacy regulations ,The computer industry is also involved in issues that will affect its future over the longer term, such as the need to improve math and science education in elementary and high schools, energy and environmental policy, and issues such as health care and pensions that affect all sectors of the economy. ",0,Human
136,"Prior to the court-ordered breakup of AT&T in 1984, the phone industry functioned in a monolithic way and was not very responsive to the needs of the growing computer networking industry. The breakup of AT&T led to growing competition, providing a wider variety of telecommunications equipment and lower phone rates just as PC users were starting to buy modems and sign up with online services and bulletin boards.  The growing deregulation movement in the 1990s (culminating in the Telecommunications Act of 1996) furthered this process by opening cable and broadcast television, radio, and other wireless communication to competition. With more than half of American Internet users on high-speed connections ,, the delivery of communications and media over the Net can only grow.  Wireless and mobile services (satellite, cell network, and 802. 11—see wireless computing) have also been growing vigorously.  The result is that the “information highway” now has many lanes, with some being express lanes. ",0,Human
137,"Telecommuting (also called telework) is the ability to work from home or from some location other than the main office.  According to a report by the nonprofit organization WorldatWork, 28. 7 million people worked from home at least one day a month in 2006.  (Self-employed persons, of course, have a much higher rate of working from home. )Telecommuting was made possible by the growing capabilities of home computers and the availability of network connections that allow the worker at home to have access to most of the people and facilities that would be available if the worker were on site.  Workers and companies that promote telecommuting often cite the following advantages:, elimination of stressful, time-wasting commutes, workers may be more productive because they have fewer office distractions, unnecessary meetings, etc. , reduction of traffic, air pollution, and fuel costs, greater flexibility in working hours, the ability of working parents with small children to combine child care and work to some extent, reduction of costs associated with office facilities",0,Human
138,"Some of the problems or disadvantages cited include:, Worker productivity may decrease due to lack of sufficient discipline and workers becoming distracted at home. ,? Managers may have trouble keeping track of or evaluating the activities of workers who are not physically present. , Telecommuters may miss critical information and go “out of the loop. ”, Security can be compromised, particularly through theft of laptops containing sensitive personal data. , Possible legal liabilities and application of OSHA rules to home working situations. ",0,Human
139,"The alternative is to connect the remote participant to a mobile robot (this is sometimes called telerobotics).  Such robots already exist, although their capabilities are limited and they are not yet widely used for meetings.  RodneyBrooks, director of the MIT Artificial Intelligence Laboratory, foresees a not very distant future in which such robots will be commonplace. The robot will have considerable built-in capabilities, so the person who has “roboted in” to it won’t need to worry about the mechanics of walking, avoiding obstacles, or focusing vision on particular objects.  Seeing and acting through the robot, the person will be able to move around an environment as freely as persons who are physically present.  The operator can give general commands amounting to “walk over there” or “pick up this object” or perform more delicate manipulations by using his or her hands to manipulate gloves connected to a force-feedback mechanism. Brooks sees numerous applications for robotic telepresence.  For example, someone at work could “robot in” to his or her household robot and do things such as checking to make sure appliances are on or off, respond to a burglar alarm, or even refill the cat’s food dish.  Robotic telepresence could also be used to bring expertise (such as that of a surgeon) to any site around the world without the time and expense of physical travel.  Indeed, robots may be the only way (for the foreseeable future) that humans are likely to explore environments far beyond Earth ,. ",0,Human
140,"The term template is used in a several contexts in computing, but they all refer to a general pattern that can be customized to create particular products such as documents. In a word processing program such as Microsoft Word, a template (sometimes called a style sheet) is a document that comes with a particular set of styles for various elements such as titles, headings, first and subsequent paragraphs, lists, and so on.  Each style in turn consists of various characteristics such as type font, type style (such as bold), and spacing.  The template also includes properties of the document as a whole, such as margins, header, and footer. To create a new document, the user can select one of several built-in templates for different types of documents such as letters, faxes, and reports, or design a custom template by defining appropriate styles and properties.  Special sequences of programmed actions can also be attached to a template ,. Templates can be created and used for applications other than word processing.  A spreadsheet template consists of appropriate macros and formulas in an otherwise blank spreadsheet.  When it is run, the template prompts the user to enter the appropriate values and then the calculations are performed.  A database program can have input forms that serve in effect as templates for creating new records by inputting the necessary data. ",0,Human
141,"The primary use of text editors today is to create programs and scripts.  These must generally be created using only standard ASCII characters ,, without all the embedded formatting commands and graphics found in word processing documents.  Programmer’s text editors can be very sophisticated in their own right, providing features such as built in syntax checking and formatting or (as with the Emacs editor) the ability to program the editor itself.  Ultimately, however, program editors must create a source code file that can be processed by the compiler. Text editors are also useful for writing quick, short scripts , and can be handy for writing HTML code for the Web.  However, many Web pages are now designed using word processor–like programs that convert the WYSIWYG (what you see is what you get) formatting into appropriate HTML codes automatically",0,Human
142,"Although they use different devices and formats, text messaging on cell phones and PDAs and instant messaging through online services have much in common.  Both involve sending short messages to other users who can receive them and reply as soon as they are online.  (This is an ad hoc connection that differs from a chat room [see chat, online] in that the latter is an established location where people go to converse with other members.  It also differs from an online discussion group [see conferencing systems and netnews and newsgroups] where messages are posted and may be replied to later, but there is no real-time communication. )Text messaging or texting uses a protocol called Short Message Service (SMS), which is available with most cell phones and service plans as well as PDAs that have wireless connections.  When a user sends a message to a designated recipient, it goes to a service center where it is routed to the destination phone; if that phone is not connected, the message is stored and retried later.  Typically messages are limited to 160 characters, though up to six or so messages can be concatenated and treated as a longer message. While texting did not become popular until the late 1990s, instant messaging began in the 1970s as a way for multiple users on a shared computer or network (such as a UNIX system) to communicate in real time using commands such as send and talk (the latter being more conversational—see chat, online).  In the late 1980s and early 1990s, various dial-up services , provided for sending text messages (AOL was the first to use the term instant messages for its facility).  By the mid-1990s instant messaging was well established on the Internet, often employing a graphical user interface, as with ICQ and AOL Instant Messenger (AOL later acquired ICQ as well). ",0,Human
143,"Between 2000 and 2004 the numbers of text messages sent worldwide soared from 17 billion to 500 billion.  At about a dime a message, texting became a major source of revenue for phone companies.  Since then, texting has continued to grow, particularly in parts of Europe, the Asia-Pacific region (particularly China), and Japan (where it has largely become an Internet-based service). In the United States texting is most popular among teenagers ,.  It is not uncommon to see a bench full of teens talking excitedly to one another while carrying on simultaneous texting with unseen friends in what, to many adult onlookers, appears to be an incomprehensible code, their conversation perhaps ending with ttyl (talk to you later). Loosely affiliated groups communicating by text , have organized everything from “happenings” to serious protest campaigns (as in the anti-WTO [World Trade Organization] demonstrations in Seattle in 1999 and in the Philippines uprising in 2001. )",0,Human
144,"As the name implies, a touchscreen is a screen display that can respond to various areas being touched or pressed.  Invented in 1971, the first form of touchscreens to become part of daily life were found on automatic teller machines (ATMs) and point-of-sale credit card processors. Touchscreens can detect the pressure of a finger or stylus in several ways: A “resistive” touchscreen uses two layers of electrically conductive metallic material separated by a space.  When an area is touched, the two layers are electrically connected, and the change in electrical current is registered and converted to a code that identifies the location touched.  Surface acoustic wave (SAW) touchscreens use an ultrasonic wave that is interrupted by a touch; capacitive touchscreens respond to the change in electron storage (capacitance) caused by contact with a human body.  Various other acoustic, mechanical (strain-based), or optical systems can also be used, with the latter being particularly popular",0,Human
145,"Many computer applications involve the arrival of a set of data that must be processed in a specified way.  For example, a bank’s ATM system receives a customer’s request to deposit money together with identification of the account and the amount to be deposited.  The system must accept the deposit, update the account balance, and return a receipt to the customer.  This is an example of real-time transaction processing. Some applications process transactions in batches.  For example, a company may run a program once a month that generates paychecks and withholding stubs from employee records that include hours worked, number of dependents claimed, and so on.  Indeed, in the ATM example, the account balance is typically not updated during the on-line transaction, but instead a batch transaction is stored.  Overnight that transaction will be processed together with other transactions affecting that account (such as checks), and the balance will then be officially updated.  (The program module that keeps track of the progress of transactions is called a transaction monitor. )",0,Human
146,"The tree is a data structure that consists of individual intersections called nodes.  The tree normally starts with a single root node.  (Unlike real trees, data trees have their root at the top and branch downward. ) The root connects to one or more nodes, which in turn branch into additional nodes, often through a number of levels.  (A node that branches downward from another node is called that node’s childnode. ) A node at the bottom that does not branch any further is called a terminal node or sometimes a leaf. Trees are useful for expressing many sorts of hierarchical structures such as file systems where the root of a disk holds folders that in turn can hold files or additional folders, and so on down many levels.  (A corporate organization chart is a noncomputer example of a hierarchical tree. )",0,Human
147,"A binary tree is a tree in which no node has more than two child nodes.  To move through data stored in a binary tree, a program can use two pointers, one to the current node’s left child and one to its right child ,.  The pointers can then be used to trace the paths through the nodes.  If the tree represents a file that has been sorted ,, comparing nodes to the desired value and branching accordingly quickly leads to the desired record. Alternatively, the data can be stored directly in contiguous memory locations corresponding to the successive numbers of the nodes.  This method is faster than having to trace through successive pointers, and a binary search algorithm can be applied directly to the stored data.  On the other hand it is easier to insert new items into a linked list ,. A common solution is to combine the two structures, storing the linked list in a contiguous range of memory by storing its root in the middle of the range, its left child at the beginning of the range, its right child at the end, and then repeatedly splitting each portion of the range to store each level of children.  Intuitively, one can see that algorithms for processing such stored trees will take a recursive approach ,",0,Human
148,"The more than five-century-old art of typography (the design, arrangement, and setting of printing type) was transformed in the latter part of the 20th century by digital technology.  With the exception of some traditional presses devoted to the fine book market, nearly all type used today is designed and set by computer. Most users are familiar with the typefaces distributed with their operating system and software, such as the popular Adobe and TrueType ,.  Many such font designs are based on (and sometimes named after) traditional typefaces, modified for readability using typical displays and printers. For control of composition, there are three overlapping levels of software, ranging from easiest to use (but most limited) to most complex, versatile, and precise.  Modern word processors such as Microsoft Word and Open Office provide enough control for many types of shorter documents ,.  Desktop publishing software adds facilities suitable for layout of fliers, brochures, newsletters, and similar publications that often mix text and graphics ,. More elaborate documents such as books, magazines, and newspapers require more sophisticated facilities to control the layout and flow of text.  Some traditional choices include LaTex (for the Tex typesetting program), used particularly by scientists and other academics, and the older troff and its offshoots on UNIX systems.  More recent programs include Quark, FrameMaker, PageMaker, and InDesign.  Related utilities often used in digital typography include font editors (for design and modification) and utilities to convert fonts from one format to another",0,Human
149,"Ubiquitous (or pervasive) computing focuses not on individual computers and tasks but on a world where most objects (including furniture and appliances) have the ability to communicate information.  (This has also been called “the Internet of things. ”) This can be viewed as the third phase in a process where the emphasis has gradually shifted from individual desktops (1980s) to the network and Internet (1990s) to mobile presence and the ambient environmentSome examples of ubiquitous computing might include:, picture frames that display pictures attuned to the user’s activities, “dashboard” devices that can be set to display changing information such as weather and stock quotes, parking meters that can provide verbal directions to nearby attractions, kiosks or other facilities to provide verbal cues to guide travelers, such as through airports, home monitoring systems that can sense and deal with accidents or health emergencies",0,Human
150,"The essential core of the UNIX system is the kernel, which provides facilities to organize and access files ,, move data to and from devices, and control the running of programs (processes).  In designing UNIX, Thompson deliberately kept the kernel small, noting that he wanted maximum flexibility for users.  Since the kernel was the only part of the system that could not be reconfigured or replaced by the user, he limited it to those functions that reliability and efficiency dictated be handled at the system level. Another way in which the UNIX kernel was kept simple was through device independence.  This meant that instead of including specific instructions for operating particular models of terminal, printers, or plotters within the kernel, generic facilities were provided.  These could then be interfaced with device drivers and configuration files to control the particular devices. A UNIX system typically has many users, each of whom may be running a number of programs.  The interface that processes user commands is called the shell.  It is important to note that in UNIX a shell is just another program, so there can be (and are) many different shells reflecting varying tastes and purposes ,.  Traditional UNIXshells include the Bourne shell (sh), C shell (csh), and Korn shell (ksh).  Modern UNIX systems can also have graphical user interfaces similar to those found on Windows and Macintosh personal computers ,. ",0,Human
151,"Traditional print and broadcast media divide the world into two groups: content producers and content consumers.  However, as noted by its creator Tim Berners-Lee at its very beginning, the World Wide Web had at least the potential for users to take an active role in linking existing content and contributing their own ,.  Indeed, Berners-Lee wanted Web client software to include not only browsing functions but easy ways for users to create their own Web pages. In reality, early users faced something of a learning curve, usually having to cope with HTML to some extent, for example.  But by the mid-2000s a variety of new media of communication had become readily accessible using an ordinary Web browser at sites that host the required software.  The most prominent applications are blogs , and wikis, particularly Wikipedia ,. Meanwhile, inexpensive digital still and video cameras and easy-to-use editing software encouraged people to make their own media creations.  Sites to enable users to upload, share, and comment on their creations have flourished ,. The growth of sites such as Facebook and MySpace , has also provided new ways for users from junior high school age on up to create and share content",0,Human
152,"The marketplace has spoken, and the desktop GUI is now the mainstream interface for most ordinary PC users.  However, there are a variety of other interfaces that are used for particular circumstances or applications, such as:, touchscreens (as with ATMs) ,, handwriting or written “gesture” recognition, such as on handheld computers , or for drawing tablets, voice-controlled systems ,, trackballs, joysticks, and touchpads (used as mouse alternatives), virtual reality interfaces using head-mounted systems, sensor gloves, and so on ,Because much interaction with computers is now away from the desktop and taking place on laptops, handheld, or palm computers, and even in cars, there is likely to be continuing experimentation with user interface design. ",0,Human
153,"Dating back to the mid-1990s, VBScript is a scripting language developed by Microsoft and based on its popular Visual Basic programming language ,.  It is also part of the evolution of what Microsoft called “active scripting,” based on components that allow outside access to the capabilities of applications.  The host environment in which scripts run is provided through Windows (as with Windows Script Host) or within Microsoft’s Internet Explorer browser. For client-side processing, VBScript can be used to write scripts embedded in HTML pages, which interact with the standard Document Object Model , in a way similar to other Web scripting languages (in particular, see JavaScript).  However, VBScript is not supported by popular non-Microsoft browsers such as Firefox and Opera, so developers generally must use the widely compatible JavaScript instead.  VBScript can also be used for processing on the Web server, particularly in connection with Microsoft’s Web servers ,. Because versions of Windows starting with Windows 98 include Windows Script Host, VBScripts can also be written to run directly under Windows.  One unfortunate consequence was scripts containing worms (such as the I LOVE YOU worm) or other malware and mailed as attachments to unwary use",0,Human
154,"When videotape first became available in the 1950s, recorders cost thousands of dollars and could only be afforded by TV studios.  Today the VCR is inexpensive and ubiquitous.  However, it is hard to edit videotape.  Tape is a linear medium, meaning that to find a given piece of video the tape has to be moved to that spot.  Removing or adding something involves either physically splicing the tape (as is done with film) or more commonly, feeding in tape from two or more recorders onto a destination tape.  Besides being tedious and limited in capabilities, “linear editing” by copying loses a bit of quality with each copying operation. Today, however, it is easy to shoot video in digital form , or to convert analog video into digital form.  Digital video is a stream of data that represents sampling of the source signal, such as from the chargecoupled device (CCD) that turns light photons into electron flow in a digital camera or digital camcorder.  This process involves either software or hardware compression for storage and decompression for viewing and editing (such a scheme is called a CODEC for “compression/decompression”).  The most widely used formats include DV (Digital Video) and MPEG (Motion Picture Expert Group), which has versions that vary in the amount of compression and thus fidelity",0,Human
155," A little later, bulletin boards and especially systems such as the WELL (Whole Earth ’Lectronic Link) based in the San Francisco Bay Area , provided long-term outlets for people to share information and interact on-line. Looking at the WELL, a writer named Howard Rheingold introduced the term virtual community in a 1993 book.  He explored the ways in which a sufficiently compelling and versatile technology encouraged people to form long-term contacts, form personal relationships, and carry out feuds.  When on-line, participants experience such a venue as the WELL as a place that becomes almost as tangible (and often as “real”) as a physical place such as a small town or corner bar. Virtual community members who live in the same geographical area sometimes do get together physically (the WELL has had picniclike “WELL Office Parties” for many years).  Members can band together to support a colleague who faces a crisis such as the life-threatening illness of a son (on the WELL, blank postings called beams are often used as an expression of sympathy).  The virtual community can also serve as a rallying point following a physical disaster such as the 1989 earthquake in the San Francisco Bay Area.  On a daily basis, virtual communities can often provide help or advice from a remarkable variety of highly qualified experts. ",0,Human
156," the computing field, virtualization involves the creation of a working model or representation of one system within a different system.  This idea has been widely used in the field since the 1960s.  Some applications of virtualization include:, An appropriate model of a system (such as a programming framework—see application programming interface) that hides unneeded details can make it easier for programmers to understand and access its functions ,. , A compiler for a language that compiles all programs to an intermediate representation (such as “bytecode”).  A virtual machine running on each kind of platform can then run the code, taking care of the details required by the host hardware ,. , A virtual machine created in software can be designed to perform all the functions available on a particular hardware platform or operating system, allowing software to be run on a system different from the one for which it was originally written ,.  For example, there are a number of virtualization programs (such as VMWare for PCs) that can create separate areas in memory, each running a different operating system, such as a version of Windows or Linux. ,? Multiple processors or entire computers can be treated as a single entity for processing a program, with software designed to assign threads of execution to physical processors and to coordinate the use of shared data ,. , A physical device such as a disk drive can be made to appear as several separate devices to the operating system (for better organization of data).  Similarly, many servers can run on the same physical machine.  Conversely, multiple drives can appear to be a single logical device while providing redundancy and error recovery ,. , A secure “virtual private network” can be created within the larger public Internet.  The virtual system takes care of encrypting and transmitting data through the physical network. ",0,Human
157,"The concept of virtualization can also be applied to how work involving computers is being conceptualized and organized in the modern world ,.  A “virtual office” or even “virtual corporation” is a business entity that is not tied to a physical location, but uses networks, communications technology, and facilities such as video conferencing to keep workers in touch.  Alternatively, several organizations can share the same physical space (such as for mail or shipping) while maintaining their separate identities. Similarly, people can form long-lasting social networks while meeting physically seldom (if at all)—see socialnetworking and virtual community",0,Human
158,"Besides military training, currently the most viable application for VR seems to be entertainment.  VR techniques have been used to create immersive experiences in elaborate facilities at venues such as Disneyland and Universal Studios, and to some extent even in local arcades.  VR that is accompanied by convincing physical sensations has allowed for the creation of a new generation of roller coasters that if built physically would be too expensive, too dangerous, or even physically impossible. However, there are other significant emerging applications for VR.  When combined with telerobotic technology ,, VR techniques are already being used to allow surgeons to perform operations in new ways.  VR technology can also be used to make remote conferencing more realistic and satisfactory for participants.  Clearly the potential uses for VR for education and training in many different fields are endless.  VR technology combined with robotics could also be used to give disabled persons much greater ability to carry out the tasks of daily life. In the ultimate VR system, users will be networked and able to simultaneously experience the environment, interacting both with it and one another.  The technical resources and programming challenges are also much greater for such applications.  The result, however, might well be the sort of environment depicted by science fiction writers such as William Gibson ,",0,Human
159,"The basic idea of VoIP is simple: the Internet can carry packets of any sort of data ,, which means it can carry the digitized human voice as well, carrying ordinary phone calls.  There are several ways to do this:, a regular phone plus an adapter that connects to the computer and compresses and converts between regular analog phone signals and the digital equivalent, a complete “IP phone” unit that includes all needed hardware and software—no computer needed, just a network connection, such as to a router, use of the computer’s own sound card and speakers with a microphone, plus software (often free)Using that last option, VoIP service can be essentially free, regardless of distance.  However, one can only call someone who is currently connected to the Internet and also has VoIP software",0,Human
160,"At least as currently implemented, VoIP does have some disadvantages:, Like cordless phones (but unlike traditional phones), VoIP requires that the user be connected to power.  This may make the system unavailable in an emergency. , Also, in an emergency, a 911 operator has no way to know where the caller is located geographically.  This could be a problem if the caller is unable to provide this information. , While a regular phone is a pretty simple device, VoIP requires special hardware or a PC, which might fail. , VoIP requires a working Internet connection—in practice, a high-speed connection ,.  Load or instability in the network could cause interruptions in calls or a lowering of voice quality. , As with other data sent over the Internet, there are potential security concerns.  Encryption can be used to secure VoIP calls, but this in turn leads to concerns by law enforcement agencies seeking to implement eavesdropping warrants. ",0,Human
161,"For some time, technology pundits have talked about computers being literally woven into daily life, embedded in clothing and personal accessories.  However, implementations have thus far seen only limited use.  For example, watches with limited computer functions , have not proven popular—a watch large enough for input and display of information would likely be too bulky for comfort.  (People have also walked about with attached webcams, although the novelty seems to have quickly worn off. )",0,Human
162,"Although the most important part of Web 2. 0 is its business and social models, a number of Web technologies are needed to provide the flexibility and rich interaction needed to offer a new Web experience.  These include:, dynamic, efficient generation of content ,, programming interfaces , using structured text files ,, platforms for running applications in the browser, such as Google apps, merging and customizing content from different sources ,, user subscription to content platforms for user-created content and collaboration",0,Human
163,"Some typical features of a modern Web browser include, navigation buttons to move forward and back through recently visited pages, tabs to switch between Web pages, a “history” panel allowing return to pages visited in recent days, a search button that brings up the default search engine (which can be chosen by the user), the ability to save page as “favorites” or “bookmarks” for easy retrieval",0,Human
164,"Today a Web user can view a live news broadcast, listen to music from a radio station, or view a document formatted to near-print quality.  All these activities are made possible by “helper” software , that gives the Web browser the capability to load and display or play files in special formats.  Examples include the Adobe PDF (Portable Document Format) reader, the Windows Media Player, and RealPlayer for playing video and audio content ,. What makes the browser even more versatile is the ability to load and run programs from Web sites ,.  Java was highly touted starting in the mid-1990s, and some observers believed that by making Web browsers into platforms capable of running any sort of software, there would be less need for proprietary operating systems such as Microsoft Windows",0,Human
165,"Thousands of real-time views of the world are available on the Web.  These include everything from the prosaic (a coffee machine at MIT) to the international (a view of downtown Paris or Tokyo) to the sublime (a Rocky Mountain sunset).  All of these views are made possible thanks to the availability of inexpensive digital cameras ,. To create a basic webcam, the user connects a digital camera to a PC, usually via a USB cable.  A program controls the camera, taking a picture at frequent intervals (perhaps every 30 seconds or minute).  The picture is received from the camera as a JPG (JPEG) file.  The program then uploads the picture to the user’s Web page (usually using file transfer protocol, or ftp), replacing the previous picture.  Users connected to the Web site can click to see the latest picture.  Alternatively, a script running on the server can update the picture automatically. ",0,Human
166,"The Web filter examines requests made by a Web user , and blocks those associated with sites deemed by the filter user to be objectionable.  There are two basic mechanisms for determining whether a site is unsuitable.  The first is to check the site’s address (URL) against a list and reject a request for any site on the list.  (Most filter programs come with default lists; the filter user can add other sites as desired.  Generally, the filter is installed with a password so only the authorized user [such as a parent] can change the filter’s behavior. )The other filtering method relies on a list of keywords associated with objectionable activities (such as pornography).  When the user requests a site, the filter checks the page for words on the keyword list.  If a matching word or phrase is found, the site is blocked and not shown to the user. ",0,Human
167,"There are many online services (including some free ones) that will provide users with personal Web pages.  There are also programs such as Microsoft FrontPage that allow users to design Web pages by arranging objects visually on the screen and setting their properties.  However, creating and maintaining a complete Web site with its many linked pages, interactive forms and interfaces to databases and other services is a complicated affair.  For most moderate to large-size organizations, it requires the services of a new category of IT professional: the webmaster",0,Human
168,"understanding how the Web site responds to and manages requests ,, fluency in the basic formatting of text and other page content and the use of frames and other tools for organizing and presenting text ,, extended formatting and content organization facilities such as Cascading Style Sheets (CSS), Dynamic HTML (DHTML), and Extensible Markup Language ,, use of graphics formats and graphics and animation programs (such as Photoshop, Flash, and DreamWeaver), extending the interactivity of Web pages through writing scripts using tools such as JavaScript and PHP ,, dealing with platform and compatibility issues, including browser compatibility",0,Human
169,"When a user types in (or clicks on) a link in the browser window, the browser sends a HTTP request ,.  To construct the request, the browser first looks at the address (URL) in the user request.  An address such as http://www. well. com/conferencing. html consists of three parts In order to direct the browser’s request to the appropriate host and server, the browser sends the URL to a name server ,.  The name server provides the appropriate numeric IP address ,.  The browser then sends an HTTP “get” request to the server’s IP address. Assuming the page requested is valid, the server sends the HTML file to the browser.  The browser in turn interprets the formatting and display instructions in the HTML file and “renders” the text and graphics appropriately.  It is remarkable that this whole process from user click to displayed page usually takes only a few seconds, even if the Web site is thousands of miles away and requests must be relayed through many intervening computers",0,Human
170,"There are several ways in which Web services can be accessed:, Remote Procedure Call (RPC), which generally uses WSDL and follows a format similar to the traditional way programs call upon library functions, An organization based on the available messages rather than calls or operations ,, Representational State Transfer (REST), which views applications or services as collections of “resources” with specific addresses (URLs) and specific requests using HTTPA variety of other specifications and approaches can be used; this area is a very fluid one.  Fortunately, programmers and even users , can build new Web applications without having to know the details of how the underlying services work. ",0,Human
171,"Wiki software varies in details such as use of markup languages, programming interface, and platform.  However, most wikis include the following features:, Users can create new pages (articles) or edit existing ones. , Pages contain links to related pages, sometimes using “wiki words” where WordsAreScrunchedTogetherWithIntialCaps. , Simple markup can be used to create such effects as boldface, headings, or lists.  The wiki software usually translates this to HTML for rendering. , A record is kept of each contribution or edit, often displayed on a “Recent Changes” page. ,? Many wikis use a database (such as MySQL) to store and retrieve pages.  Some wikis simply store each page as a file, and a few (such as TiddlyWiki) store all pages together as a single document. , Wikis can be public (open to anyone) or restricted, such as to members of an organization. , The administrator of the wiki establishes guidelines or standards (such as for citing sources for facts) and procedures for dealing with disputes and controversial topics",0,Human
172,"Typically, a wireless LAN uses a frequency band with each unit on a slightly different frequency, thus allowing all units to communicate without interference.  (Although radio frequency is now most popular, wireless LANs can also use microwave links, which are sometimes used as an alternative to Ethernet cable in large facilities. )Usually there is a network access point, a PC that contains a transceiver and serves as the network hub (it may also serve as a bridge between the wireless network and a wired LAN).  The hub computer can also be connected to a high-speed Internet service via DSL or cable.  It has an antenna allowing it to communicate with wireless PCs up to several hundred feet away, depending on building configuration. Each computer on the wireless network has an adapter with a transceiver so it can communicate with the access point.  The adapter can be built-in (as is the case with some handheld computers), or mounted on a PC card (for laptops) or an ISA card (for desktop PCs) or connected to a USB port. ",0,Human
173,"The term word processor was actually coined by IBMin the 1960s to refer to a system consisting of a Selectric typewriter with magnetic tape storage.  This allowed the typist to record keystrokes (and some data such as margin settings) on tape.  Material could be corrected by being rerecorded.  The tape could then be used to print as many perfect copies of the document as required.  A version using magnetic cards instead of tape appeared in 1969. The first modern-style word processor was marketed by Lexitron and Linolex.  It also used magnetic tape, but it added a video display screen.  Now the writer could see and correct text without having to print it first.  A few years later, a new invention, the floppy disk, became the standard storage medium for dedicated word processing systems. The word-processing systems developed by Wang, Digital Equipment Corporation, Data General, and others became a feature in large offices in the late 1970s.  These systems were essentially minicomputers with screens, keyboards, and printers and running a specialized software program.  Because these systems were expensive (ranging from about $8,000 to $20,000 or more), they were not affordable by smaller businesses.  Typically, they were operated by specially trained personnel (who became known also as “word processors”) to whom documents were funneled for processing, as with the old “typing poo",0,Human
174,"Some typical features today include:, different views of the document, including an outline showing headings down to a user-specified level, automatic table of contents and index generation, tables and multicolumn text, automatic formatting of bulleted and numbered lists, built-in and user-defined styles for headings, paragraphs, and so on. , the ability to use built-in or user-defined templates to provide starting settings for new documents ,, the ability to record or otherwise specify a series of commands to be performed automatically ,, spelling and grammar checkers, the ability to incorporate a variety of graphics image formats in the document, automatic formatting and linking of Web hyperlinks within documents, the ability to import and export documents in a variety of formats, including Web documents ",0,Human
175,"Zuse was born on June 22, 1910, in Berlin.  He stud-ied civil engineering at the Technische Hochschule Berlin-Charlottenburg, receiving his degree in 1935.  One of histasks in engineering was performing calculations of thestress on structures such as bridges.  At the time these cal-culations were carried out by going through a series of stepson a form over and over again, plugging in the data andcalculating by hand or using an electromechanical calcula-tor.  Like other inventors before him, Zuse began to wonderwhether he could build a machine that could carry outthese repetitive steps automatically.  departing from other calculator designers). The Z1 had trouble storing and retrieving numbers andnever worked well.  Undeterred, Zuse began to develop anew machine that used electromechanical telephone relays(a ubiquitous component that was also favored by HowardAiken [see Aiken, Howard]).  The new machine workedmuch better, and Zuse successfully demonstrated it at theGerman Aerodynamics Research Institute in 1939. With World War II under way, Zuse was able to obtainfunding for his Z3, which was able to carry out automaticsequences from instructions. Zuseused spare time from his military duties at the Henschelaircraft company to work on the Z4, which was completedin 1949. ",0,Human
176,"Since the late 1990s, Web users (particularly younger ones)have been adept at sharing media content online ,.  In the 2000 decade, however,the emphasis has shifted to users not merely sharing otherpeoples’ content, but creating their own ,.  The first part of the recipe was the availability ofubiquitous digital cameras and camcorders; the second partwas easy-to-use video-editing software; and the third partwas a Web site that could host the results. Created in 2005 by three former PayPal employees, thevideo-sharing site YouTube has been the leading venue foramateur video.  Although available content includes clipsfrom movies and TV shows (some unauthorized), much ofthe most interesting content is original videos created anduploaded by users.  Beyond just sharing or accessing con-tent, users are encouraged to rate and comment on the vid-eos they see, and users can also subscribe to “feeds” of newmaterial that is likely to be of interest to them. By 2008 more than 83 million videos were available onYouTube—and hundreds of thousands added each day. ",0,Human
177,"YouTube broke into the highly visual field ofpolitical advertising.  Most candidates in the 2008 presiden-tial primaries have put their statements and other videos onYouTube. ups).  Political commentators and journalists have also beenactive in putting their opinions on YouTube (or comment-ing on those of others).  Perhaps the political establishment’sbiggest nod to YouTube is the series of debates cosponsoredby CNN and YouTube, bringing together the Republicanand Democratic primary fields. YouTube has had its share of criticism: Critics havecharged the service with not sufficiently policing copyrightviolations and violent content (including videos of fightsor bullying in schools), as well as neo-Nazi propaganda,scenes of animal abuse, and videos by anti-American insur-gent groups, as well as generally tasteless exhibitionism.  Afew countries and some schools have responded by block-ing access to the service. ",0,Human
178,"Yahoo!has played an importantrole in the development of Web services.  In 1994 Stan-ford students Jerry Yang and David Filo developed the firstpopular directory of Web sites.  Realizing thatthe millions of Web users flocking to their site provided anopportunity for advertising and services, the two partnersincorporated Yahoo! in 1995. Yahoo! continued to grow, and the company acquireda number of other online services, which they used to pro-vide Web-based e-mail, Web hosting, and news.  But havingflown so high, Yahoo! had far to fall when the dot-com mar-ket bubble burst in 2001: A stock that had traded at around$130. 00 per share fell as low as $4. 06. However, Yahoo! proved its resilience as one of the fewearly dot-coms to survive and has continued to thrive inthe post-bubble era since 2002.  The company made strate-gic partnerships with telecommunications companies suchas BT and Verizon.  Yahoo! entered a continuing strugglewith another Web services powerhouse , whileacquiring new media sites (such as the photo-sharing ser-vice Flickr and the social “bookmarking” service del. icio. us), and creating new services ,.  Yahoo! also provides onlinestorefronts, competing in that venue mainly with eBay. ",0,Human
179,"Computers and technology play a role in the lives of mostyoung people that many adults have difficulty compre-hending.  Children in industrialized countries are liable toencounter video games even before they arrive at school. Once there, they will be exposed to a considerable amountof educational software, depending on their school’s afflu-ence ,.  Upon returningfrom school, there are more sophisticated games, MySpacepages to keep updated ,, sophisti-cated tools for creating music and video, and, of course, theInternet in all its vast diversity.  Meanwhile, a web of inces-sant messages , islikely to keep the youngster in touch with friends. ",0,Human
180,"In recent years there has been growing concern that Internet users  may  eventually  be  treated  differently  by  service  pro-viders  depending  on  the  kind  of  data  they  download  or  the kind  of  application  programs  they  use  online.   Advocates  of network (or net) neutrality , want legislation that would bar cable, DSL, or other provid-ers , from making  such  distinctions,  such  as  by  charging  content  pro-viders higher fees for high volumes of data or even blocking certain applications.  Advocates of net neutrality believe that, since there are rather limited choices for broadband Internet service,  discrimination  on  the  basis  of  Web  content  could lead to a loss of freedom for consumers and providers alike. ",0,Human
181,"NLP is a multidisciplinary field that draws from linguis-tics and computer science, particularly artificial intelligence ,.  In terms of linguistics, a program must be able to deal with words that have multiple mean-ings (“wind up the clock” and “the wind is cold today”) as well as grammatical ambiguities (in the phrase “little girl’s school” is it the school that is little, the girls, or both?).  Of course each language has its own forms of ambiguity. Programs can use several strategies for dealing with these problems, including using statistical models to predict the likely meaning of a given phrase based on a “corpus” of existing text in that language ,. As formidable as the task of extracting the correct (lit-eral) meaning from text can be, it is really only the first level of natural language processing.  If a program is to success-fully summarize or draw conclusions about a news report from North Korea, for example, it would also have to have a knowledge base of facts about that country and/or a set of “frames” , about how to interpret vari-ous situations such as threat, bluff, or compromise. )",0,Human
182,"Users of modern operating systems such as microsoft Win-dows are familiar with multitasking, or running several programs at the same time.  For example, a user might be writing a document in a word processor, pause to check the e-mail program for incoming messages, type a page address int o a Web browser, then return to writing.  meanwhile, the operating system may be running a number of other pro-grams tucked unobtrusively into the background, such as a virus checker, task scheduler, or system resource monitor. Each running program “takes turns” using the PC’s cen-tral processor.  In early versions of Windows, multitasking was cooperative, with each program expected to periodically yield the processor to Windows so it could be assigned to the next program in the queue.  One weakness of this approach is that if a program crashes, the CPU might be “locked up” and the system would have to be rebooted.  However, Win-dows NT, 2000, and xP (as well as operating systems such as UNIx) use preemptive multitasking.  The operating sys-tem assigns a “slice” of processing (CPU) time to a program and then switches it to the next program regardless of what might be happening to the previous program.  Thus, if a pro-gram  “crashes,”  the  CPU  will  still  be  switched  to  the  next program,  and  the  user  can  maintain  control  of  the  system and shut down the offending program. ",0,Human
183,"Microsoft . NET is a programming platform , that is intended to pro-vide a clear and consistent way for applications written in a variety of languages such as C++, C#, and Visual Basic to access Windows functions and to interact with other programs and services on the same machine or over the Internet. . NET consists of the following main parts:, Base Class Library of data types and common func-tions (such as file manipulation and graphics) that is available to all . NET languages, Common Language Runtime, which provides the code that applications need to run within the operat-ing system, manage memory, and so forth (“Common language” means it can be used for any . NET pro-gramming language. ), ASP . NET, a class framework for building dynamic Web applications and services (the latest version of ASP—see activeseRveRpages), ADO . NET, a class framework that allows programs to access databases and data services",0,Human
184,"Whatever memory chips or other devices are installed in a computer,  the  operating  system  and  application  programs must  have  a  way  to  allocate,  use,  and  eventually  release portions of memory.  The goal of memory management is to use available memory most efficiently.  This can be difficult in  modern  operating  environments  where  dozens  of  pro-grams may be competing for memory resources. Early  computers  were  generally  able  to  run  only  one program at a time.  These machines didn’t have a true oper-ating  system,  just  a  small  loader  program  that  loaded  the application  program,  which  essentially  took  over  control of the machine and accessed and manipulated the memory.  Later systems offered the ability to break main memory into several  fixed  partitions.   While  this  allowed  more  than  one program to run at the same time, it wasn’t very flexible. ",0,Human
185,"If  computers  were  merely  fast  sequential  calculators,  they would still be of some use.  However, much of the power of the  computer  comes  from  its  ability  to  carry  out  repetitive tasks  without  supervision.   The loop  is  the  programming language  structure  that  controls  such  activities.   Virtually every language has some form of loop construct, with vari-ations  in  syntax  ranging  from  the  relatively  English-like COBOL  and  Pascal  to  the  more  cryptic  C. ",0,Human
186,"Starting in the 1980s, many organizations sought to connect their  employees’  desktop  computers  so  they  could  share central  databases,  share  or  back  up  files,  communicate  via e-mail,  and  collaborate  on  projects.   A  system  that  links computers  within  a  single  office  or  home,  or  a  larger  area such as a building or campus, is called a local area network (LAN).   (Larger  networks  linking  branches  of  an  organiza-tion  throughout  the  country  or  world  are  called  wide  area networks, or WANs.  See netWoRk. )",0,Human
187,"Naturally  there  must  be  software  to  manage  the  transmis-sion and reception of data packets.  The structure of a packet (sometimes  called  a frame)  has  been  standardized  with  a preamble, source and destination addresses, the data itself, a  checksum,  and  two  special  layers  that  interface  with  the differing ways that Ethernet and token ring networks physi-cally handle the packets. ",0,Human
188,"A list is a series of data items that can be accessed sequen-tially  by  following  links  from  one  item  to  the  next.   Lists can be very useful for ordering or sorting data items and for storing them on a stack or queue. There  are  two  general  approaches  to  constructing  lists.  In a data list used with procedural programming languages such  as  C,  each  list  item  consists  of  a  structure  consisting of a data member and a pointer.  The pointer, called “next,” contains the address of the next item.  A program can easily “step through” a list by starting with the first item, process-ing  its  data,  then  using  the  pointer  to  move  to  the  next item,  continuing  until  some  condition  is  met  or  the  end  of the list is reached. ",0,Human
189,"Lists are generally used to provide convenient access to rel-atively  small  amounts  of  data  where  flexibility  is  required.  Unlike an array, a list need use only as much memory as it needs to accommodate the current number of items (includ-ing their associated pointers).  A LISP-style node list can be even  more  flexible  in  that  items  with  varying  sizes  and types of data can be included in the same list.  Lists are thus a  more  flexible  way  to  implement  such  things  as  look-up tables. ",0,Human
190,"Linux  is  an  increasingly  popular  alternative  to  proprietary operating systems.  Its development sprang from two sources.  First was the creation of open-source versions of UNIx utili-ties  ,  by  maverick  programmer  Richard  Stallman as  part  of  the gNU  (“gnu’s  not  UNIx”)  project  during  the 1980s.  Although these tools were useful, the kernel, or basic set of operating system functions, was still missing ,.   Starting  in  1991,  another  creative  programmer,  Linus Torvalds, began to release open-source versions of the UNIx kernel  ,.   The  combination  of  the  ker-nel  and  utilities  became  known  as  Linux  (a  combination of Linus  and  UNIx),  though  Stallman  and  his  supporters believe that gNU/Linux is a more accurate name. ",0,Human
191,"The  idea  behind  an  operating  system  kernel  is  that  there is  a  relatively  small  core  set  of  “primitive”  functions  that are necessary for the operation of system services ,.   These  functions  can  be  provided  in  a single component that can be adapted and updated as desir-able.  The fundamental services include:,    Process control—scheduling  how  the  processes  (pro-grams or threads of execution within programs) share the CPU, switching execution between processes, cre-ating  new  processes,  and  terminating  existing  ones ,. ,      Interprocess   communication—sending   “messages” between  processes  enabling  them  to  share  data  or coordinate their data processing. ,      memory   management—allocating   and   freeing   up memory  as  requested  by  processes  as  well  as  imple-menting  virtual  memory,  where  physical  storage  is treated as an extension of main (RAm) memory.  (See memoRymanagement. ),    File  system  services—creating,  opening,  reading  from, writing to, closing, and deleting files",0,Human
192,"JavaScript  is  one  of  several  popular  languages  that  can enable  Web  pages  to  interact  with  users  more  quickly  and efficiently ,.  The  language  first  appeared  in  the  mid-1990s’  Netscape  2 browser under the name LiveScript.  Technically, JavaScript is  the  Sun microsystems  trademark  for  its  implementation of  a  standard  called  ECmAScript.   Despite  the  name,  Java-Script  is  not  directly  related  to  the  Java  programming  lan-guage. In  its  early  years  JavaScript  was  perhaps  a  victim  of  its own  success.   Having  a  relatively  easy-to-use  scripting  lan-guage  provided  an  easier  way  to  add  features  such  as  3D buttons  and  pop-up  windows  to  formerly  humdrum  Web forms.   However,  as  with  an  earlier  generation’s  fondness for multiple fonts, early JavaScript programmers were often prone  to  add  unnecessary  and  confusing  clutter  to  Web pages.   Besides  sometimes  annoying  users,  early  JavaScript also  suffered  from  significant  differences  in  how  it  was implemented  by  the  major  browsers.   As  a  result,  Netscape users  were  sometimes  stymied  by  JavaScript  written  for micr  osoft Internet Explorer, and vice versa.  Finally, browser flaws have sometimes allowed JavaScript to be used to com-promise  security  such  as  by  installing  malware-infested “browser helpers. ” As a result, many security experts began to  recommend  that  users  disable  JavaScript  execution  in their browsers. ",0,Human
193,"Java  has  largely  fulfilled  this  promise  for  Web  developers.  C++  programmers  have  an  easy  learning  curve  to  Java, since  the  two  languages  have  very  similar  syntax  and  a similar use of classes and other object-oriented features.  On the  other  hand,  programmers  who  don’t  know  C++  benefit from  Java  being  more  streamlined  than  C++.   For  example, Java avoids the necessity to use pointers ,  and  uses  classes  as  the  consistent  building block of program structure.  Software powerhouses such as microsoft (until recently) and IBm have joined Sun in pro-moting Java. Another  much-touted  feature  of  Java  is  its  platform independence.  The language itself is separate from the vari-ous  operating  system  platforms.   For  each  platform,  a  Java Vir tual machine ( JVm) is created, which interprets or com-piles the code generated by the Java compiler so it can run on that platform. For  security,  Java  applets  run  within  a  “sandbox”  or restricted  environment  so  the  user  is  protected  from  mali-cious   Java   programs.    (For   example,   programs   are   not allowed  to  access  the  user’s  disk  or  to  connect  the  user’s machine to another Web site. ) Web browsers can also be set to disable the running of Java applets. ",0,Human
194,"Java  is  a  computer  language  similar  in  structure  to  C++.  Although Java is a general-purpose programming language, it is most often used for creating applications to run on the Internet,  such  as  Web  servers.   A  special  type  of  Java  pro-gram called an applet can be linked into Web pages and run on the user’s Web browser ,. As  an  object-oriented  language,  Java  uses  classes  that provide commonly needed functions including the creation of user interface objects such as windows and buttons ,.   A  variety  of sets  of  classes  (“class  frameworks”)  are  available,  such  as the AWT (Abstract Windowing Toolkit). ",0,Human
195,"An interpreter is a program that analyzes (parses) program-ming commands or statements in a high-level language ,,  creates  equivalent  executable instructions in machine code , and executes them.  An interpreter differs from a compiler in that the lat-ter converts the entire program to an executable file rather than processing and executing it a statement at a time . many  earlier  versions  of  the  BASIC  programming  lan-guage  were  implemented  as  interpreters.   Since  an  inter-preter only has to hold one program statement at a time in memory, it could run on early microcomputers that had only a  few  tens  of  thousands  of  bytes  of  system  memory.   How-ever,  interpreters  run  programs  considerably  more  slowly than a compiled program would run.  One reason is that an interpreter “throws away” each source code statement after it  interprets  it.   This  means  that  if  a  statement  runs  repeat-edly ,, it must be re-interpreted each time it runs.  A  compiler,  on  the  other  hand,  would  create  only  one  set of  machine  code  instructions  for  the  loop  and  then  move on.   Also,  because  a  compiler  keeps  the  entire  program  in memory,  it  can  analyze  the  relationship  between  multiple statements  and  recognize  ways  to  rearrange  or  substitute them for greater efficiency. ",0,Human
196,"An  Internet  service  provider  is  any  organization  that  pro-vides  access  to  the  Internet.   While  nonprofit  organiza-tions  such  as  universities  and  government  agencies  can  be Internet service provider       considered  to  be  ISPs,  the  term  is  generally  applied  to  a commercial, fee-based service. Typically, a user is given an account that is accessed by logging in through the operating system’s Internet connec-tion facility by supplying a user ID and password.  Once con-nected, the user can run Web browsers, e-mail clients, and other programs that are designed to work with an Internet connection.  most  ISPs  now  charge  flat  monthly  fees  rang-ing  from  $20  or  so  for  dial-up  access  to  around  $40–$60 for  high-speed  cable  or  DSL  connections  ,.  Some  services  such  as  America  Online  and  CompuServe include  ISP  service  as  part  of  a  package  that  also  includes such  features  as  software  libraries,  discussion  forums,  and instant messaging.  Online services tend to be more expen-sive than “no frills” ISP services",0,Human
197,"Internet  radio  is  the  provision  of  radio  broadcast  content over  the  Internet  ,.   Basically,  the  digitized sound  files  of  the  broadcasts  can  be  accessed  and  played using  widely  available  software  such  as  Windows media Player or RealPlayer.  Internet radio began in the mid-1990s, and  today  an  increasing  number  of  broadcast  stations  are offering their programming in this form, allowing them to reach  audiences  far  beyond  the  reach  of  their  signal.   Some stations  stream  live  (during  the  actual  broadcast),  while others  make  programs  available  for  download.   (For  auto-matic  downloading  of  broadcasts,  see podcasting).   There are also “radio stations” that provide their content only via the  Internet.   Internet  radio  should  not  be  confused  with satellite or cable radio, which carry conventional radio sig-nals in real time. ",0,Human
198,"The  growth  of  the  Internet  and  its  centrality  in  business, education,  and  other  fields  has  led  many  programmers to  specialize  in  Internet-related  applications.   These  can include the following:,    low-level infrastructure  (networking  [wired  and  wire-less], routing, encryption support, and so on),    Web servers and related software,      e-commerce infrastructure ,,      interfacing with databases,      data analysis and extraction ,,      support for searching ,,      autonomous  software  to  navigate  the  net  ,,      Internet-based  communications  ,,      systems  to  deliver  text  and  media  ,,      support  for  collaborative  use  of  the  Internet  ,,      security software (firewalls, intrusion analysis, etc. )",0,Human
199,"   Netnews  (also  called  Usenet,  for  UNIx  User  Net-work)  is  in  effect  the  world’s  largest  computer  bul-letin  board.   It  began  in  1979,  when  Duke  University and the University of North Carolina set up a simple mechanism for “posting” text files that could be read by  other  users.   Today  there  are  tens  of  thousands  of topical “newsgroups” and millions of messages (called articles).   Although  still  impressive  in  its  quantity  of content,  many  Web  users  now  rely  more  on  discus-sion  forums  based  on  Web  pages  ,. ",0,Human
200,"    Ftp  (File  Transport  Protocol)  enables  the  transfer  of one  or  more  files  between  any  two  machines  con-nected  to  the  Internet.   This  method  of  file  transfer has  been  largely  supplanted  by  the  use  of  download links  on  Web  pages,  except  for  high-volume  applica-tions  (where  an  ftp  server  is  often  operated  “behind the  scenes”  of  a  Web  link).   FTP  is  also  used  by  Web developers  to  upload  file",0,Human
201,"   Telnet  is  another  fundamental  service  that  brought the  Internet  much  of  its  early  utility.   Telnet  allows  a user at one computer to log into another machine and run a program there.  This provided an early means for users  at  PCs  or  workstations  to,  for  example,  access the  Library  of  Congress  catalog  online.   However,  if program  and  file  permissions  are  not  set  properly  on the  “host”  system,  telnet  can  cause  security  vulner-abilities.   The  telnet  user  is  also  vulnerable  to  having IDs and passwords stolen, since these are transmitted as  clear  (unencrypted)  text.   As  a  result,  some  online sites  that  once  supported  telnet  access  now  limit access to Web-based forms.  (Another alternative is to use a program called “secure shell” or ssh, or to use a telnet client that supports encryption. )",0,Human
202,"  WAIS  (Wide  Area  Information  Service)  is  a  gateway that  allows  databases  to  be  searched  over  the  Inter-net.   WAIS  provided  a  relatively  easy  way  to  bring large  data  resources  online.   It,  too,  has  largely  been replaced by Web-based database services. ",0,Human
203,"The Internet is the worldwide network of all computers (or networks of computers) that communicate using a particu-lar protocol for routing data from one computer to another ,.   As  long  as  the  programs  they  run  follow  the rules  of  the  protocol,  the  computers  can  be  connected  by a variety of physical means including ordinary and special phone  lines,  cable,  fiber  optics,  and  even  wireless  or  satel-lite transmission. ",0,Human
204,"Internationalization  and  localization  are  ways  to  adapt computer  software  (often  created  in  the  United  States  or Europe) to other languages and cultures.  The abbreviations I18n and L10n are sometimes used for internationalization and  localization,  respectively  (the  numbers  in  each  word refer  to  the  number  of  letters  in  the  alphabet  between  the letters).  The two processes are complementary. ",0,Human
205,"By  the  mid-2000  decade,  the  biggest  intellectual  property battles  were  not  about  esoteric  program  codes  but  rather revolved around how to satisfy the ordinary home consum-er’s  appetite  for  music  and  video  while  preserving  produc-ers’  revenues.   Increasingly,  music  and  even  video  is  being downloaded rather than being bought in commercial pack-aging at the local store. In  the Sony  v.   Universal  case  (1984)  the  Supreme  Court ruled  that  manufacturers  of  devices  such  as  VCRs  were not  liable  for  their  misuse  if  there  were  “substantial  non-infringing uses”—such as someone making a copy of legally possessed  media  for  their  own  use.   However,  in  2005  the Supreme  Court  ruled  that grokster,  a  decentralized  file-sharing service, could be held liable for the distribution of illegally copied media if it “actively induced” such copying. By   2006   media   industry   lobbyists   (particularly   the Recording  Industry  Institute  of  America,  or  RIAA)  were promoting  a  number  of  bills  in  Congress  that  would  fur-ther  restrict  consumers’  rights  to  use  media.   Such  mea-sures might include requiring that devices be able to detect “flagged”  media  and  refuse  to  copy  it  ,,  as  well  as  adding  stricter  provisions  to  the Digital millennium  Copyright  Act  (DmCA).   These  mea-sures  are  opposed  by  cyber-libertarian  groups  such  as  the Electronic Frontier Foundation and consumer groups such as the Home Recording Rights Coalition. ",0,Human
206,"Intellectual  property  can  be  defined  as  the  rights  the  cre-ator  of  an  original  work  (such  as  an  invention  or  a  book) has  to  control  its  reproduction  or  use.   Developers  of  new computer  hardware,  software,  and  media  content  must  be able to realize a return on their time and effort.  This return is threatened by the ease with which programs and data on disks can be illicitly copied and redistributed.  Several legal mechanisms can be used to deter such behavior. ",0,Human
207,"Information theory is the study of the fundamental charac-teristics of information and its transmission and reception.  As  a  discipline,  information  theory  took  its  impetus  from the ideas of Claude Shannon ,. In  his  seminal  paper  “A mathematical  Theory  of  Com-munication”  published  in  the Bell  System  Technical  Journalin 1948, Shannon analyzed the redundancy inherent in any form  of  communication  other  than  a  series  of  purely  ran-dom  numbers.   Because  of  this  redundancy,  the  amount  of information  (expressed  in  binary  bits)  needed  to  convey  a message  will  be  less  than  the  number  in  the  original  mes-sage.   It  is  because  of  redundancy  that  data  compression algorithms can be applied to text, graphics, and other types of  files  to  be  stored  on  disk  or  transmitted  over  a  network ",0,Human
208,"While  much  attention  is  paid  by  system  designers  to  the representation, storage and manipulation of information in the computer, the ultimate value of information processing software is determined by how well it provides for the effec-tive retrieval of that information.  The quality of retrieval is dependent  on  several  factors:  hardware,  data  organization, search algorithms, and user interface. ",0,Human
209,"Image  processing  is  a  general  term  for  the  manipulation of  a  digitized  image  to  produce  an  enhanced  or  more  con-venient  version.   Some  of  the  earliest  applications  were  in the military (aerial and, later, satellite reconnaissance) and in  the  space  program.   The  military  and  space  programs had a great need for extracting as much useful information as  possible  from  images  that  were  often  gathered  under extreme or marginal conditions.  They also needed to make cameras  and  other  hardware  components  simultaneously more  compact  and  more  efficient,  and  generally  had  the funds to pay for such specialized developments. Once  developed,  higher-quality  image  processing  sys-tems found their way into other applications such as domes-tic  surveillance  and  medical  imaging.   The  development  of cameras that could directly turn light into digitized images , made image processing seam-less by avoiding the necessity of scanning images from tra-ditional film. Image  processing  applications  can  be  divided  into three general categories: enhancement, interpretation, and maintenance. ",0,Human
210,"Starting  in  the  late  1950s,  in  computer  facilities  at mIT, Stanford,  and  other  research  universities  people  began  to encounter  persons  who  had  both  unusual  programming skill  and  an  obsession  with  the  inner  workings  of  the machine.   While  ordinary  users  viewed  the  computer  sim-ply  as  a  tool  for  solving  particular  problems,  this  peculiar breed of programmers reveled in extending the capabilities of  the  system  and  creating  tools  such  as  program  editors that  would  make  it  easier  to  create  even  more  powerful programs.  The movement from mainframes that could run only one program at a time to machines that could simulta-neously  serve  many  users  created  a  kind  of  environmental niche  in  which  these  self-described hackers  could  flourish.  Indeed,  while  administrators  sometimes  complained  that hackers  took  up  too  much  of  the  available  computer  time, they  often  depended  on  them  to  fix  the  bugs  that  infested the  first  versions  of  time-sharing  operating  systems.   Hack-ers also tended to work in the wee hours of the night while normal users slept. ",0,Human
211,"The base 16 or hexadecimal system is a natural way to rep-resent the binary data stored in a computer.  It is more com-pact than binary because four binary digits can be replaced by a single “hex” digit. The  following  table  gives  the  corresponding  decimal, binary, and hex values from 0 to 15:Note that decimal and hex digits are the same from 0 to 9,  but  hex  uses  the  letters  A–F  to  represent  the  digits  cor-responding to decimal 10–15.  The system extends to higher numbers  using  increasing  powers  of  16,  just  as  decimal uses  powers  of  10:  For  example,  hex  FF  represents  binary 111  11111 or decimal 255.  many of the apparently arbitrary numbers encountered in programming can be better under-stood  if  one  realizes  that  they  correspond  to  convenient groupings of bits: FF is eight bits, sufficient to hold a single character ,.  In low-level pro-gramming memory addresses are also usually given in hex ",0,Human
212,"In  operating  systems  and  certain  programming  languages (such as LISP), a heap is a pool of memory resources avail-able  for  allocation  by  programs.   The  memory  segments (sometimes called cells) can be the same size or of variable size.   If  the  same  size,  they  are  linked  together  by  pointers ,.    memory is then allocated for a vari-able by traversing the list and setting the required number of  cells  to  be  “owned”  by  that  variable.   (While  some  lan-guages such as Pascal and C use explicit memory allocation or deallocation functions, other languages such as LISP use a separate runtime module that is not the responsibility of the programmer. )",0,Human
213,"In  the  early  days  of  computing,  the  programmers  of  a  sys-tem  tended  to  also  be  its  users  and  were  thus  intimately familiar  with  the  program’s  operation  and  command  set.  To search a hashed database, the hashing formula is first applied to the search key, yielding a hash value.  That value can then be used in a binary search to quickly zero in on the matching record, if any.         health, personalIf not a programmer, the user of a mainframe program was probably  at  least  a  well-trained  operator  who  could  work with  the  aid  of  a  brief  summary  or  notes  provided  by  the programmer.   However,  with  the  beginnings  of  office  auto-mation  in  the  1970s  and  the  growing  use  of  desktop  com-puters in office, home, and school in the 1980s, increasingly complex  programs  were  being  put  in  the  hands  of  users who  often  had  only  minimal  computer  training  ,. While  programs  often  came  with  one  or  more  tutorial or  reference  manuals,  designers  realized  that  offering  help through  the  program  itself  would  have  some  clear  advan-tages.  First, the user would not have to switch attention from the computer screen to look things up in a manual.  Second, the  help  system  could  be  programmed  to  not  only  provide information,  but  also  to  help  the  user  find  the  informa-tion needed in a given situation.  For example, related topics could be linked together and a searchable index provided",0,Human
214,"A hash  is  a  numeric  value  generated  by  applying  a  math-ematical  formula  to  the  numeric  values  of  the  characters in a string of text ,.  The for-mula is chosen so that the values it produces are always the same  length  (regardless  of  the  length  of  the  original  text) and  are  very  likely  to  be  unique.   (Two  different  strings should  not  produce  the  same  hash  value.   Such  an  event  is called a collision. )",0,Human
215,"The  two  major  application  areas  for  hashing  are  informa-tion  retrieval  and  cryptographic  certification.   In  databases, an index table can be built that contains the hash values for the key fields and the corresponding record number for each field,  with  the  entries  in  hash  value  order.   To  search  the database, an input key is hashed and the value is compared with  the  index  table  (which  can  be  done  using  a  very  fast binary search).  If the hash value is found, the corresponding record number is used to look up the record.  This tends to be much faster than searching an index file directly. ",0,Human
216,"Even  after  decades  of  evolution  in  computing,  the  hard disk  drive  remains  the  primary  means  of  fast  data  storage and  retrieval  in  computer  systems  of  all  sizes.   The  disk itself consists of a rigid aluminum alloy platter coated with a  magnetic  oxide  material.   The  platter  can  be  rotated  at speeds of more than 10,000 rpm.  A typical drive consists of a stack of such platters mounted on a rotating spindle, with a read/write head mounted above each platter. Early  hard  drive  heads  were  controlled  by  a  stepper motor, which positioned the head in response to a series of electrical pulses.  (This system is still used for floppy drives. ) Today’s hard drives, however, are controlled by a voice-coil actuator,  similar  in  structure  to  an  audio  speaker.   The  coil surrounds a magnet.  When a current enters the coil, it gen-erates a magnetic field that interacts with that of the perma-nent magnet, moving the coil and thus the disk head.  Unlike the stepper motor, the voice coil is continuously variable and its  greater  precision  allows  data  tracks  to  be  packed  more tightly on the platter surface, increasing disk capacity. The  storage  capacity  of  a  drive  is  determined  by  the number  of  platters  and  the  spacing  (and  thus  number)  of tracks  that  can  be  laid  down  on  each  platter.   Capacities have  steadily  increased  while  prices  have  plummeted:  In 1980,  for  example,  a  hard  drive  for  an  Apple  II  microcom-put  er cost more than $1,000 and held only 5 mB of data.  As of  2007  internal  hard  drives  with  a  capacity  of  500 gB  or more cost around a $150. 00. ",0,Human
217,"most interfaces between users and computer systems involve the  equivalent  of  switches—keyboard  keys  or  mouse  but-tons.   These  interfaces  cannot  respond  to  degrees  of  pres-sure (for an exception, see gRaphicstablet).  Further, there is  no  feedback  returned  to  the  user  through  the  interface device—the key or mouse does not “push back. ”Haptic (from the greek word for “touch”) interfaces are different in that they do register the pressure and motion of touch, and they often provide touch feedback as well. ",0,Human
218,"Some emerging or near-future uses of haptic technology include:One approach to handwriting recognition involves the extraction of a stroke pattern and its comparison to a database of templates rep-resenting various letters and symbols.  Ultimately the corresponding ASCII character is determined and stored. haptic interfaces ,      remote  surgery,  where  the  surgeon  can  feel  the  resis-tance of tissues and the location of anatomical features,      use of haptic technology to provide robots with more humanlike gripping capabilities,      3D sculpture in a virtual 3D world modeling the char-acteristics of different materials and tools",0,Human
219,"Starting  in  the  late  1950s,  in  computer  facilities  at mIT, Stanford,  and  other  research  universities  people  began  to encounter  persons  who  had  both  unusual  programming skill  and  an  obsession  with  the  inner  workings  of  the machine.   While  ordinary  users  viewed  the  computer  sim-ply  as  a  tool  for  solving  particular  problems,  this  peculiar breed of programmers reveled in extending the capabilities of  the  system  and  creating  tools  such  as  program  editors that  would  make  it  easier  to  create  even  more  powerful programs.  The movement from mainframes that could run only one program at a time to machines that could simulta-neously  serve  many  users  created  a  kind  of  environmental niche  in  which  these  self-described hackers  could  flourish.  Indeed,  while  administrators  sometimes  complained  that hackers  took  up  too  much  of  the  available  computer  time, they  often  depended  on  them  to  fix  the  bugs  that  infested the  first  versions  of  time-sharing  operating  systems.   Hack-ers also tended to work in the wee hours of the night while normal users slept. ",0,Human
220,"A  handwriting  recognition  system  begins  by  building a representation of the user’s writing.  With a pen or stylus system, this representation is not simply a graphical image but  includes  the  recorded  “strokes”  or  discrete  movements that  make  up  the  letters.   The  software  must  then  create  a representation  of  features  of  the  handwriting  that  can  be used  to  match  it  to  the  appropriate  character  templates.  Handwriting  recognition  is  actually  an  application  of  the larger problem of identifying the significance of features in a pattern. ",0,Human
221,"A  number  of  handheld  computers  beginning  with  Apple’s Newton in the mid-1990s and the now popular Palm devices and  BlackBerry  have  some  ability  to  recognize  handwrit-ing.   However,  current  systems  can  be  frustrating  to  use 0        handwriting recognitionbecause accuracy often requires that users write very care-fully  and  consistently  or  (as  in  the  case  of  the  Palm)  even replace their usual letter strokes with simplified alternatives that the computer can more easily recognize.  If the user is allowed  to  use  normal  strokes,  the  system  must  be  gradu-ally  “trained”  by  the  user  giving  writing  samples  and  con-firming the system’s guess about the letters.  As the software becomes  more  adaptable  and  processing  power  increases (allowing  more  sophisticated  algorithms  or  larger  neural networks  to  be  practical)  users  will  be  able  to  write  more naturally and systems will gain more consumer acceptance.  (One step in this direction is the Tablet PC, a notepad-sized computer with a digitizer tablet and a stylus and handwrit-ing recognitions  software,  included  in  Windows xP  and expanded  in  Windows  Vista.   Programs  such  as microsoft OneNote  use  handwriting  recognition  to  allow  users  to incorporate  handwritten  text  into  notes  that  can  be  orga-nized and quickly retrieved. )Currently,  handwriting  recognition  is  used  mainly  in niche  applications,  such  as  collecting  signatures  for  deliv-ery services or filling out “electronic forms” in applications where  the  user  must  be  mobile  and  relatively  hands-free",0,Human
222,"game  consoles  are  computer  devices  dedicated  to  (or  pri-marily  used  for)  playing  video  games.   The  earliest  such devices  appeared  in  the  1970s  from magnavox  and  then Atari, and could only play simple games like Pong (a crude simulation  of  ping-pong).   Slightly  later  systems  began  to feature cartridges that allowed them to play a greater vari-ety of games. ",0,Human
223,"The  normal  method  for  getting  a  computer  to  perform  a task  is  to  specify  the  task  clearly,  choose  the  appropriate approach  ,,  and  then  implement  and  test the  code.   However,  this  approach  requires  that  the  pro-grammer  first  know  the  appropriate  approach,  and  even when there are many potentially suitable algorithms, it isn’t always clear which will prove optimal. ",0,Human
224,"Variations of genetic algorithms or “evolutionary program-ming” have been used for many applications.  In engineering development, a virtual environment can be set up in which a  simulated  device  such  as  a  robot  arm  can  be  allowed  to evolve  until  it  is  able  to  perform  to  acceptable  specifica-tions.  (NASA has also used genetic programs competing on 80 computers to design a space antenna. ) Different versions of an expert system program can be allowed to compete at performing  tasks  such  as  predicting  the  behavior  of  finan-cial markets.  Finally, a genetic program is a natural way to simulate  actual  biological  evolution  and  behavior  in  fields such as epidemiology",0,Human
225,"A  genetic  program  consists  of  a  number  of  copies  of  a routine  that  contain  encoded  “genes”  that  represent  ele-ments  of  algorithms.   The  routines  are  given  a  task  (such as  sorting  data  or  recognizing  patterns)  and  the  most  suc-cessful  routines  are  allowed  to  “reproduce”  by  exchanging genetic  material.   (Often,  further  “mutation”  or  variation  is introduced  at  this  stage,  to  increase  the  range  of  available solutions. )  The  new  “generation”  is  then  allowed  to  tackle the  problem,  and  the  process  is  repeated.   As  a  result,  the routines  become  increasingly  efficient  at  solving  the  given problem, just as organisms in nature become more perfectly adapted to a given environment. ",0,Human
226,"Bill  gates  built microsoft,  the  dominant  company  in  the computer software field and in doing so, became the world’s wealthiest  individual,  with  a  net  worth  measured  in  the tens  of  billions.   Born  on  October  28,  1955,  to  a  successful professional  couple  in  Seattle, gates’s  teenage  years  coin-cided  with  the  first  microprocessors  becoming  available  to electronics hobbyists. gates showed both technical and business talent as early as age 15, when he developed a computerized traffic-control system.   He  sold  his  invention  for  $20,000,  then  dropped out  of  high  school  to  work  as  a  programmer  for  TRW  for the very  respectable  salary  of  $30,000.   By  age  20, gates had  returned  to  his  schooling  and  become  a  freshman  at Harvard, but then he saw a cover article in Popular Electron-ics.   The  story  introduced  the  Altair,  the  first  commercially available microcomputer kit. ",0,Human
227,"geographic  data  can  be  stored  as  either  a  raster  or  a vector representation.  A raster system divides the area into a grid and assigns values to each cell in the grid.  For exam-ple, each cell might be coded according to its highest point of elevation, the amount of vegetation (ground cover) it has, its  population  density,  or  any  other  factor  of  interest.   The simple  grid  system  makes  raster  data  easy  to  manipulate, but the data tends to be “coarse” since there is no informa-tion about variations within a cell. ",0,Human
228,"The power of geographic information systems comes from the ability to integrate data from a variety of sources, whether aerial  photography,  census  records,  or  even  scanned  paper maps.  Once in digital form, the data can be represented in a variety of ways for various purposes.  A sophisticated gis can be  queried  to  determine,  for  example,  how  much  of  a  pro-posed  development  would  have  a  downhill  gradient  and  be below sea level such that flooding might be a problem.  These results can in turn be used by simulation programs to deter-mine,  for  example,  whether  release  of  a  chemical  into  the groundwater from a proposed plant site might affect a partic-ula r  town  two  miles  away.  geographic  information  systems are  thus  vital  for  the  management  of  a  variety  of  complex systems  that  are  distributed  over  a  geographical  area,  such as water and sewage systems, power transmission grids, and traffic control systems.  Other applications include emergency planning (and evacuation routes) and the long-term study of the effects of global warming trends. ",0,Human
229,"globalization  can  be  described  as  a  group  of  trends  that are  breaking  down  the  boundaries  between  national  and regional  economies,  making  countries  more  dependent  on one  another,  and  resulting  in  the  freer  flow  of  labor  and resources.   These  trends  have  been  praised  by  free  trade advocates  and  decried  by  proponents  of  labor  rights  and environmentalism.   However  one  feels  about  them,  it  is clear  that  global  trends  are  reshaping  the  computer  and information  industry  in  many  ways,  and  pose  significant challenges. ",0,Human
230,"global trends that affect computer technology, software, and services include:,      offshoring, or  the  continuing  movement  of  manufac-turing of high-value components (and whole systems) from the industrialized West to regions such as Asia,    outsourcing—moving  functions  (such  as  technical support)  from  a  company’s  home  country  to  areas where  suitable  labor  forces  are  cheaper  ,,      removal of traditional intermediaries such as brokers and agents, with some of their functions being taken over by software ,,      decentralized  networks  (of  which  the  Internet  itself is  the  most  prominent  example)  and  the  tendency  of information  to  flow  freely  and  quickly  despite  barri-ers such as censorship,      virtualization—creation   of   work   groups   or   whole companies  that  are  distributed  across  both  space and time (24 hours), coordinated by the Internet and mobile communications ,,      increasing use of open-source and collaborative mod-els  of  software  and  information  development  ,,      blurring  of  the  distinction  between  consumers  and producers  of  information ",0,Human
231,"Computer-related businesses must also deal with the effects of  globalization  on  the  market  for  hardware,  software,  and services.   Lower-cost  offshore  manufacturing  has  helped contribute to making many computer systems and peripher-als  into  commodity  items.   This  certainly  benefits  consum-ers (consider the ubiquitous $100 or less computer printer).  However,  it  becomes  more  difficult  to  extract  a  premium for a brand as opposed to a generic name.  Some companies have responded by relentless efforts to maximize efficiency in manufacturing , while a few others have maintained a reputation for style or innovation .   Consumers  have  increasingly  objected, however, to the difficulty in dealing with offshore technical support. While  the  power  of  the  Internet  has  opened  many  new ways  of  reaching  potential  customers  around  the  world, dealing   with   a   global   marketplace   brings   considerable added complications, such as the need to deal with different regulatory systems .  In some areas  there is also the problem of unauthor-ized  copying  of  software  and  media  products . ",0,Human
232,"google  Inc.   (NASDAQ  symbol: gOOg)  has  built  a  busi-ness  colossus  by  focusing  on  helping  users  find  what  they are  looking  for  on  the  Internet  while  selling  advertising targeted at those same users.  By 2006, “to google” could be found in dictionaries as a verb meaning to look up anyone or anything online. goog  le was founded by two Stanford students ,  who,  for  their  doctoral  thesis, had described a Web search algorithm that could give a bet-ter  idea  of  the  likely  relevance  of  a  given  site  based  on  the number  of  sites  that  linked  to  it.   The  two  students  imple-mented  a  search  engine  based  on  their  ideas  and  hosted  it on  the  Stanford  Web  site,  where  its  popularity  soon  irri-tated  the  university’s  system  administrators.   In  1998  their bus  iness  was  incorporated  as google,  Inc. ,  and  moved  to the  archetypal  Silicon  Valley  entrepreneur’s  location—a friend’s  garage.   However,  as  the  company  attracted  invest-ment  capital  and  grew  rapidly,  it  moved  to  Palo  Alto  and the  n its present home in mountain View. google’s  initial  public  stock  offering  was  in  2004,  and the   market’s   enthusiastic   response   made   many   senior employees  instant  millionaires.  google’s  steady  growth  in subsequent  years  has  kept  its  stock  in  demand,  reaching  a record  peak  of  $560  in  September  2007.   (In  2006 google was added to the S&P 500 Index. )",0,Human
233,"prior  to  the  late  1970s,  most  computer  applications  (other than  some  scientific  and  experimental  ones)  did  not  use graphics.   However,  the  early  microcomputer  systems  such as the Apple II, Radio Shack TRS-80, and Commodore PET could all display graphics, either on a monitor or (with the aid  of  a  video  modulator)  on  an  ordinary  TV  set.   While primitive (low resolution; monochrome or just a handful of colors)  this  graphics  capability  allowed  for  a  thriving  mar-ket in games and educational software. The  earliest  video  displays  for  mainstream  PCs  pro-vid ed basic text display capabilities (such as the mDA, or monochrome  display  adapter,  with  25  lines  of  text  up  to 80  characters  per  line)  plus  the  ability  to  create  graphics by setting the color of individual pixels.  The typical low-endgraphics card of the early 1980s was the CgA (Color graphics  Adapter),  which  offered  various  modes  such  as 320  by  200  pixels  with  four  colors.   Computers  marketed forprofessional  use  offered  the  EgA  (Enhanced graph-ics  Adapter),  which  could  show  640  by  350  pixels  at  16 colors. ",0,Human
234,"Broadly speaking, a graphics file consists of data that speci-fies the color of each pixel (dot) in an image.  Since there are many  ways  this  information  can  be  organized,  there  are  a variety  of  graphics  file  formats.  ",0,Human
235,"In  a  bitmap  format  there  is  a  group  of  bits  (i. e.   a  binary value)  that  specifies  the  color  of  each  pixel.   Windows  pro-vides standard  bitmap  (BmP)  formats  for  1-bit  (2  colors or  monochrome),  4-bit  (16  colors),  8-bit  (256  colors),  or 24-bit  (16  million  colors).   The  Windows  bitmap  format  is also  called  a  DIB  (device-independent  bitmap)  because  the stored  colors  are  independent  of  the  output  device  to  be used  (such  as  a  monitor  or  printer).   The  relevant  device driver is responsible for translating the color to one actually used by the device.  Because it is “native” to Windows, BmP is widely used, especially for program graphics resources. ",0,Human
236,"Bitmap  formats  have  the  advantage  of  storing  the  exact color  of  every  pixel  without  losing  any  information.   How-ever,  this  means  that  the  files  can  be  very  large  (from hundreds  of  thousands  of  bytes  to  several  megabytes  for Windows  screen  graphics).   BmP  and  other  bitmap  formats do  support  a  simple  method  of  compression  called  run-length encoding (RLE), where a series of identical pixels is replaced  by  a  single  pixel  and  a  count.   Bitmap  files  can  be further compressed through the use of utilities such as the popular Zip program ",0,Human
237,"EPS (Encapsulated PostScript) is a vector-based rather than bitmap (raster) format.  This means that an EPS file consists not  of  the  actual  pixel  values  of  an  image,  but  the  instruc-tions for drawing the image (including coordinates, colors, and  so  on).   The  instructions  are  specified  as  a  text  file  in the versatile PostScript page description language.  This for-mat is usually used for printing, and requires a printer that supports PostScript (there are also PostScript renderers that run entirely in software, but they tend to be slow and some-what unreliable). ",0,Human
238,"gIF, or graphics Interchange Format, is a bitmapped format promulgated  by  CompuServe.   Instead  of  reserving  enough space  to  store  a  large  number  of  colors  in  each  pixel,  this format  uses  a  color  table  that  can  hold  up  to  256  colors.  Each pixel contains a reference (index into) the color table.  This means that gIF works best with images that have rela-tively  few  colors  and  for  applications  (such  as  Web  pages) where compactness  is  important.  gIF  also  uses  compres-sion to achieve compactness, but unlike the case with JPEg it is a lossless compression called LZW.  There is also a gIF format that stores simple animations. ",0,Human
239,"JPEg,  which  stands  for  Joint  Photographic  Experts group, is  widely  used  for  digital  cameras  because  of  its  ability  to highly  compress  the  data  in  a  color  graphics  image,  allow-ing  a  reasonable  number  of  high-resolution  pictures  to  be stored  in  the  camera’s  onboard  memory.   The  compression is “lossy,” meaning that information is lost during compres-sion ,.  At relatively low compression ratios (such as 10:1, or 10 percent of the original image size) changes  in  the  image  due  to  data  loss  are  unlikely  to  be         graphics formatsperceived by the human eye.  At higher ratios (approaching 100:1)  the  image  becomes  seriously  degraded.   JPEg’s  abil-ity to  store  thousands  of  colors  (unlike gIF’s  limit  of  256) makes  the  format  particularly  suitable  for  the  subtleties  of photography. ",0,Human
240,PCx is a compressed bitmap format originally used by the popular PC Paintbrush program.  In recent years it has been largely supplanted by BmP and TIFF. ,0,Human
241,"TIFF,  or  Tagged  Image  File  Format,  is  also  a  compressed bitmap  format.   There  are  several  variations  by  different vendors,  which  can  lead  to  compatibility  problems.   Imple-mentations  can  use  various  compression  methods,  gener-ally leading to ratios of 1. 5 to 1 to about 2 to 1. ",0,Human
242,"While conventional pointing devices , are quite satisfactory  for  making  selections  and  even  manipulat-ing  objects,  many  artists  prefer  the  control  available  only through  a  pen  or  pencil,  which  allows  the  angle  and  pres-sure of the stylus tip to be varied, creating precise lines and shading.  A graphics tablet (also called a digitizing tablet) is a device that uses a specially wired pen or pencil with a flat surface (tablet).  Besides tracking the location of the pen and tra  nslating  it  into x/Y  screen  coordinates,  the  tablet  also has  pressure  sensors  (depending  on  sensitivity. the  tablet can recognize 256, 512, or 1024 levels of pressure).  In com-bination with buttons on the pen, the pressure level can be used  to  control  the  line  thickness,  transparency,  or  color.  In  addition,  the  driver  software  for  some  graphics  tablets includes additional functions such as the ability to program the  pen  to  control  features  of  such  applications  as  Adobe Photoshop. ",0,Human
243,"This is a general term for features that reduce the growing environmental impact of the manufacture or use of comput-ers.   This  impact  has  several  aspects:  energy  consumption, resource  consumption,  e-waste,  and  pollution  and  green-house emissions. ",0,Human
244,"Computers consume a variety of resources, starting with their manufacturing and packaging.  Resource consumption can be reduced  by  building  more  compact  units  and  by  designing components so they can be more readily stripped and recycled or  reused.   Adopting  reusable  storage  media  (such  as  rewrit-able  CDs),  recycling  printer  toner  cartridges,  and  changing office  procedures  to  minimize  the  generation  of  paper  docu-ments are also ways to reduce resource consumption. ",0,Human
245,"In recent years the disposal of obsolete computers and other electronic  equipment  (“e-waste”)  has  been  both  a  grow-ing  concern  and  a  business  opportunity.   There  are  many toxic substances in electronics components, including lead, mercury,  and  cadmium.   Processing  e-waste  to  recover  raw materials is expensive, so greater emphasis has been placed on  disassembling  machines  and  reusing  or  refurbishing their  individual  components.  meanwhile,  many  communi-ties have banned disposing of e-waste in regular trash, and some have offered opportunities to drop off e-waste at no or minimal  charge.   States  such  as  California  have  also  insti-tuted  a  recycling  fee  that  is  collected  upon  sale  of  devices such as CRT monitors and televisions. ",0,Human
246,"Fabrication of computer chips in more than 200 large plants around the world involves a variety of toxic chemicals and waste products.  The Silicon Valley alone is home to 29 toxic sites under the EPA’s Superfund Program.  The shift of much of semiconductor and computer component manufacturing to  countries  such  as  China  that  have  less  strict  pollution controls  has  also  exacerbated  what  has  become  a  global problem. Whether through regulation or enlightened self-interest, companies  that  want  to  reduce  future  emissions  can  use several strategies.  manufacturing equipment and processes can be modified so they create fewer toxic substances or at least  keep  them  from  getting  into  the  environment.   Non-toxic  (or  less  toxic)  materials  can  be  substituted  where possible—for  example,  use  of  ozone-depleting  chlorofluo-rocarbons (CFCs) as cleaning agents has been largely elimi-nated.   Finally,  waste  can  be  properly  sorted  and  disposed of, and recycled wherever feasible. Like  other  major  manufacturing  sectors,  the  computer industry  is  also  faced  with  the  need  to  reduce  the  amount of  the  greenhouse  gases  (particularly  CO2)  contributing  to global  warming.   This  mainly  means  further  reducing  the energy  consumption  of  new  PCs.   In  June  2007  a  number of  major  players,  including google,  Intel,  Dell,  Hewlett-Packard, microsoft, and Sun, established the Climate Savers Computing  Initiative.  going  beyond  Energy  Star,  the  pro-gram  is  expected  to  reduce  power  consumption  equivalent to 54 million tons of greenhouse gases annually—about the same  as  that  produced  by  11  million  cars  or  20  large  coal-fired power plants. ",0,Human
247,"grid  or  cluster  computing  involves  the  creation  of  a  sin-gle  computer  architecture  that  consists  of  many  separate computers  that  function  much  like  a  single  machine.   The computers  are  usually  connected  using  fast  networks  ,.   The  purpose  of  the  arrangement can  be  to  provide  redundant  processing  in  case  of  system failures,  to  dynamically  balance  a  fluctuating  work  load, or  to  split  large  computations  into  many  parts  that  can  be performed  simultaneously.   This  latter  approach  to  “high-performance computing” creates the virtual equivalent of a very large and powerful machine. ",0,Human
248,"grid  and  cluster  architectures  often  overlap,  but  the  term grid  tends  to  be  applied  to  a  more  loosely  coordinated structure  where  the  computers  are  dispersed  over  a  wider area  (not  a  local  network).   In  a  grid,  the  work  is  usually divided  into  many  separate  packets  that  can  be  processed independently without the computers having to share data.  Each task can be completed and submitted without waiting for the completion of any other task.  Clusters, or the other hand,  more  closely  couple  computers  to  act  more  like  a single large machine. ",0,Human
249,"Popular groupware software suites such as Lotus Notes and microsoft Exchange generally offer at least some of the following features:,      e-mail coordination, including the creation of group or task-oriented mail lists,      shared  calendar,  giving  each  participant  information about all upcoming events,      meeting  management,  including  scheduling  (ensur-ing  compatibility  with  everyone’s  existing  schedule) and facilities booking,    scheduling  tasks  with  listing  of  persons  responsible for  each  task,  progress  (milestones  met),  and  check-ing off completed tasks,      real-time “chat” or instant message capabilities,      documentation systems that allow a number of people to  make  comments  on  the  same  document  and  see and respond to each other’s comments,    “whiteboard”  systems  that  allow  multiple  users  to draw  a  diagram  or  chart  in  real  time,  with  everyone able to see and possibly modify it",1,Boat
250,"Grove, Andrew S. (1936– )Hungarian-AmericanEntrepreneur.  Andrew grove  is  a  pioneer  in  the  semiconductor  industry and builder of Intel, the corporation whose processors now power the majority of personal computers.  grove was born András gróf on September 2, 1936, in Budapest to a Jewish family.  grove’s family was disrupted by the german occupa-tion of Hungary later in World War II.  Andrew’s father was conscripted into a work brigade and then into a Hungarian formation  of  the german  army.   Andrew  and  his  mother, maria,  had  to  hide  from  the  Nazi  roundup  in  which  many Hungarian Jews were sent to death in concentration camps. ",1,Boat
251,"Fault  tolerance  is  a  design  concept  that  recognizes  that  all computer-based systems will fail eventually.  The question is whether a system as a whole can be designed to “fail grace-fully. ”  This  means  that  even  if  one  or  more  components fail,  the  system  will  continue  to  operate  according  to  its design  specifications,  even  if  its  speed  or  throughput  must decrease. ",1,Boat
252,"There  are  a  number  of  ways  to  make  a  system  more  fault tolerant.  Individual components such as hard drives can be composed of multiple units so that the remaining units can take over if one fails ,.  If each key component has at least one backup, then there should be time to replace the primary before the backup also fails. Another way to achieve fault tolerance is to provide mul-tiple paths to successful completion of the task.  In fact, this is  how  packet-switched  networks  like  the  Internet  work ,.   If  one  communications  link  is  down  or  too congested, packets are given an alternative routing. Fault diagnosis software can also play an important role both in determining how to respond to a problem (beyond any automatic response) and for providing data that will be useful  later  to  system  administrators  or  technicians.   Some fault diagnosis systems can use elaborate rules , to pinpoint the cause of a fault and recommend a solution. ",1,Boat
253,"The  amount  of  fault  tolerance  to  be  provided  for  a  sys-tem depends on a number of factors:,    How important is it that the system not fail?,      How critical is a given component to the operation of the system?,      How  likely  is  it  that  a  given  component  will  fail? (mean time between failures, or mBTF),      How expensive is it to make the component or system fault tolerant?",1,Boat
254,"A  fiber  optic  (or  optical  fiber)  cable  transmits  photons (light)  instead  of  electrons.   Depending  on  the  diameter  of the cable, the light is guided either by total internal reflec-tion  or  as  a  waveguide  (manipulating  refraction).   These principles were known as early as the mid-19th century and began to be used in the 20th century for such applications as  dental  and  medical  illumination  and  in  experiments  in transmitting images for television. ",1,Boat
255,"Optical  fiber  in  its  modern  form  was  developed  in  the 1950s.   The  glass  fiber  through  which  the  light  passes  is surrounded  by  a  transparent  cladding  designed  to  provide the needed refractive index to keep the light confined.  The cladding  in  turn  is  surrounded  by  a  resin  buffer  layer  and often an outer jacket and plastic cover.  Fiber used for com-munication is flexible, allowing it to bend if necessary. Early  optical  fiber  could  not  be  used  for  practical  com-munication because of progressive attenuation (weakening) of the light as it traveled.  However, by the 1970s the attenu-ation  was  being  reduced  to  acceptable  levels  by  removing impurities from the fibers.  Today the light signals can travel hundreds of miles without the need for repeaters or amplifi-ers.  In the 1990s a new type of optical fiber (photonic crys-tal)  using  diffraction  became  available.   This  kind  of  fiber is  particularly  useful  in  applications  that  require  higher power signals. ",1,Boat
256,"Optical  fiber  has  several  advantages  over  ordinary  electric cable  for  communications  and  networking.   The  signals  can travel much farther without the need for a repeater to boost the  signal.   Also,  the  ability  to  modulate  wavelengths  allows optical fiber to carry many separate channels, greatly increas-ing the total data throughput.  Optical fiber does not emit RF (radio  frequency)  energy,  a  source  of  “cross  talk”  (interfer-ence) in electrical cable.  Fiber is also more secure than elec-trical cable because it is hard for an eavesdropper to tap. Today  fiber  is  used  for  most  long-distance  phone  lines and Internet  connections.  many  cable  television  systems are  upgrading  from  video  cable  to  fiber  because  of  its greater reliability and ability to carry more bandwidth and enhanced data services. ",1,Boat
257,"At bottom, information in a computer is stored as a series of bits,  which  can  be  grouped  into  larger  units  such  as  bytes or “words” that represent particular numbers or characters.  In  order  to  be  stored  and  retrieved,  a  collection  of  such binary  data  must  be  given  a  name  and  certain  attributes that  describe  how  the  information  can  be  accessed.   This named entity is the file. ",1,Boat
258,"The file system is the facility of the operating system that organizes files ,.  For example, on DOS and older Windows PCs, there is a file allocation table (FAT) that consists of a linked list of clusters (each cluster consists of a fixed number of sectors, varying with the overall size of the disk).  When the operating system is asked to access a file, it can go through the table and find the clusters belonging to that file, read the data and send it to the requesting applica-tio n.   modern  file  systems  further  organize  files  into  groups called folders or directories, which can be nested several lay-ers  deep.   Such  a  hierarchical  file  system  makes  it  easier  for users to organize the dozens of applications and thousands of files found on today’s PCs.  For example, a folder called Book might have a subfolder for each chapter, which in turn con-tains folders for text and illustrations relating to that chapter. ",1,Boat
259,"The  ultimate  organization  of  data  in  a  file  depends  on  the application.   A  typical  approach  is  to  define  a  data  record with  various  fields.   The  program  might  have  a  loop  that repeatedly  requests  a  record  from  the  file,  processes  it  in some  way,  and  repeats  until  the  operating  system  tells  it that  it  has  reached  the  end  of  the  file.   This  would  be  a sequential  access;  a  program  can  also  be  set  up  for ran-dom  access,  which  means  that  an  arbitrary  record  can  be requested  and  that  request  will  be  translated  into  the  cor-rect  physical  location  in  the  file.   The  two  approaches  can be combined in ISAm (Indexed Sequential Access method), where  the  records  are  stored  sequentially  but  fields  are indexed so a particular record can be retrieved. ",1,Boat
260,"The  growth  in  desktop  computing  since  the  1980s  has resulted  in  much  data  being  moved  from  mainframe  com-puters  to  desktop  PCs,  which  are  now  usually  linked  by networks.  While a network enables users to exchange files, there  remains  the  problem  of  storing  large  files  or  collec-tions of files (such as databases) that are too large for a typi-cal PC hard drive or that need to be accessed and updated by many users. The  common  solution  is  to  obtain  a  computer  with large,  fast  disk  drives  ,.   This  computer,  the file  server,  is  equipped  with  software  (often  included  with the  networking  package)  that  serves  (provides)  files  as requested  by  users  or  applications  on  the  other  PCs  on the  network.   (See  also client-seRveRcomputing. )  The specifics  of  configuring  the  server  for  optimum  efficiency, providing  adequate  security,  and  arranging  for  backup  or archiving varies with the particular network operating sys-tem  in  use  (the  most  popular  environments  are  Windows NT, Vista, and the various versions of UNIx and Linux)",1,Boat
261,"The  file  server  has  many  advantages  over  storing  the files needed by each user on his or her own PC.  By storing the files on a central server, ordinary users’ PCs do not need to have larger, more expensive disk drives.  Central storage also  makes  it  easier  to  ensure  that  backups  are  run  regularly. ",1,Boat
262,"File-sharing services allow participants to provide access to files  on  their  personal  computers,  such  as  music  or  video.  In turn, the user can browse the service to find and down-load material of interest.  The structure is generally that of a peer-to-peer (P2P) network with no central server. The  first  major  file-sharing  service  was  Napster.   This was  a  P2P  network  but  had  a  central  server  that  provided the  searchable  list  of  files  and  locations—but  not  the  files themselves,   which   were   downloaded   from   users’   PCs.  Napster  was  forced  to  close  in  2001  by  legal  action  from copyright  holders  ,.   A  new  but  unrelated  for-pay  service  opened  later under the same name. ",1,Boat
263,"many  services  today  use  the  popular  BitTorrent  file-shar-ing protocol.  A BitTorrent client (either the program of that name  or  another  compatible  one)  can  transmit  or  receive any  type  of  data.   To  share  a  file,  the  client  creates  a  “tor-rent”—a  small  file  that  contains  metadata  describing  the file and an assignment to a “tracker. ” The tracker is another computer  (node)  that  coordinates  the  distribution  of  the file.  Although this sounds complicated and a request takes longer  to  set  up  than  an  ordinary  HTTP  connection,  the advantage  is  that  once  set  up,  downloading  is  efficiently managed  even  for  files  for  which  there  is  high  demand.  The  downloading  client  connects  to  multiple  clients  that provide  pieces  of  the  desired  file.   Because  of  its  efficiency, BitTorrent allows for distribution of substantial amounts of data  at  low  cost,  particularly  since  the  system  “scales  up” automatically  without  having  to  provide  extra  resources.  BitTorrent  is  currently  being  used  for  a  variety  of  legally distributed  material,  including  video,  sound,  and  textual content ",1,Boat
264,"Because  of  their  frequent  use  to  share  copyrighted  music, video, or other material, a variety of organizations of copy-right  owners  have  sued  file-sharing  services  and/or  their users.   The  biggest  problem  for  the  courts  is  to  determine whether  there  is  “substantial  non-infringing  use”—that  is, the service is being used to exchange legal data. Some  file-sharing  services  have  been  accused  of  dis-tributing  malware  (viruses  or  spyware)  or  of  being  used to  distribute  material  that  is  illegal  per  se  (such  as  child pornography). In  response  to  litigation  threats,  file-sharing  services have tended to become more decentralized, and some have features  that  increase  anonymity  of  users  , or use encryption. ",1,Boat
265,"With  today’s  networked  PCs  and  the  use  of  e-mail  attach-ments  it  is  easy  to  send  a  copy  of  a  file  or  files  from  one computer  to  another,  because  networks  already  include  all the  facilities  for  doing  so.   Earlier,  many  PCs  were  not  net-worked  but  could  be  connected  via  a  dial-up  modem.   To established the connection, a terminal program running on one  PC  had  to  negotiate  with  its  counterpart  on  the  other machine,  agreeing  on  whether  data  would  be  sent  in  7-  or 8-bit  chunks,  and  the  number  of  parity  bits  that  would  be included  for  error-checking  ,.   The sending  program  would  inform  the  receiving  program  as to  the  name  and  basic  type  of  the  file.   For  binary  files (files  intended  to  be  interpreted  as  literal  binary  codes,  as with executable programs, images, and so on) the contents would be sent unchanged.  For text files, there might be the issue of which character set (7- bit or 8-bit ASCII) was being used, and whether the ends of lines were to be marked with a  CR  (carriage  return)  character,  an  LF  (linefeed),  or  bot",1,Boat
266,"Once the programs agree on the basic parameters for a file transfer,  the  transfer  has  to  be  managed  to  ensure  that  it completes  correctly.   Typically,  files  are  divided  into  blocks of data (such as 1K, or 1024 bytes each).  During the 1970s, Ward Christensen developed xmodem, the first widely used file transfer program for PCs running CP/m (and later, mS-DOS and other operating systems).  xmodem was quite reli-able because it incorporated a checksum (and later, a more advanced  CRC)  to  check  the  integrity  of  each  data  block.  If  an  error  is  detected,  the  receiving  program  requests  a retransmission. ",1,Boat
267,"The  role  of  the  computer  in  film  begins  well  before the  first  camera  rolls.   Writers  can  use  computers  to  write scripts,  while  specialized  programs  can  be  used  to  lay out  storyboards.   Using  3D  programs  somewhat  like  CAD (drafting)  programs,  set  designers  can  experiment  with the positioning of objects before deciding on a final design and  obtaining  or  creating  the  physical  props.   For  mattes (backgrounds  against  which  the  characters  will  be  shot  in a  scene),  a  computer-generated  scene  can  now  be  inserted directly  into  the  film  without  the  need  for  an  expensive, hand-painted backdrop. ",1,Boat
268,"There are many calculations or other processes that can be described using a specific series of states or conditions.  For example,  the  state  of  a  combination  lock  depends  not  only on what numeral is being dialed or punched at the moment, but  on  the  numbers  that  have  been  previously  entered.   An even simpler example is a counter (such as a car odometer), whose  next  output  is  equal  to  one  increment  plus  its  cur-rent  setting.   In  other  words,  a  state-based  device  has  an inherent “memory” of previous steps. ",1,Boat
269,"many programs and operating systems are structured as an endless  loop  where  an  input  (or  command)  is  processed, the  results  returned,  the  next  input  is  processed,  and  so on, until an exit command is received.  A mode or state can be  used  to  determine  the  system’s  activity.   For  example,  a program  might  be  in  different  modes  such  as  waiting  for input,  processing  input,  displaying  results,  and  so  on.   The program  logic  will  refer  to  the  current  state  to  determine what  to  do  next  and  at  some  point  the  logic  will transitionthe system to the next state in the sequence.  The validity of some kinds of programs, protocols, or circuits can therefore be proven by showing that there is an equivalent finite-state machine—and thus that all possible combinations of inputs have been accounted for. Finite-state machines have many other interesting appli-cations.  Simple organisms can be modeled as a set of states that  interact  with  the  environment .  The lower-level functions of robots can also be represented as  a  set  of  interacting  finite-state  machines.   Even  video game characters often use FSms to give them a repertoire of plausible behavior. ",1,Boat
270,"The  vulnerability  of  computer  systems  to  malicious  or criminal  attack  has  been  greatly  increased  by  the  growing number  of  connections  between  computers  (and  local  net-works)  and  the  worldwide  Internet  ,.   The  widespread  use of  permanent  broadband  connections  by  consumers  (such as  DSL  and  cable  modem  links)  has  increased  the  risk  to home  users.   Intruders  can  use  “port  scanning”  programs to  determine  what  connections  a  given  system  or  network has open, and can use other programs to snoop and steal or destroy sensitive data. ",1,Boat
271,"Typical firewall functions include:,    Examining incoming data  packets  and  blocking  those that  include  commands  to  examine  or  use  unauthor-ized ports or IP addresses,      Blocking  data  packets  that  are  associated  with  com-mon  hacking  techniques  such  as  “trojans”  or  “back-door” exploitationsThis diagram shows a finite-state representation of a ZIP code.  The arrows link each state (within a circle) to its possible successor.  In this simple example each digit must be followed by another digit until the fifth digit, which can either be followed by a blank (indi-cating a five-digit ZIP code) or four more digits for a 9-digit ZIP.         firewall,      Hiding  all  the  internal  network  addresses  on  a  local network,  presenting  only  a  single  address  to  the outside  world  (this  is  also  called  NAT,  or  Network Address Translation),      monitoring  particular  applications  such  as  ftp  (file transfer  protocol)  and  telnet  (remote  login),  restrict-ing them to certain addresses.  Often a special address called  a  proxy  is  established  rather  than  allowing direct  connections  between  the  outside  and  the  local network. ",1,Boat
272,"FireWire  is  a  high-speed  serial  interface  used  by  personal computers  and  digital  audio  and  video  equipment.   (The name FireWire is an Apple brand name, but it is used gener-ically.  Technically it is the IEEE 1394 Serial Bus. )FireWire was developed in the 1990s by the IEEE P1394 Working group  with  substantial  funding  from  Apple  and help  from  engineers  from  major  corporations  including IB m,  Digital  Equipment  Corporation  (DEC),  Sony,  and Texas  Instruments.   In  1993  it  was  hailed  as  the  “most  sig-nificant new technology” by Byte magazine. ",1,Boat
273,"Common uses for FireWire include connecting digital video (such as camcorder) devices, audio devices, and some data storage devices.  FireWire is favored over USB 2. 0 for many professional applications because of its higher speed and power distribution capabilities.  However, it is more expensive than USB 2. 0, which provides sufficient speed for many consumer peripherals such as digital cameras and printers. ",1,Boat
274,"A flag is a variable that is used to specify a particular condi-tion or status ,.  Usually a flag is either true or false.   For  example,  a  flag  Valid_Form  could  be  set  to  true before  the  input  form  is  processed.   If  the  validation  check for  any  data  field  fails,  the  flag  would  be  set  to  false.   After the  input  procedure  has  ended,  the  main  program  would check the Valid_Form flag.  If it’s true, the data on the form is  processed  (for  example,  continuing  on  to  the  payment process).  If the flag is false, the input form might be redis-played with errors or omissions highlighted. ",1,Boat
275,"In computers, the term ""flash mob"" typically refers to a group of individuals who organize a spontaneous and coordinated online activity, such as a social media campaign or an online protest.  Flash mobs often use social media platforms and other online tools to mobilize large groups of people quickly and efficiently. Flash mobs can take many different forms, ranging from coordinated tweets or Facebook posts to more elaborate online events such as virtual marches or protests.  They are often used to draw attention to a particular cause, raise awareness about an issue, or promote a message or idea. ",1,Boat
276,"Smart  mobs  are  similar  in  organization  to  flash  mobs  but tend  to  be  more  purposeful  and  enduring  forms  of  social organization.  The phenomenon was first described by How-ard  Rheingold  in  his  book Smart  Mobs:  The  Next  Social Revolution ,.  Rheingold describes several examples of smart mobs, including teenage “thumb tribes” in Tokyo and Helsinki, Finland (named for their use of  tiny  thumb-operated  keyboards  on  cell  phones).   Their typical  activities  included  organizing  impromptu  raves  or converging on rock stars or other celebrities. ",1,Boat
277,"A flash or “thumb” drive is a small data storage device that uses semiconductor flash memory rather than a disk drive.  It is connected to a digital device using the universal serial bus  ,.   Because  most  computers,  digital  cameras, and  other  digital  devices  have  USB  ports,  a  flash  drive  is  a convenient way to provide up to 16 gB (as of 2007) of low power,  rewritable  memory.   Flash  drives  first  appeared  in late 2000. Flash drives can use a separate USB cable (useful when several devices need to be connected to closely spaced USB ports)  or  simply  have  a  connector  that  plugs  directly  into the port.  many  people  who  regularly  work  with  several computers carry their backup data or even a complete oper-ating system (such as Linux) on a flash drive, perhaps con-nected to their keyring. ",1,Boat
278,"The  traditional  computer  display  uses  a  cathode  ray  tube (CRT)  like  that  in  a  television  set  ,.   The  flat-panel  display  is  an  alternative  used  in  most  laptop  com-puters  and  some  higher-end  desktop  systems.   The  most common type uses a liquid crystal display (LCD).  The dis-play consists of a grid of cells with one cell for each of the three colors (red, green, and blue) for each pixel. ",1,Boat
279,"Until  the  mid-1990s,  the  floppy  disk  or  diskette  was  the primary  method  for  distributing  software  and  providing removable  data  storage  for  personal  computers.   Diskettes first appeared in the late 1960s on IBm minicomputers, and became  more  widespread  on  a  variety  of  minicomputers and early microcomputers during the 1970s. The now obsolete 8-inch and 5-¼ inch disks were made from  mylar  with  a  metal  oxide  coating,  the  assembly  being housed in a flexible cardboard jacket (hence the term “floppy disk”).   The  more  compact  3. 5-inch  diskettes  first  widely introduced  with  the  Apple macintosh  in  1984  became  the standard  type  for  all  PCs  by  the  1990s.   These  diskettes  are no longer truly “floppy” and come in a rigid plastic case. ",1,Boat
280,"A flowchart is a diagram showing the “flow” or progress of operations  in  a  computer  program.   Flowcharting  was  one of  the  earliest  aids  to  program  design  and  documentation, and a plastic template with standard flowcharting symbols was a common programming accessory.  Today CASE (com-puter-aided  software  engineering)  systems  often  include utilities  that  can  automatically  generate  flowcharts  based on  the  control  structures  and  procedure  calls  found  in  the program code. The standard flowchart symbols include blocks of vari-ous  shapes  that  represent  input/output,  data  processing, sorting and collating, and so on.  Lines with arrows indicate the  flow  of  data  from  one  stage  or  process  to  the  next.   A diamond-shaped  symbol  indicates  a  decision  to  be  made by  the  program.   If  the  decision  is  an  “if”  ,  separate  lines  branch  off  to  the  alternatives.  If the decision involves repeated testing ,, the line returns  back  to  the  decision  point  while  another  line  indi-cates  the  continuation  of  processing  after  the  loop  exits.  Devices  such  as  printers  and  disk  drives  have  their  own symbols  with  lines  indicating  the  flow  of  data  to  or  from the device",1,Boat
281,"In computing, a font refers to a typeface that has a distinc-tive  appearance  and  style.   In  most  word  processing,  desk-top publishing, and other programs the user can select the point  size  at  which  the  font  is  to  be  displayed  and  printed (in traditional typography each point size would be consid-ered to be a separate font).  Operating systems such as Win-A flowchart uses a set of simple symbols to describe the steps involved in a data processing operation.  The parallelograms indi-cate an input/output operation (such as reading or writing a file).  The “decision diamonds” have yes and no branches depending on the result of a test or comparison. 00        flowchartdows  and macintosh  usually  come  with  an  assortment  of fonts, and applications can register additional fonts to make them available to the system. ",1,Boat
282,"There  are  two  basic  ways  to  store  font  data  in  the computer  system.   Bitmapped  fonts  store  the  actual  pat-tern of tiny dots that make up the letters in the font.  This has  the  advantage  of  allowing  each  letter  in  each  point size  to  be  precisely  designed.   The  primary  disadvantage is  the  amount  of  memory  and  system  resources  required to  store  a  font  in  many  point  sizes.   In  practice,  this  con-sideration  results  in  only  a  relatively  few  fonts  and  sizes being available. ",1,Boat
283,"Forth  has  a  very  simple  structure.   The  Forth  system  con-sists  of  a  collection  of words.   Each  word  is  a  sequence  of operations  (which  can  include  other  existing  words).   For example, the DUP word makes a copy of a data value.  Data is  held  by  a  stack.   For  example,  the  arithmetic  expression written  as  2  +  3  in  most  languages  would  be  written  in Forth  as  +  2  3.   When  the  +  operator  (which  in  Forth  is  a pre-defined  word)  executes,  it  adds  the  next  two  numbers it  encounters  (2  and  3)  together,  and  puts  the  sum  on  the stack (where in turn it might be fetched for further process-ing by the next word in the program ,.  This rep-resentation  is  also  called postfix  notation  and  is  familiar  to many users of scientific calculators. ",1,Boat
284,"A key feature of Forth is its extensibility.  Once you have defined a word, the new word can be used in exactly the same way  as  the  predefined  words.   The  various  forms  of defining words allow for great control over what happens when a new word  is  created  and  when  the  word  is  later  executed.   (In many ways Forth anticipated the principles of object-oriented programming, with words as objects with implicit construc-tors and methods.  A well-organized Forth program builds up from  “primitive”  operations  to  the  higher-level  words,  with the program itself being the highest-level word. )",1,Boat
285,"Fortran  (FORmula  TRANslator)  was  the  first  widely used  high-level  programming  language.   It  was  developed by a project begun in 1954 by a team under the leadership of I  Bm researcher John Backus.  The goal of the project was to create a language that would allow mathematicians, sci-entists, and engineers to express calculations in something close  to  the  traditional  notation.   At  the  same  time,  a  com-piler  would  have  to  be  carefully  designed  so  that  it  would produce  executable  machine  code  that  would  be  nearly  as efficient as the code that would have been created through the more tedious process of using assembly languages.  (See compileR and assembleR. )",1,Boat
286,"Fractals  and  the  related  idea  of  chaos  have  profoundly changed  the  way  scientists  think  about  and  model  the world.   Around  1960,  Benoit mandelbrot  noticed  that  sup-posedly random economic fluctuations were not distributed evenly but tended to form “clumps. ” As he investigated other sources of data, he found that many other things exhibited this  odd  behavior.   He  also  discovered  that  the  patterns  of distribution were “self-similar”—that is, if you magnified a portion of the pattern it looked like a miniature copy of the whol  e.   mandelbrot  coined  the  term fractal  (meaning  frac-tured, or broken up) to describe such patterns.  Eventually, a  number  of  simple  mathematical  functions  were  found  to exhibit such behavior in generating values. ",1,Boat
287,"many  computer  users  are  familiar  with  the  colorful  fractal patterns  generated  by  some  screen  savers.   There  are  hun-dreds  of  “families”  of  fractals  (beginning  with  the  famous mandelbrot  set)  that  can  be  color-coded  and  displayed  in endless  detail.   But  there  are  a  number  of  more  significant applications.   Because  of  their  ability  to  generate  realistic textures at every level of detail, many computer games and simulations  use  fractals  to  generate  terrain  interactively.  Fractals  can  also  be  used  to  compress  large  digital  images into  a  much  smaller  equivalent  by  creating  a  mathemati-cal  transformation  that  preserves  (and  can  be  used  to  re-cre  ate)  the  essential  characteristics  of  the  image.  military experts can use fractal analysis either to distinguish artifi-cial  objects  from  surrounding  terrain  or  camouflage,  or  to generate more realistic camouflage.  Fractals and chaos the-ory are likely to produce many surprising discoveries in the future, in areas ranging from signal analysis and encryption to economic forecasting. ",1,Boat
288,"Functional languages have generally been used for special-ized  purposes,  although  they  can  in  principle  perform  any task  that  an  imperative  language  can.   APL,  which  is  basi-cally a functional language, has devotees who appreciate its compact  and  powerful  syntax  for  performing  calculations ,.   LISP  and  its  variants  have  long  been  favored  for many  artificial  intelligence  applications,  particularly  natu-ral language processing, where its representation of data as lists and the facility of its list-processing functions seems a natural fit. Proponents of functional languages argue that they free the  programmer  from  having  to  be  concerned  with  explic-itly setting up and using variables.  In a functional language, problems can often be stated in a more purely mathematical way.   Further,  because  functional  programs  are  not  orga-nized  as  sequentially  executed  tasks,  it  may  be  easier  to implement  parallel  processing  systems  using  functional languages. However, critics point out that imperative languages are much  closer  to  how  computers  actually  work  (employing actual storage locations and sequential operation) and thus produce  code  likely  to  be  much  faster  and  more  efficient than that produced by functional languages. ",1,Boat
289,"At  bottom,  a  data  bit  in  a  computer  is  “all  or  nothing” (1  or  0).  most  decisions  in  computer  code  are  also  all  or nothing: Either a condition is satisfied, and execution takes one  specified  path,  or  the  condition  is  not  satisfied  and  it goes  elsewhere.   In  real  life,  of  course,  many  situations  fall between the cracks.  For example, a business might want to treat  a  credit  applicant  who  almost  qualifies  for  “A”  status different  from  one  who  barely  made  “B. ”  While  a  program could be refined to include many gradations between B and A, another approach is to express the degree of “closeness” (or certainty) using fuzzy logic. ",1,Boat
290,"eBayeBay Inc.  (NASDAQ symbol: EBAY) is the world’s largest online auction and shopping site.  The first appearance of the auction service was in 1995 as AuctionWeb, part of the personal Web site of Pierre Omidyar ,.  Omidyar was surprised at how rapidly the auction service (which was initially free) grew.  After he imposed a modest listing fee, Omidyar found himself receiving thousands of dollars in small checks, and decided that online auctions could become a full-time business. ",1,Boat
291,"An e-book is a book whose text is stored in digital form and can be read on a PC or a handheld reading device.  Since most books today are created on word processors and typesetting systems, it is easy for a publisher to create an electronic version.  Older books that exist only in printed form can be scanned and converted to text. ",1,Boat
292,"A digital library is to e-books what a conventional library is to printed books.  Sometimes called an electronic library or virtual library, digital libraries can be created in a variety of ways.  Printed books can now be scanned and digitized rapidly.  Google has said that it can scan 3,000 volumes a day using a proprietary system.  (This is not necessary, of course, for books that were originally created in digital form",1,Boat
293,"Advantages of digital libraries include the following:166? ? ? ? e-books and digital libraries, There is never a shortage of copies or the need for a reader to wait for access. ,? Many digital libraries allow full searching of the text of all volumes.  Libraries can also use a common data format (such as “Open Archives. ”) to make their material searchable throughout the Internet. ,? Many older, hard-to-find books can be made more “discoverable” and accessible",1,Boat
294,"The most popular e-commerce sectors today include the selling of books, music and movies, travel-related services, electronics, clothing, luxury goods, and medications.  (In 2006, online buyers actually spent more money on clothing than on computers and related products. ) A number of other online activities can be considered part of e-commerce, although they are usually not included in retailing statistics ",1,Boat
295,"One continuing obstacle to the growth of e-commerce has been consumers’ concerns about the theft or misuse of personal information gathered as part of the shopping process.  This can involve either fake Web sites , or legitimate businesses that sell information about customers without their knowledge or consent ,.  According to a report from Gartner Research, more than $900 million in e-commerce sales during 2006 was lost because of consumers’ security concerns, and about a billion dollars more in sales was lost because customers decided not to buy online at all",1,Boat
296,"In the early 1950s, knowledge of computing tended to have and hoc nature.  On the practical level, computing staffs tended to train newcomers in the specific hardware and machine-level programming languages in use at a particular site.  On the theoretical level, programmers in scientific fields were likely to come from a background in electronics, electrical engineering, or similar disciplines. As it became clear that computers were going to play an increasingly important role, courses specific to computing were added to curricula in mathematics and engineering.  By the late 1950s, however, leading people in the computing field had become convinced that a formal curriculum in computer science was necessary for further advance in an increasingly sophisticated computing arena .  By the early 1960s, efforts at the University of Michigan, University of Houston, Stanford, and other institutions had resulted in the creation of separate graduate departments of computer science.  By the mid-1960s, the National Academy of Sciences and the President’s Science Advisory Committee had both called for a major expansion of efforts in computer science education to be aided by federal funding.  During the 1970s and 1980s, mathematical and engineering societies (in particular the Association for Computing Machinery (ACM) and Institute for Electrical and Electronic Engineering (IEEE) worked to established detailed computer science curricula that extended to undergraduate study.  By 2000, there were 155 accredited  programs in computer science in the United States. ",1,Boat
297,"BASIC was invented at Dartmouth College in 1963–1964 by John G.  Kemeny and Thomas E.  Kurtz, both professors of mathematics, assisted by a group of undergraduate student programmers.  Computers then were huge, slow, and expensive; there were no personal computers.  Their goal was to bring easy and accessible computing to all students, not just science or engineering students.  The method they chose called for developing a time-shared operating system, which would allow many users simultaneously.  (This operating system was developed entirely by Dartmouth undergraduate students. ) The new language, BASIC, easy to learn and easy to use, was an essential part of this effort.  BASIC was thus developed originally for a large multipleuser, time-shared system and not for personal computers, which did not appear widely until the early 1980s.  It has been asked whyBASICwas invented.  Couldn’t an existing language have been used for the purpose? The answer to the second question is no, which also answers the first question.  Other computer languages did exist in 1963, although there were not nearly as many as there are today.  The principal ones were FORTRAN and Algol; most of the others are long since forgotten.  Some of the common languages used today—C, C++, and Java—had not even been conceived.  FORTRAN and Algol were each considered briefly.  These languages were designed for production use on big machines or for scientific research, using punched cards.  But neither was suitable for use by beginners, neither was particularly well suited for a time-shared environment, and neither permitted speedy handling of short programs.  Kemeny and Kurtz had experimented with other simple computer languages as early as 1956, but with only modest success.  So, in 1963, when they began building a time-shared system for students, they quickly realized that a new language had to be invented—BASIC. ",1,Boat
298,"Timing attacks were publicized by Paul Kocher in 1996.  They attack the implementation of cryptosystems by measuring observable differences in the timing of the algorithm based on the particular value of the key.  They then use statistical methods to determine the bits of key by observing many operations using the same key.  Timing attacks typically require a significant number of chosen ciphertexts.  Related attacks can use any measure of differences in the performance of the encryption and decryption functions such as power consumption and heat dissipation.  Timing attacks and related attacks can be protected against to some degree by “blinding” the devices performing encryption and decryption computations so that all computations have the same performance, regardless of the particular key and message being used.  However, this can have a substantial performance cost, as it requires all computations to have worst-case performance.  Such attacks can also be protected against by designing systems so that they will not act as an “oracle” by decrypting and returning all and any messages that come their way, thereby preventing an attacker from obtaining the necessary data to carry out the attack.  However, this is not always possible without interfering with the purpose of the system. ",1,Boat
299,"The  arithmetic  logic  unit  is  the  part  of  a  computer  system that actually performs calculations and logical comparisons on data.  It is part of the central processing unit (CPU), and in  practice  there  may  be  separate  and  multiple  arithmetic and logic units ,. The ALU works by first retrieving a code that represents the operation to be performed (such as ADD).  The code also specifies the location from which the data is to be retrieved and  to  which  the  results  of  the  operation  are  to  be  stored.  (For example, addition of the data from memory to a num-ber  already  stored  in  a  special  accumulator  register  within the CPU, with the result to be stored back into the accumu-lator. )  The  operation  code  can  also  include  a  specification of the format of the data to be used (such as fixed or float-ing-point  numbers)—the  operation  and  format  are  often combined into the same code. In  addition  to  arithmetic  operations,  the  ALU  can  also carry  out  logical  comparisons,  such  as  bitwise  operations that compare corresponding bits in two data words, corresponding to Boolean operators such as AND, OR, and xOR ,. The  data  or  operand  specified  in  the  operation  code  is retrieved as words of memory that represent numeric data, or  indirectly,  character  data  ,.  Once the operation is per-formed,  the  result  is  stored  (typically  in  a  register  in  the CPU).   Special  codes  are  also  stored  in  registers  to  indicate characteristics  of  the  result  (such  as  whether  it  is  positive, negative,  or  zero).   Other  special  conditions  called  excep-tions  indicate  a  problem  with  the  processing.   Common exceptions include overflow, where the result fills more bits than are available in the register, loss of precision (because there  isn’t  room  to  store  the  necessary  number  of  decimal places),  or  an  attempt  to  divide  by  zero.   Exceptions  are typically  indicated  by  setting  a  flag  in  the  machine  status register.  ",1,Boat
300,"An  applet  is  a  small  program  that  uses  the  resources  of  a larger program and usually provides customization or addi-tional  features.   The  term  first  appeared  in  the  early  1990s in  connection  with  Apple’s  AppleScript  scripting  language for the macintosh operating system.  Today Java applets rep-resent the most widespread use of this idea in Web develop-ment ,. Java  applets  are  compiled  to  an  intermediate  repre-sentation  called  bytecode,  and  generally  are  run  in  a  Web browser  ,.   Applets  thus  represent  one of  several  alternatives  for  interacting  with  users  of  Web pages  beyond  what  can  be  accomplished  using  simple  text markup  ,. An  applet  can  be  invoked  by  inserting  a  reference  to its  program  code  in  the  text  of  the  Web  page,  using  the HTmL applet element or the now-preferred object element.  Although  the  distinction  between  applets  and  scripting code  (such  as  in  PHP)  is  somewhat  vague,  applets  usually run  in  their  own  window  or  otherwise  provide  their  own interface,  while  scripting  code  is  generally  used  to  tailor the  behavior  of  separately  created  objects.   Applets  are  also rather  like  plug-ins,  but  the  latter  are  generally  used  to provide  a  particular  capability  (such  as  the  ability  to  read or  play  a  particular  kind  of  media  file),  and  have  a  stan-dardized facility for their installation and management ,. Some  common  uses  for  applets  include  animations  of scientific or programming concepts for Web pages support-ing  class  curricula  and  for  games  designed  to  be  played using  Web  browsers.   Animation  tools  such  as  Flash  and Shockwave are often used for creating graphic applets. To  prevent  badly  or  maliciously  written  applets  from affecting  user  files,  applets  such  as  Java  applets  are  gen-erally  run  within  a  restricted  or  “sandbox”  environment where, for example, they are not allowed to write or change files on disk.  ",1,Boat
301,"In  personal  computers  a  chipset  is  a  group  of  integrated circuits that together perform a particular function.  System purchasers  generally  think  in  terms  of  the  processor  itself (such  as  a  Pentium  III,  Pentium  IV,  or  competitive  chips from AmD  or  Cyrix).   However  they  are  really  buying  a system  chipset  that  includes  the  microprocessor  itself  , and often a memory cache (which may be part of the microprocessor or a separate chip—see cache) as  well  as  the  chips  that  control  the  memory  bus  (which connects  the  processor  to  the  main  memory  on  the  moth-erboard—see bus. )  The  overall  performance  of  the  system depends not just on the processor’s architecture (including data  width,  instruction  set,  and  use  of  instruction  pipe-lines)  but  also  on  the  type  and  size  of  the  cache  memory, the memory  bus  (RDRAm  or  “Rambus”  and  SDRAm)  and the  speed  with  which  the  processor  can  move  data  to  and from memory. In addition to the system chipset, other chipsets on the motherboard are used to support functions such as graphics (the AgP,  or  Advanced graphics  Port,  for  example),  drive connection  (EIDE  controller),  communication  with  exter-nal devices ,, and connections to expansion cards (the PCI bus). At  the  end  of  the  1990s,  the  PC  marketplace  had  chip-sets  based  on  two  competing  architectures.   Intel,  which originally  developed  an  architecture  called  Socket  7,  has switched  to  the  more  complex  Slot-1  architecture,  which is  most  effective  for  multiprocessor  operation  but  offers the advantage of including a separate bus for accessing the cac  he memory.  meanwhile,  Intel’s  main  competitor,  AmD, has  enhanced  the  Socket  7  into  “Super  Socket  7”  and  is offering  faster  bus  speeds.   On  the  horizon  may  be  com-pletely  new  architecture.   In  choosing  a  system,  consumers are locked into their choice because the microprocessor pin sockets used for each chipset architecture are different. ",1,Boat
302,"A  class  is  a  data  type  that  combines  both  a  data  structure and  methods  for  manipulating  the  data.   For  example,  a string  class  might  consist  of  an  array  to  hold  the  charac-ters in the string and methods to compare strings, combine strings,  or  extract  portions  of  a  string  ,. As  with  other  data  types,  once  a  class  is  declared, objects  (sometimes  called  instances)  of  the  class  can  be created  and  used.   This  way  of  structuring  programs  is called   object-oriented   programming   because   the   class object  is  the  basic  building  block  ,. Object-oriented  programming  and  classes  provide  sev-eral advantages over traditional block-structured languages.  In  a  traditional  BASIC  or  even  Pascal  program,  there  is no  particular  connection  between  the  data  structure  and the  procedures  or  functions  that  manipulate  it.   In  a  large program  one  programmer  might  change  the  data  structure without  alerting  other  programmers  whose  code  assumes the  original  structure.   On  the  other  hand,  someone  might write  a  procedure  that  directly  manipulates  the  internal data rather than using the methods already provided.  Either transgression can lead to hard-to-find bugs. With  a  class,  however,  data  and  procedures  are  bound together,  or  encapsulated.   This  means  that  the  data  in  a class  object  can  be  manipulated  only  by  using  one  of  the methods  provided  by  the  class.   If  the  person  in  charge of  maintaining  the  class  decides  to  provide  an  improved implementation  of  the  data  structure,  as  long  as  the  data parameters  expected  by  the  class  methods  do  not  change, code  that  uses  the  class  objects  will  continue  to  function properly. ",1,Boat
303,"access Control Matrix means preparing a system permitting to bring together user and the system’s available resources.  Preparing a matrix requires the following steps: A broad level of groups of resources that share the same or similar security objectives is established based on requirements for Confidentiality, Integrity, Availability, User Accountability, Authentication and Audit (Compliance) (CIA UAA).  The resources include files, directories, applications, databases, hosts services, processes and others including those protected by the operating system or by other mechanisms.  Users are grouped according to common security needs into functional teams and a group owner is identified who is responsible for group management If necessary, naming standards for resources can be defined based on the findings under 1 & 2 above, thereby further facilitating resource groupings.  Now a decision can be made on the degree of access such as read, write, execute, take ownership, access control, delete, purge, modify, file scan ,.  Balancing central security control and group administration decides about the involvement of security administration.  A corporation’s access control matrix should not become a static document but, instead, regular review and improvement is a must.  This matrix is closely linked to a Role-Based Access management system, whereby user roles (e. g. , nurse versus private or general physician) have roles to perform requiring access and modification of data or addition of new information regarding an electronic patient file. ",1,Boat
304,"Active OS Fingerprinting is conducted in order to detect the target’s Oper ating System.  It is usually done by sending specially crafted network packets and comparing them against known responses.  Each operating system re sponds to different packet differently and even response to the ping command can give a good indication of the target OS.  Several methods have been developed and fingerprints are widely available on the internet.  The tool of the trade for this is a tool called Network Mapper (nmap).  While Active OS Fingerprinting is more accurate than Passive OS Fingerprinting, it has a significant disadvantage.  Being active, means that attackers have to send packets to the host, hence, Active versus passive Fingerprinting means risking discovery ,. ",1,Boat
305,"is a method used for dynamic web sites/pages thatincludes one or more scripts (small embedded programs) that are processedon a web server before the page is sent to the user.  An ASP is somewhat similarto a server-side include or a common gateway interface (CGI) application inthat it involves programs that run on the server, usually tailoring a page forthe user.  Typically, the script in the web page at the server uses input receivedas the result of the user’s request for the page to access data from a database,thereafter it builds or customizes the page on the fly before sending it to therequestor. ",1,Boat
306,"are similar to Java applets in that ActiveX controls may be includedwithin a web page.  The control is downloaded and executed on the browser’scomputer in the form of a pre-compiled executable.  Unfortunately, ActiveXdoes not enforce any form of security management technology.  Hence, ActiveX control has the same level of control of the client computer as theuser that is executing the browser.  ActiveX controls are specific to MicrosoftInternet Explorer (MSIE). ActiveX controls are elements that can be added to web pages, therebyproviding them with more functionality (e. g. , animation, video, and threedimensional browsing).  The controls are written in programming languagessuch as Visual Basic, C or C++.  They are written in a different code than theone used for the web pages itself such as HTML.  They could, however, beinfected with malicious code (Malware). Whatever risks are associated with running native executables on a computer also apply to ActiveX.  How security of ActiveX controls is handled isat the user’s discretion who runs the browser.  Without appropriate training this may be risky, justifying disabling this functionality within webbrowsers by setting security settings to ‘high,’ ActiveX is prevented fromrunning",1,Boat
307,"Advisory and Notification Markup Language (ANML) is an Extensible Markup Language (XML) -based specification for describing advisories and other types of notifications.  ANML is currently being developed to help in solving the inconsistent use of terminology by software vendors in their advisories.  The hope is that ANML will make it easy for applications to read these advisories.  This will make way for the necessary tools to automatically update systems.  Although ANML will have its biggest impact for security advisories, it can be used for any type of notification.  Some examples include bug-fixes, feature enhancements, upgrade availability, and many more.  More information can be found in Appendix 1 (Opensec) and Appendix 6 under ADML",1,Boat
308,"pronounced AL-go-rith-um is a procedure or formula for solving a problem.  The word derives from the name of the mathematician, Mohammed ibn-Musa al-Khwarizmi, who was part of the royal court in Baghdad and who lived from about 780 to 850.  Al-Khwarizmi’s work is the likely source for the word algebra as well.  Algorithm is any well-defined procedure (does not have to be computa tional) that takes some value or set of values as input and produces some value or set of values as output.  It is a technique that comes with a guarantee.  The technique for ratio nal function integration is an algorithm because it always produces the an swer, without exception.  Differentiation is an algorithm—given an elemen tary function, you can always find its derivative.  Algorithms can be fast or slow, but the important thing is the guarantee.  In some sense, an algorithm is a ‘predictable heuristic,’ whereby one cannot tell if a heuristic will work, before one tries it, but one knows in advance what the output of an algorithm will be.  In computing terms, algorithm is a sequence of computational steps that transform the input to the output.  A computer program can be viewed as an elaborate algorithm.  In mathe matics and computer science, an algorithm usually means a small procedure that solves a recurrent problem.  In this context the term Virus Algorithm means a set of operations or a procedure designed to create a virus problem.  In the context of Digital Signatures or Encryption, the algorithm describes how the signature or text is encrypted using mathematical formulas Another example is the Condensation algorithm (Conditional Density Propagation) that allows quite general representations of probability.  The simplicity of the Condensation algorithm also allows the use of non-linear motion models more complex than those commonly used in Kalman filters.  Using the statistical technique of importance sampling it is possible to build a Condensation tracker which runs in real time tracking a dancer or a hand as they move",1,Boat
309,Apache is a freely available multiplatform web server.  It is currently the most commonly used server on internet connected sites.  Its genesis was in early 1995 when developers of some high visibility web sites decided to pool their patches and enhancements to the NCSA / 1. 3 server to create a patchy server.  The project has since gained considerable momentum. ,1,Boat
310,"ASCII (American Standard Code for Information Interchange) is a series of standards used to identify simple characters (numbers, letters, etc. ) where each character is represented by a numerical code.  Each character is assigned a 7-bit code, whereby the bit has a minimum unit of data, 0 (zero) or 1.  ASCII files can be created using simple text editors.  ASCII is a universal computer code for English letters and characters.  Computers store all information as binary numbers, regardless of what make or brand the computer is.  ASCII also refers to a protocol for copying files from one computer to another over a network, in which neither computer checks for any errors that might have been caused by static or other problems.  The difficulty with ASCII is twofold: 1) 2) all special fonts and elements used in a document typed using one software (e. g. , WordPerfect) will be lost when the file / document is saved in ASCII format and than reloaded by somebody else into WordPerfect (or even Microsoft Word for that matter), and special characters such as those used in German cannot be transferred by ASCII (e. g. , ü is transferred as a blank and an ue must be typed instead).  Besides German, for many languages (e. g. , Chinese and Japanese), this represents a real problem.  For the above reasons, a new source called Unicode was developed ,.  As 8 bit codes only allow for 256 separate characters, a single 8-bit en coding is not suitable for all text requirements.  Even western alphabets have many ‘characters’, and once languages of China, and Braille are included there are many thousands of characters that are needed.  Of course, within a given domain, an implicit assumption of a particular character set could be made.  This leads to multiple 8-bit codes.  But it doesn’t work for those character sets where more than 256 characters are needed in the same context.  Both 7-bit ASCII and the various 8-bit extensions of it can be considered to be subsets of Unicode.  One does not need to know the above level of detail, but it is important to see why ASCII is insufficient, and why a standard is required for character encodings ,. ",1,Boat
311,"Asymmetrical Digital Subscriber Line (ADSL) allows voice, video anddata to be transmitted over a single telephone line at up to 6. 144 megabitsper second (Mbps) in a single direction, with significantly slower speedsin the other direction.  Accordingly, it is very appropriate for downloading large amounts of data but for certain applications, such as videoconferencing, other technologies work better [see also Very-High-bit-rateDigital Subscriber Line (VDSL), Discrete Multi-Tone (DMT) modulation,Quadrature Amplitude Modulation (QAM-VDSL)]. ",1,Boat
312,"Attack is a single unauthorized access attempt, or unauthorized use attempt,regardless of success.  Success may or may not result in the alteration, releasing or denying of data.  The likelihood of success depends on the effectivenessof implemented security measures that reduce the risk and probability for athreat resulting in a compromised system ,.  Computernetworks make it easier to start attacks and speed their dissemination, or forone anonymous individual to reach vast numbers of people at virtually nocost. Defending against Attacks means engineering in a world ruled by Satan’sLaw.  The differences between Attacks and Accidents are intent, intelligence,and control.  Things go wrong because there is a malicious and intelligentadversary trying to force things to go wrong ,Table 3A outlines a taxonomy of the attacks that can be launched againstinformation resources and infrastructure.  ",1,Boat
313,Authentication results in positively verifying the identity of a user‚ device‚ or another entity in an information system.  This is often a prerequisite for allowing access to resources offered by a system.  One element that contributes to the reliability of individual authentication is good password management practices.  In an area of high risk‚ stronger authentication may be required such as: Asymmetric Keys—see Access Control Biometrics—see Biometrics Cryptographic Tokens—see Cryptography Digital Certificates—see Digital Certificate Smart Cards—see Smart Card One-Time Password Generators—where password can be used once only.  Stronger authentication relies on combining one or more of the following: password / Pin or something else user knows‚ token or other means‚ that is something user has‚ and finally‚ biometrics or other technique enabling system to identify who the person is.  The above means may be used to verify the true source of a message or data.  But all approaches have their weak spots and combinations of measures are usually more effective.  In case of electronic voting‚ the term refers to verification that an electronic ballot really comes from the person it claims to have been initiated by‚ and not from an imposter. ,1,Boat
314,Backdoor is a hidden feature of an application prepared by its designer ormaintainers.  The backdoor gives the programmer special privileges for running the application.  These privileges are not available to the user. The motivation for such holes is not always sinister; some operating systems‚ for example‚ come out of the box with privileged accounts intended foruse by field service technicians or the vendor’s maintenance programmers. But we are not sure if such an account should be called backdoor – in ourunderstanding‚ backdoor is a hidden feature.  Yes‚ these accounts were sometimes hidden‚ Microsoft NT 3. 51 and then they could be called backdoors‚but generally they are not hidden. ,1,Boat
315,Batch Files are files usually describing automated sequence of commands. These are used in mainframe operations where even special languages weredeveloped for creation of batches.  Shell scripts known in the UNIX worldcan also be considered in some cases as batch files.  In MS-DOS and MSWindows context‚ these files are characterized by a . BAT extension.  Thesetext files contain MS-DOS commands‚ one on each line of the file that areprocessed in sequential order‚ for example when the computer is booted (e. g. ‚Autoexec. bat). ,1,Boat
316,"Binders are programs permitting hackers to ‘bind’ two or more programstogether resuling in a single . EXE file.  Hence‚ harmless . EXE animations‚e-greetings or other such files could have a Trojan horse inserted , ,. The only way to stop an executable from harming a PC or system is to run itin a proactive ‘sandbox’ environment and monitor its behavior for maliciousactivity in real-time. ",1,Boat
317,"Biometrics identification systems are based on the recognition of unique morphological characteristics of each individual‚ so that only the physical presence of the person will allow access to the system.  Numerous biometric parameters are available such as: facial‚ iris‚ fingerprints‚ hand and finger geometry‚ signature and voice recognition.  Although iris recognition has stronger security credentials‚ fingerprints are often preferred due to the maturity of the technology ,.  As Table 4A outlines‚ Retina Scan‚ Iris Scan and Hand Geometry are most accurate and both‚ the False Rejection Rate (FRR) and the False Acceptance Rate (FAR) are quite low for these Authentication measures based on Biometrics.  In Table 4B other measures are outlined that can be used for Access Control.  Often a system may use a Magnetic Swipe Card and a Keypad Entry System to give an employee access to a restricted office area or a database.  Some of the time a system such as the ones outlined in Table 4B may also be combined with one of those described and explained in Table 4C.  Unfortunately‚ all the one’s in Table 4C do have‚ however‚ some severe weaknesses that limit their Reliability and Validity.  In particular the FRR and FAR may not be satisfactory.  For instance‚ during May 2002 a Japanese group of researchers reported that using fake fingerprints fashioned from gelatin were able to fool biometric fingerprint readers 80% of the time.  The researchers also devised a way to create fake fingerprints from fingerprints left on glass surfaces.  What is interesting is that the material needed to make this work‚ was purchased at a neighborhood store and cost less than Euro 11.  This attack is a classic replay (or forgery) attack.  Unfortunately‚ replays are not unique to fingerprints but are a fundamental Vulnerability of all Biometrics ,.  The American Civil Liberties Union (ACLU) published a report during May 2002 about the inaccuracy of tests using facial recognition technology at the Palm Beach (FL) International Airport.  The technology failed to correctly identify faces more than half of the time.  The recognition rate went down when people wore glasses‚ turned their heads‚ or were moving. ",1,Boat
318,"Bluetooth is short-range radio that can be stuck on anything‚ including a mobile phone or computer as well a ticket barrier‚ or a trolley full of supermarketgoods.  In turn‚ users can use the technology to connect various devices (e. g. ‚computer and stereo) or pay at the train waving their Bluetooth enabled technology (e. g. ‚ card or mobile phone) to have the fare added to their monthlybill ,. Bluetooth was named after a century Danish King‚ Harald Bluetooth. The standard was founded by Ericsson in 1994 but it was joined by Nokia‚IBM and Intel in 1998 to form the Bluetooth Special Interest Group thatcampaigns for further Bluetooth adoption ,. ",1,Boat
319,Blue Screen of Death (BSOD) is a term used in relations to Microsoft Windows operating systems.  Some crashes of these systems appear as a bluesscreen with white hexadecimal text (part of memory dump).  Many usersconsider this a useless information‚ however it can be often used to detectmisbehaving programs (often not from Microsoft) causing these fatal crashes,1,Boat
320,Broadband is high-speed internet access.  Broadband may be delivered to private households with Asymmetrical Digital Subscriber Line (ADSL)‚ DigitalSubscriber Line (DSL)‚ Cable TV lines‚ Fixed Wireless Access or even satellite supported broadband in more remote areas,1,Boat
321,bulletin Board System(s) (BBS) are a type of online computer service thatfunctions as an electronic notice board.  Users can read or post messages‚download programs‚ and play online games.  Some functions of a BBS aresimilar to that of the internet‚ but on a smaller scale. ,1,Boat
322,"Business Continuity Plan (BCP) is a plan to ensure that the essential business functions of the organization are able to continue (or re-start) in the event of unforeseen circumstances; normally a disaster of some sort ,.  The BCP follows the Disaster Recovery Plan ,.  BCP identifies the critical people and their roles and functions while the BCP is in force‚ information‚ systems‚ and other infrastructures (e. g. ‚ telephones‚ servers‚ SMS gateways) that are required to enable the business to operate again fully.  The BCP lays out a detailed plan which‚ if called upon‚ should be executed to assure minimum additional disruption after a massive computer Virus Attack or disaster.  Companies that do not have clear business continuity plans remain very vulnerable.  Good recovery from a disaster is‚ however‚ contingent upon people‚ processes and training.  Finally‚ management awareness may be the main weakness in business continuity planning.  Doing the basics well is they key‚ whereby if one says one will take his or her data off site within 24 hours of a calamity‚ one must make sure that this is being done.  Hence‚ fire drills or ‘dress rehearsals’ by simulating various disaster scenarios will permit the organization to be in a better position‚ while recovering faster after a disaster.  Hence‚ business continuity and disaster recovery plans need to be exercised so that kinks may be worked out before the crisis hits. ",1,Boat
323,Disk Cache is a temporary storage place that a computer can use to storea file after reading it from the hard drive.  For instance‚ telling a computerto open a MP3 file‚ it may take several seconds for it to locate and read thefile into memory from the PCs hard drive.  However‚ if the computer storesthe file in the Disk Cache‚ the next time one wishes to open the same file‚data can be retrieved from the disk cache rather than loading it from the harddrive. One definition refers to a Disk Cache specifically as: hard disk-based memory used to store accessed web pages.  This technique enables the browserload the stored pages from the cache rather than from the network.  That iswhy clicking the ‘Back’ button on a browser usually retrieves a page nearlyinstantaneously.  The virtual memory system that comes with Microsoft Windows is also another example of disk caching to increase performance,1,Boat
324,File Cache is used to store the locations of frequently used files for quickreference.  When open a file that is stored on a hard drive‚ the computer willfirst check for the file name (and location) in the file cache.  If it finds thisinformation‚ the computer can jump immediately to the correct place on ahard drive without having to search in the file allocation table (a type of tableof contents for a computer’s hard drive).  Because read/write heads on a harddrive have to physically move across the disk to search for them‚ it takes timefor the computer to search the hard drive for files‚ that is why using the cacheis fasterISPs may also be required to pay copyright fees when caching in the nearfuture. ,1,Boat
325,Web Cache is closely related to Disk Caching and occurs between webservers and a client or many clients.  It watches requests for HTML pages‚images and files to come by‚ saving a copy for itself.  Then‚ if there is anotherrequest for the same object‚ it will use the copy that it has‚ instead of askingthe origin server for it again. This type of caching may‚ however‚ infringe upon copyrights and publishers and music distributors are trying to find a solution for this problem,1,Boat
326,omputer Security Incident Response Team (CSIRT) is a service organization that is responsible for receiving‚ reviewing‚ and responding tocomputer security Incident reports and activity. A CSIRT usually performs these services for a defined constituency or agroup of stakeholders.  These could a firm or a g,1,Boat
327,"certification Authority is a trusted third party clearing house issueing DigitalCertificates and Digital Signatures.  For firms‚ the certificates include thecorporation’s name‚ a serial number‚ and an expiration date.  A public key isalso enclosed to allow others to decrypt the message.  The digital signature ofthe certificate-issuing authority is also part of this‚ permitting the recipientto verify that the certificate is valid ,. The challenge is that in some countries‚ the government may require thatthe Key Recovery facilities must be exercised within its national borders. For instance‚ how this may affect citizens who have a Digital Signature todo e-government business with their local government when wanting to doa transaction with the EU or EC or another EU member state’s agency stillneeds to be addressed.  Will these other governments accept that the KRfacility is exercised in Denmark instead of‚ for instance‚ France?",1,Boat
328,"checksum is a mathematical method whereby the individual binary values ofa string of storage locations on a computer’s hard drive are summed up, andthe total is then retained for future reference.  On subsequent accesses, thesumming procedure is repeated, and the total compared to the one derivedpreviously. A difference indicates that an element of stored data has changed duringthe intervening period.  Agreement provides a high degree of assurance (butnot total assurance) that data have not been changed during the interveningperiod. A checksum is also used to verify that a network transmission has beensuccessful.  If the counts agree, it is safe to assume that the transmission wascompleted correctly ,. ",1,Boat
329,"Click Wrap Agreement checks if a user meets certain requirements, by clicking on the I Agree button, the user has agreed to complete terms of use agreement including another confirmation that the user meets certain requirements(e. g. , working at an educational institutions or being located in a country theproduct can and may be used).  To complete the agreement, the user mayagain be required to scroll to the bottom of the agreement and click on the “IAgree” icon [see also End User License Agreement (EULA), Jurisdiction]. This is also sometimes called a Shrink Wrap Agreement, whereby rippingoff the shrink wrap around the software implies that the user will take advantage of the software according to the conditions stipulated by the vendor",1,Boat
330,"Command and Conrol Warfare (C2W) is an integrated use of electronicwarfare, military deception, operations security, and also physical destruction.  These activities are supported by intelligence in order to deny information or degrade or destroy adversary command and control capabilities. Friendly C2 activities are protected C2W is an application of information operations in military operations and a subset of information warfare.  Hence,it can be offensive and defensive raising ethical questions for non militaryapplications if ever used. ",1,Boat
331,"Computer Metal Oxide Semiconductor (CMOS) is a section of the RAMmemory containing important data, such as date and time of the computerclock, and its configuration settings.  A battery that is housed on the computermotherboard powers the CMOS.  While a virus can overwrite information onthe CMOS, it can neither infect nor reside in it. ",1,Boat
332,"Confidentiality is the property that data or information is not made availableor disclosed to unauthorized, parties (e. g. , individuals, organizations andprocesses).  Hence, a health insurer cannot get access to medical files as suchbut only to information pertaining to a particular bill submitted electronicallyfor reimbursement",1,Boat
333,"cookies are data files that are stored on a hard disk by some web sites. Whenever visiting a Website, it tries to access this cookie enabling usersto enter the site according to one’s preferences (e. g. , first page shows news,email and horoscope).  Cookies may also store one’s password to access a siteunless the user prevents the browser from doing so, a must for any securityminded user.  Additional information is collected from subsequent browsingon the web site, to further personalize one’s browsing experience on this website (e. g. , customer profile). Cookies are accessible to a particular Website only and cannot be used byother Websites to gain information about the user",1,Boat
334,"Critical Infrastructure Protection (CIP) tries to coordinate efforts to protectcritical infrastructure that may include but not be limited to informationtechnology and utility grids (e. g. , electricity).  Critical Infrastructure mayinclude essential services such as telecommunication, finance/banking, foodproduction, transport and logistics, energy and utilities as well as criticalgovernment services. One also should consider that in many countries much of the CriticalInfrastructure (e. g. , electricity, gas distribution and shipping) is privatelyowned. Critical Infrastructure Protection may also include Emergency Preparedness.  Its mission is usually to enhance the safety and security of citizens orusers in their physical and cyber environments. Mandates could be such as:to provide a comprehensive approach to protecting critical infrastructure—thekey physical and cyber components of the energy and utilities, communications,services, transportation, safety and government sectors; andto be a government’s primary agency for ensuring national civil emergencypreparedness–for all types of emergencies. ",1,Boat
335,"Critical Information Infrastructure (CII) may include the information technology component (e. g. , hardware, software and data) of essential ser[1]vices, such as telecommunication, finance/banking, food production, trans[1]port and logistics, energy and utilities as well as critical government services .  One also should consider that in many countries much of the CII for essential services such as electricity supply lines are is privately owned.  CII may be vulnerable to an outside dimension that comes from disruption through natural disasters, accidents and mismanagement as well as deliberate Attack with criminal intent.  An inside dimension is Safety and System-related issues including Complexity. ",1,Boat
336,"cyberpunks embody behaviors similar to what we define as Crackers andphone phreaks but, in addition, they use technology to damage, destroy orcapitalize on the data they find (e. g. , for profit).  Most importantly, cyberpunksuse their know how to gain more information which, in turn, increases theirinfluence, power and potential threat upon others’ information world.  Mostof this activity is done at somebody else’s expense by, for example, breakingand entering into an organization’s voice mail system.  Gaining unauthorizedaccess and using IT resources and process while not being authorized to doso ,. Similar to the things we learned in Economics 101, demand and supply ofgoods are related.  Accordingly, cyberpunks can be compared to “fences” inNew York who sell stolen merchandise at very “attractive” prices.  As longas there is a consumer who is willing to go home with a “good” deal, even ifit is at the expense of the victim whose apartment / car was broken into, thenthe supply will continue.  If we stop purchasing from fences supply will drop;if cyberpunks find no demand for their illegally acquired information and,therefore fail to sell their goods, supply will be reduced ,. Finally, providing individual cyberpunks with five minutes of fame doesfurther reinforce the cool image or status the individual is striving for withinhis or her social group.  Lack of attaining fame, status or other benefits (e. g. ,being on a TV show) will also help reduce the supply of cyberpunks. ",1,Boat
337,"Cyclic Redundancy Check (CRC) is a technique used to determine fileintegrity through the generation of a CRC algorithm.  The CRC algorithmcalculates the CRC of the file in question.  This way a protection system canbe established, whereby if something changes, the CRC also changes.  Thispermits the detection of any possible modifications",1,Boat
338,"Darknets are a collection of networks and technologies used to share digitaland other content or objects (e. g. , software programs, songs, movies, andbooks) and have substantial non-infringing uses.  The darknet is not a separatephysical network but an application and protocol layer riding on existingnetworks. Darknets offer distributed object storage, whereby today’s Darknets do notrely upon any centralized server or service—a peer just needs the IP addressof one or a few participating peers to be able to reach any host on the Darknet. Also important is that with the open protocol, anyone can write a clientapplication for a particular Darknet.  Second, Gnutella is not really “run”by anyone: it is an open protocol and anyone can write a Gnutella clientapplication. Members-only darknets are popping up to protect file sharing from prying eyes.  Inn",1,Boat
339,"Data Encryption Standard (DES) has been the most popular encryptionalgorithm of the past twenty-five years.  Originally developed at IBM Corporation, it was chosen by the US’ National Bureau of Standards (NBS) asthe government-standard encryption algorithm in 1976.  Since then, it has become a domestic and international encryption standard, and has been used inthousands of applications.  Concerns about its short key length have doggedthe algorithm since the beginning, and in 1998 a brute-force machine capableof breaking DES was built.  Today, modifications to DES, such as triple-DES,ensure that it will remain secure for the foreseeable future",1,Boat
340,"Demilitarized Zone (DMZ) is a separate and shielded or ‘cut off’ systemfrom the main corporate network, containing technical equipment such asthe Webpage.  This further protects the main system from being accessed byexternal parties or via the InternetThe term comes from the buffer zone that was set up between North Koreaand South Korea following their war in the early 1950s.  A DMZ is not a singlesecurity component; it signifies a capability.  Within the DMZ one can find:firewalls,choke and access routers, and alsofront-end and back-end servers. Essentially, the DMZ provides multi-layer filtering and screening to completely block off access to the corporate network and data.  And, even wherea legitimate and authorised external query requests corporate data, no directconnection will be permitted from the external client, only a back-end serverwill issue the request (which may require additional authentication) fromthe internal corporate network.  How much data may be accessible from theoutside is also depending on asset values that may be represented by thesedata",1,Boat
341,"is considered to take place only when accessto a computer or network resource is intentionally blocked or degraded as aresult of malicious action taken by another user.  While these attacks coulddamage data directly or permanently they do not have to.  However, theyintentionally compromise the availability of the resources.  An attacker carriesout a denial-of-service attack by making a resource inoperative, by taking upso much of a shared resource that none of the resource is left for other users,or by degraded the resource so that it is less valuable to users.  Those sharedresources are reached through processes and can include other processes,shared files, disk space, percentage of CPU, modems, etc.  DoS is an attack based on the principles of the TCP Three-way Handshakeexploitation.  It was very popular in late 1990s.  Flooding system by speciallycrafted packets from one host could disable its networking capabilities andin some cases even force it to reboot.  Majority of the exploitable holes werepatched and this form of attack is nowadays nearly impossible. ",1,Boat
342,"Digital Certificates is the electronic version of an ID card that establishesone’s credentials and authenticates a person’s connection when performinge-commerce or e-government transactions. To obtain Digital Certificate an organization or individual must apply toa Certifications Authority which is responsible for validating and ensuringthe authenticity of requesting organization.  The Certificate will identify thename of the organization, a serial number, the validity date (“from / to”) andthe organization’s Public Key where encryption to / from that organizationis required. In addition, the Digital Certificate will also contain the Digital Signature ofthe Certification Authority to allow any recipient to confirm the authenticityof the Digital Certificate. A global standard (X.  509 Public Key Infrastructure for the Internet) defines the requirements for Digital Certificates and the major Certificate Authorities conform to this.  Such standards, and the integrity of the CertificateAuthorities are vital for the establishment of ‘digital trust’, without whiche-Commerce will never attain its full potential. ",1,Boat
343,"Digital Rights Management (DRM) (sometimes also called Digital Information Management) lets a document owner define how recipients can handledocuments in terms of forwarding, copying, and printing them.  Also allowsthe DRM holder to determine expiration dates for those permissions.  A document owner can also designate sections of a document that only certainpeople can change, force the use of revision marks for changes, and force theuse of certain formatting and styles.  Microsoft has integrated the same typeof functionality into Office Excel 2003 and Office Outlook 2003. To enable users to take advantage of DRM features in Office 2003, Windows Rights Management Services (RMS) for Windows Server 2003 hasto be implemented first on the network.  RMS is based on the ExtensibleRights Markup Language (XrML), which is a method for defining rights andpolicies. ",1,Boat
344,"Digital Signature uses public-key algorithm to generate a digital signature,which is a block of data used to create some authentication ,.  When a judge sees a digital signature, he or she does not knowanything about the signatory’s intentions.  He doesn’t know if the personagreed to the document as one being presented with a notarized signature. Nor do we know if the signatory ever saw the signed document.  The problemis that:while a digital signature authenticates the document up to the point of the signingcomputer,it does not authenticate the link between that computer and the individual. Digital signatures prove, mathematically, that a secret value known as theprivate key was present in a computer at the time the person’s signature wascalculated.  It is a small step from that inferring that the individual enteredthat key into the computer at the time of signing.  But it is a much largerstep to assume that the individual actually intended a particular documentto be signed.  And without a tamperproof computer trusted by the signingindividual, one can expect “digital signature experts” to show up in courtcontesting a lot of digital signatures. ",1,Boat
345,"Public Key (PKI) is used to verify that the signature was really generatedusing the corresponding private key.  Public keys are often registered witha third party and can be downloaded so the person can check if the key isgenuine.  (See also Digital Signatures). Public Key Infrastructure is needed as a means of generating and managing the encryption keys is required.  It is the use and management of cryptographic keys-a public key and a private key-for the secure transmission andauthentication of data across public networks.  Vendor systems do, however,differ (Key Recovery, Encryption-Authorization). ",1,Boat
346,Digital Watermark is a unique identifier being part of a digital document. The watermark is invisible to the human eye but a computer can analyze the document and extract the hidden data.  The watermark cannot beremoved. The primary use of such marks is to allow different marks to be used whenthe document is copied to different persons and thereby establish an AuditTrail should there be any leakage of information. ,1,Boat
347,"Disaster Recovery Plan deals with the immediate crisis and tries to securecritical IT infrastructure by preventing further spread or continuation of thecrisis such as a computer virus or a denial of service attack ,. The Disaster Recovery Plan is needed to make sure that when the disasterstrucks, people are being taken to safety quickly, or the further spread of aVirus or Trojan horse can be prevented.  Also, with the help of the BusinessContinuity Plan, systems can go online again immediately if need be or elsewithin the time frame planned and agreed upon beforehand ,",1,Boat
348,"Distributed Denial-of-Service Attack (DDoS) is a distributed version ofDoS.  Many hosts are used to send packets to a target host.  This way the hostis flooded by a high amount of traffic and similar results to DoS are achieved,. Administrators should check any systems connected to the internet frequently for the presence of DDoS software that could be used to attack othernetworks by following the steps as outlined in Table 8. Moreover, unnecessary ports should be closed.  For instance, during August 2003 MSBlaster took advantage of known vulnerable network ports inWindows, ports that should have been closed. ",1,Boat
349,"The Domain Name System (DNS) is the Internet's system for mapping alphabetic names to numeric Internet Protocol (IP) addresses like a phone book maps a person's name to a phone number.  For example, when a Web address (URL) is typed into a browser, a DNS query is made to learn an IP address of a Web server associated with that name. Using the www. example. com URL, example. com is the domain name, and www is the hostname.  DNS resolution maps www. example. com into an IP address (such as 192. 0. 2. 1).  When a user needs to load a webpage, a conversion must occur between what a user types into their web browser (www. example. com) into an IP address required to locate the www. example. com site. The DNS system is an open worldwide network of database name servers that include 13 authoritative name servers that serve the DNS root zone level, known as ""root servers"".  A root server (also called a DNS root nameserver) receives a DNS query that includes a domain name (e. g.  www. thousandeyes. com), and responds by directing that request to a top-level domain (TLD) nameserver, based on the TLD of that domain such as . com, . net, and . org.  It directly responds to requests for DNS records in the root zone by returning an appropriate list of the authoritative TLD name servers for the appropriate TLD that can resolve the initial DNS lookup request for an IP address of that domain name. ",1,Boat
350,"A dynamic link library (DLL) is a collection of small programs that larger programs can load when needed to complete specific tasks.  The small program, called a DLL file, contains instructions that help the larger program handle what may not be a core function of the original program. An example of those tasks might be communicating with a specific device, such as a printer or scanner to process a document.  DLL files that support specific device operations are known as device drivers. DLL contains bits of code and data, like classes and variables, or other resources such as images that the larger program can use. In addition to being a generic term for dynamic link libraries, Dynamic Link Library is also the name of Microsoft's version of the shared library concept for Windows.  A shared library can exist in any operating system (OS). ",1,Boat
351,"e-Government is the public’s efforts to bring dealings with the governmentonline, thereby enabling citizens to conduct most of their businesses (e. g. ,ordering a passport) online.  Accordingly, while the UK wants every government transaction to be offered online by 2005, Denmark has chosen toprovide all of its citizens with digital signatures to enable them to do all theirtransactions online ,. Pushing e-Government initiatives requires satisfactory IT security of information, data and protection of people’s privacy which can be a challenge. For instance in 2002, Canada’s Auditor General released a report in which itstated that government sites do not seem to do well as far as privacy and datasecurity are concerned.  His 2003 report acknowledged some improvementsbut did not yet give e-Government sites a passing grade.  Quite likely, othergovernments may have to improve on this score as well. As Table 9 suggests, putting down a policy about e-government and ITinitiatives is important.  The hard work follows thereafter.  Providing everycitizen with a digital signature is a start but, without addressing the issuesin Table 9, it is unlikely to improve service for citizens.  Accordingly, governments will have to learn how to manage the changed relationships withtheir citizens and business thanks to e-government.  Also, Identity Theft maybecome an issue thanks to increased use of digital signatures by citizensinteracting with the government. ",1,Boat
352,"eMail or Electronic Mail is an electronically transmitted message which arrives as a computer file on a user’s PC or the corporation’s server.  Originallyconceived as a simple means of sending short messages from one computer toanother, the Simple Mail Transfer Protocol (SMTP) was introduced withoutsecurity in mind. Whilst standards have been agreed for the attachment of files to eMailmessages, be aware that such files can contain Malicious Code such as a Virus. eMail is insecure because:Message can purport to have been sent from an individual, whilst it was sentfrom somebody else, possible misrepresentation;The From field may have been modified to indicate a sender that is fallacious ordoes not exist;Because there is no Authentication, the eMail can be opened by anyone unlessit is encrypted ,;When sending eMail, the sender has no guarantee that the recipient has receivedit after passing through multiple computer nodes to get to the final destination, hence, without requesting safe receipt there is little guarantee ,; andeMail is not a legal document unless sent using a digital signature but by 2002,EU member states and the USA (some states) have begun accepting documents withDigital Signatures as legally binding documents",1,Boat
353,"Encryption is the process of conversion of an easily understood format (text)into another format apparently lacking sense because it is encoded.  Theencrypted text is called ciphertext ,. In the Encryption context, Algorithms use a key to control encryption anddecryption (See Algorithm), two categories are used:Symmetric (or Secret-key): Uses the same key for encryption & decryption, orthe latter key is easily derived from the encryption key ,. Asymmetric (or Public key): A different key is used for encrypting and decrypting a message; accordingly, the decrypting key cannot be derived from theencrypting key.  (See also Algorithms, Tables 11A and 11B). A majority of cryptographic products are software rather than hardwarebased.  Moreover, many are communications-oriented rather than data storageoriented; they heavily tend towards secure electronic mail, IP security (IPsec),and Virtual Private Network applications. In 1999 a report identified 805 hardware and / or software products incorporating cryptography manufactured in 35 countries outside the UnitedStates.  Most were manufactured in these countries in that order:United Kingdom, followed by Germany, Canada, Australia, Switzerland,Sweden, the Netherlands, and Israel. Other countries accounted for slightly more than a quarter of the world’stotal of encryption products.  Table 11A outlines some of the algorithms thathave been used based on the DES standard. Table 11B outlines the various standards that were submitted for testingand examination.  These finalists were part of the tests being undertaken toselect the Advanced Encryption Standard (AES) Rijndael",1,Boat
354,"nd User License Agreement (EULA) is a legally binding contract betweenthe developer or publisher of a software program (or application) and thepurchaser of that software.  The purchaser does not own the software but has merely a right to use it in accordance with the license agreement. During software installation, the EULA is usually shown and one is required to Accept or Refuse the terms ,. In some cases, the EULA is written on the outside of the packaging withthe breaking of the seal to the CD, indicating acceptance of the EULA. In all cases, the EULA is the contract which users ignore at their peril;and whilst most EULAs contain broadly similar clauses and restrictions, itis important to confirm these before committing your organization. ",1,Boat
355,"Extensive Mark-up Language (XML) is the first building bloc for a Semantic Web.  Invisible to the human viewer, XML tags can be used to describehow information on a page is structured, allowing visiting computers to readand act on it without human invention.  XML describes data in terms of its content.  In that respect XML is a markuplanguage that has significant potential for the capture and onward processingof data directly from web pages.  The real significance of this is that Businessto Business data transfer is greatly facilitated by XML as neither party needs.  to write interfaces to each other’s systems; they merely need to be able toaccept and process XML.  Unlike Hyper Text Mark-up Language (HTML) which is a single predefined language‚ XML is a metalanguage.  Hence‚ it is a language for describing other languages.  Therefore‚ visiting computers need to be familiar with thespecific XML language before then can interpret the web page or document. Hence‚ a computer can refer to an XML “schema” located elsewhere on theweb. ",1,Boat
356,Extranet helps the organization to link the outside world such as suppliersand customers with a private intranet.  While this is similar to the internet‚access is controlled and restricted to particular groups‚ similar to the Intranet. Accordingly‚ an Extranet web server can be accessed by all the participantsinvolved in a project (e. g. ‚ various engineers and the firm developing a newproduct)‚ but not by anyone else.  In this example‚ the Extranet providesproject management functions for the work in progress and the work teamsinvolved.  The security is increased; however‚ breaches can still occur (e. g. ‚cyberpunk getting hold of a password or access to a server who‚ with apassword‚ is given access to the Extranet) ,1,Boat
357,Burden of Proof is the necessity or duty of affirmatively proving a factor facts in a dispute.  Hence‚ it is important to provide Reliable and Validevidence‚ especially if the victimized party (e. g. ‚ home user) wants to proofthat he or she has suffered damages through a computer virus.  In turn‚ anorganization requires a systematic approach to develop the costs (e. g. ‚ Tables2A–2D) to arrive at the quantified losses it suffered from,1,Boat
358,False Negative occurs when an actual intrusive action happened but thesystem fails to detect it or simply allows it to pass as a non-intrusive behavior.  Similarly if a virus was activated by a user action on the PC butthe software failed to detect it‚ a False Negative occurred ,1,Boat
359,"Firewall consists of a set of related programs‚ located at a network gateway server.  A firewall is a combination of hardware and software used toimplement a security policy governing the network traffic between two ormore networks.  Some of that traffic may be under the administrator’s control(e. g. ‚ organization’s networks) and some of which may be out of the systemadministrator’s control (e. g. ‚ the Internet). Firewalls determine whether to block or allow network traffic by lookingat TCP7IP packet headers to determine if these are in accordance with predetermined security policy.  However‚ a firewall does neither have the capabilityto recognize malicious code (Malware‚ Virus)‚ nor any means for preventingits transfer to a target system. A Firewall usually protects the resources of a private network from usersfrom other networks.  A network firewall commonly serves as a primary lineof defense against external threats to an organization’s computer systems‚networks‚ and critical information.  Firewalls can also be used to partition anorganization’s internal networks‚ reducing the risk from insider attacks. There are three types of firewalls:Pack Filter—filters the contents of the IP packet header‚ therefore‚ limited tothe source and destination address as well as the TCP/UDP port number.  Filterdoes not check content of message/data;Circuit Filter or Circuit Level Gateway—applies packet filtering but verifiesinformation based on TCP or UDP packet header information as well.  Hence‚it can make a better decision if the individual packets form part of a valid TCPsequence.  Creates a handshake‚ and once that takes place passes everythingthrough until the session is ended.  Still it has no knowledge of which user isrequesting access to services; andApplication Filter—uses proxies to apply filter rules based on the data contentand sometimes the user.  A dedicated program called a ‘proxy’ or ‘proxy server’is used to effect the application filter policy rules.  Commonly used applicationfilter is the web proxy.  It can be used to restrict the internal (or Intranet) webpages that are published out to the internet ,. ",1,Boat
360,Firmware often takes the form of a device which is attached to‚ or built into‚a computer‚ such as a ROM chip.  It performs some software function but isnot a program in the sense of being installed and run from the computer’sstorage media.  Hence‚ it is located in the middle of the conceptual continuumbetween hardware and software. ,1,Boat
361,Challenge-Handshake Authentication Protocol (CHAP) is used to periodically verify the identity of the peer using a 3-way handshake.  This isdone upon initial link establishment‚ and MAY be repeated anytime after thelink has been established. After the Link Establishment phase is complete‚ the authenticator sendsa “challenge” message to the peer which is a random byte-sequence as wellas the identifier‚ a randomly generated number.  The peer responds with avalue calculated using a “one-way hash” function.  The authenticator checksthe response against its own calculation of the expected hash value.  If thevalues match‚ the authentication is acknowledged; otherwise the connectionSHOULD be terminated. CHAP provides protection against playback attack through the use of anincrementally changing identifier and a variable challenge value.  The use ofrepeated challenges is intended to limit the time of exposure to any singleattack.  The authentication can occur between client and server‚ in largerinfrastructures‚ however‚ the administration of keys or passwords can bequite a big effort. CHAP also supports the use of central server that acts as a central certification unit according to such as‚ the Remote Access Dial-in User Serviceprinciple or is in control of the frequency and timing of the challenges. ,1,Boat
362,Hexadecimal is a numerical system using base 16 (as opposed to the usualbase 10).  Hexadecimal is a useful way to express binary computer numbersin which a byte is normally expressed as having 8 bits; with 2 hexadecimalcharacters representing eight binary digits—aka a byte. ,1,Boat
363,honeynet is a network of hosts that is specifically designed to be compromised.  It is further refinement of a Honeypot.  Highest security precautionsare taken and such networks are heavily monitored.  The purpose of suchnetworks is to study Hackers’ behaviors‚ tools‚ motives and possible contrameasures. ,1,Boat
364,Honeypot is a system or host specifically designed to be compromised. Such a system seems to be attractive to Hackers‚ but at the same momentthese are heavily monitored.  The purpose of such a host is to study attacker’sbehavior‚ security tools and possible contra measures. ,1,Boat
365,"Host means a computer that communicates across the network (e. g. ‚ information system‚ PC or other IT hardware).  But a host can also be a PC‚information system or other IT software or hardware that affords subsistenceor lodgment to an infectious agent under normal conditions ,.  Some malicious code or viruses pass successive stages in alternatehosts of different systems. ",1,Boat
366,Hyper Text Mark-up Language (HTML) is a descriptive language used forthe transmission of information‚ graphics‚ sounds and animation between aclient web browser and the web server using HTTP protocol. HTML tags‚ or mark-up‚ used in web pages dictate how the informationwill be displayed‚ such as a headline here or italics there.  However‚ they giveno clue as to the text’s meaning. ,1,Boat
367,Hyper Text Transfer Protocol (HTTP) is used for the transmission of information‚ graphics‚ sounds and animation between a client web browser andthe web server.  It is defined in RFC2616 and updated with RFC2817. ,1,Boat
368,"Secure Hyper Text Transfer Protocol (HTTPS) uses HTTP but additionally activates web server security‚ in the form of Secure Socket Layer (SSL). This means that the communications between the client and the (host) webserver are encrypted and‚ additionally‚ that the host web server may be validated by the client using a Digital Certificate on the server ,. The URL for such web sites indicates that they are secure by the use of‘https://address’ (rather than http://address). Some may list this term as shttp instead of https. ",1,Boat
369,"Integrated Services Digital Network (ISDN) allows voice, video and datato be transmitted over a single telephone line at speeds depending upon thenetwork provider.  In the mid 1990s ISDN offered speed of up to four timesas fast as conventional 28. 8 Kbps modems (up to 128 kilobits per second orKbps. There are two basic types of ISDN service: Basic Rate Interface (BRI)and Primary Rate Interface (PRI).  BRI consists of two 64 kb/s B channelsand one 16 kb/s D channel for a total of 144 kb/s.  This basic service isintended to meet the needs of most individual users. PRI is intended for users with greater capacity requirements.  Typically thechannel structure is 23 B channels plus one 64 kb/s D channel for a total of1536 kb/s. In Europe, PRI consists of 30 B channels plus one 64 kb/s D channel fora total of 1984 kb/s. ",1,Boat
370,"Internet Protocol Version 6 (IPv6) is the “next generation” protocol designed by the Internet Engineering Task Force (IETF) to replace the currentversion Internet Protocol, IP Version 4 (“IPv4”). Most of today’s internet uses IPv4, which is now twenty years old.  IPv4has been remarkably resilient in spite of its age, but it is beginning to haveproblems.  Most importantly, there is a growing shortage of IPv4 addresses,which are needed by all new machines added to the Internet. IPv6 fixes a number of problems in IPv4, such as the limited number ofavailable IPv4 addresses.  It also adds many improvements to IPv4 in areassuch as routing and network autoconfiguration.  IPv6 is expected to graduallyreplace IPv4, with the two coexisting for a number of years during a transitionperiod ,. ",1,Boat
371,"Internet Service Provider (ISP) describes a firm that provides access to theInternet, plus a range of standard services such as email and the hosting(running) of personal and corporate web sites. ISPs usually charge a tariff for their services although income can bederived from various sources of advertising and portal activities. ",1,Boat
372,Java Applets are Java applications with some security-related limitationsimposed on them.  These applets are downloaded to the local computer orpc.  They run within a Java ‘Sandbox’ created by a web browser.  This limitsthe applet’s ability to perform some functions that could be considered risky. Java applets cannot:execute arbitrary system commands;write to the local file system outside of strictly designated areas (but this is browserdependent); andopen network connections to sites other than the one from which the appletoriginated,1,Boat
373,"Java Sandbox contains specific provisions to deal with potentially dangerousapplets, and tries to execute them in a protected mode that severely limits theeffects they can have on other applications and the host computer.  The Javadesign team spent time worrying about malicious executables and how theycan be prevented from running amok, hence the Sandbox was invented. ",1,Boat
374,"JavaScript is an interpreted scripting language, similar in capability toMicrosoft’s Visual Basic, or SUN Microsystems’ Perl scripting language. Java script is interpreted, not compiled, and therefore slower to execute thancompiled code.  It is easier to maintain and fast enough for small applications.  Security risks associated with JavaScript are generally limited toDenial-of-Service (DoS) , attacks, such as excessive loadon the processor, or annoyance attacks ,. ",1,Boat
375,"Keystroke Monitoring is audit trail software or a specially designed device,recording every key struck by a user and every character of the response thatthe information system returns to the user. ",1,Boat
376,"Logic Bombs (also called Fork Bombs) is a program or portion thereoffthat triggers or causes an application or operating system to perform whena certain logical event occurs.  The code may be used to recursively spawncopies of itself, thereby eventually eating all the process table entries andeffectively locking up the system ,. A specific date, key combination, or internal counter are some of themost commonly used triggers that produce effects ranging from on-screendisplays to the blocking of the system or the deletion of files and programs. For instance, every day at 17:00 hours it mails out a message to 10 addressesout of a person’s email address database ,. A Virus may also no longer distribute itself after a certain date.  For instance,the Sobig virus family expired September 10, 2003 indicating that the writerwas primarily interested in studying the virus’ effects on networks.  However,this might change in the near future. ",1,Boat
377,"Master Boot Record (MBR) is the program stored in the boot sector of thebootable media.  MBR viruses normally enter the system through a floppydisk.  All floppy disks have a boot sector, regardless of whether they arebootable or not.  If the computer is started with a floppy disk in drive “A:”,the operating system reads the information contained in its boot sector andchecks to see if it is bootable.  If there is a virus in this sector, the computerreads this virus code first, and therefore, the virus is able to infect the computer",1,Boat
378,"Moore’s Law is a theorem that states that the amount of information storableon a given amount of silicon has roughly doubled every year since the technology was invented.  First mentioned in 1964 by semiconductor engineerGordon Moore, co-founder of Intel in 1968, this held until the late 1970s,at which point the doubling period slowed to 18 months.  Some are nowsuggesting that it is taking again 24–30 months. ",1,Boat
379,"Open Source is code that is put into the public domain.  Hence, any usercan take advantage of it usually for free.  Most importantly, if the code ispopular many people may examine it and, therefore, assuring that securitybugs are published quickly.  Very nicely for users, fixes are usually availablein relatively short time thereafter",1,Boat
380,"Operating System are computer programs that that are primarily or entirelyconcerned with controlling the computer and its associated hardware, ratherthan with processing work for users.  Computers can operate without application software, but they cannot run without an operating system.  Examplesare DOS, MaxOS, Linux and Unix. ",1,Boat
381,Parallel Processing occurs when a computer uses more than one processor‚either to be able to perform more than one task at the same time or to improveprocessing speed by breaking down one larger task between different processors.  Parallel processing is not quite the same as ‘Multi-Tasking’ since‚by definition‚ a single processor cannot do two things at once.  It just seemsthat way to the user because the two things are handled one after the otherso very quickly. ,1,Boat
382,Password is usually a string of alphanumeric characters a user will type onhis or her keyboard with lower and/or uppercase letters as well and hopefullywithout vocals such as (19mlnMY82].  Ideally‚ a computer or a network hasits own dictionary of common passwords‚ whereby a password previouslyused or included in the dictionary is refused by the system. Passwords must never (ever) be written down.  Neither should one useone’s first‚ last or a family member’s name nor one containing all digits or aword contained in a dictionary.  Below are some additional issues that needto be remembered. ,1,Boat
383,Ubiquitous Computing is a term put forward by Mark Weiser in Ubiquitous Computing is a term put forward by Mark Weiser in 1988‚ describing it as information technology’s next wave after the mainframe and PC.  In this new world‚ what Weiser called “calm technology” will reside around us‚ interacting with users in natural ways to anticipate their needs and supply the information they want wherever they are.  Pervasive Computing requires that computing devices are ubiquitious and if not invisible‚ at least handy for users and easy to take wherever one wishes to go (e. g. ‚ small cellular used for tracking location of person).  PervasiveComputing envisions environments richly lathered with computation‚ communication and networked devices‚ mobile users interacting with their environment using speech and vision‚ with secure access to personal or publicdata.  Pervasive Computing environments will not simply be standalone vehicles for number crunching‚ rather they will immerse their users in a triad of nvisible computation‚ communication and devices‚ working in concert to satisfy userrequirements according to the facilities available in the environment. As such Pervasive Computing is a world saturated with computing andcommunication on the road to Ubiquitous Computing.  The latter also gracefully integrates social and end-user issues including but not limited to SocialInformatics and Social Securematics. ,1,Boat
384,"PHP is an HTML-embedded Web scripting language.  Accordingly‚ PHPcode can be inserted into the HTML of a Web page.  When a PHP page isaccessed‚ the PHP code is read or “parsed” by the server the page resides on. The output from the PHP functions on the page are typically returned asHTML code‚ which can be read by the browser.  Because the PHP code istransformed into HTML before the page is loaded‚ users cannot view the PHPcode on a page.  This make PHP pages secure enough to access databases andother secure information. A lot of the syntax of PHP is borrowed from other languages such as C‚Java and Perl ,.  However‚ PHP has a number of uniquefeatures and specific functions as well.  The goal of the language is to allowWeb developers to write dynamically generated pages quickly and easily. PHP is also helpful for creating database-driven Web sites. ",1,Boat
385,Ping stands for Packet Internet (or Inter-Network) Groper and is a packet(small message) sent to test the validity/availability of an IP address ona network.  The technical term for ‘ping’ is the Internet Control MessageProtocol.  Maliciously sending large volumes of ‘Pings’ to cause difficultiesfor anyone else attempting to access that address is known as Smurfing. ,1,Boat
386,Port Address Translation (PAT) is communication technology used byrouters to allow multiple users in a local network to access—with their ownIP address—the Internet or corporate networks via a single public address. PAT actually translates multiple private IP addresses to a single public address‚ or to a public sub network‚ recognized by the IP service provider.  Thisfunction can reduce operating costs‚ increase security and simplify Internetaccess. If an attacker wants to access ports connected to the 3Com OfficeConnectRemote 812 ADSL router the router will not allow this connection.  However‚firmware versions V1. 1. 9 and V1. 1. 7 had a confirmed vulnerability that ifa connection is made to a redirected port using PAT and then to any portnot redirected using PAT‚ the router allows the successive connections to anyport.  The problem exists with TCP and with UDP. ,1,Boat
387,"Port Scan gives a list of all ports that are actually listening.  The netstat command can be run locally to determine the open ports but an external port scanagainst the system is usually also needed.  If the results of netstat differ fromthe port scanning results‚ validation of why each port is open‚ and what isrunning on each port is needed.  Ports that cannot be validated or justifiedshould be closed.  The final list should be recorded and used to audit the portson a regular basis‚ thereby making sure no extraneous ports appear ,. Blocking ports is not a substitute for a comprehensive security solution.  Anattacker may have gained access via other means such as a dial-up modem‚ atrojan e-mail attachment‚ or a person who is an organization insider.  Hence‚the attacker can exploit these ports if not properly secured on every hostsystem in the firm",1,Boat
388,Pretty Good Privacy (PGP) is a software package permitting users to useencryption when exchanging messages‚ widely available.  Export versionsof PGP are different than versions used in the USA and Canada ,1,Boat
389,"Protocol is a set of formal rules describing how to transmit data, especiallyacross a network.  Low level protocols define the electrical and physicalstandards to be observed, bit- and byte-ordering and the transmission anderror detection and correction of the bit stream.  High level protocols dealwith the data formatting, including the syntax of messages, the terminal tocomputer dialogue, character sets, sequencing of messages etc.  Protocols are,therefore, a set of rules that define how communications should take place,as they are common formulas that enable two separate computers to ‘speak’with and ‘understand’ each other. The first group of protocols includes the Transmission Control Protocol/Internet Protocol (TCP/IP) family, used for communication via Internet. Other examples are such as HTTP that is used for Web page communications,being a subset of TCP/IP",1,Boat
390,"Radio Frequency Identification (RFID) technology was used by Gillette infield tests for tracking packets of razors through its supply chain.  Michelinplans to use vulcanizing to attach an RFID to a tire. Benetton is another clothing manufacturer that tested RFID tags in someproducts, such as, by weaving the technology into the collar tags of clothesthat cost at least $15 to keep track of them as they ship.  Benetton pulled backfrom this RFID trial after a consumer group announced a global boycott ofthe clothing manufacturer. The advantage of RFIDs over barcodes is that information can be collectedwithout a line of sight to the tag, hence, a pallet of goods or a razor can justbe scanned by passing through a radio field. With location tracking chips in mobile phones and toll payment cards thetechnology can always provide information about where the product and itsuser are currently located. This does not look good for data protection and Privacy and consumeradvocacy groups have complained loudly and continue fighting for citizen’srights to privacy. ",1,Boat
391,"Remote Access Tools (RATS) enables a person to access a server remotelyby using, for instance, a telephone modem or wireless access.  RAT candrift in and out of legitimacy according to the prevailing legal climate andthe ensuing degree of nervousness displayed by the legal department ,. Nonetheless, generally RATS are defined as being malicious programsthat run invisibly on host PCs.  They can permit an intruder remote accessand if successful give him or her also control of the machine or PC.  Theseprograms are usually installed for stealth installation and the programs mayby hidden via a Trojan Horse that is embedded in a game or another program. These are usually small files with a size of between 10 KB–30 KB. An attacker may try to hide this program using a so-called Binder tocombine a RAT with legitimate executables, thereby enabling the RAT toexecute in the background while the legitimate application runs as well,thereby keeping the victim unaware of these undesirable activities. Best known RATs are Back Orifice and SubSeven that can capture screen,sound and video content.  These Trojans are key loggers, remote controllers,FTP servers, and HTP servers.  Telnet servers and password finders are alsopart of their capabilities and RATS may also rogue mechanisms that hidethe Trojans by using encrypted communication.  Worse is if they also containprofessional-looking APIs, thereby making it feasible for other attackers toinsert additional features. ",1,Boat
392,"Rijndael Algorithm was finally chosen as the winner because it was thefastest of them all.  The algorithm was broken shortly after its adoption byMike Boyle and Chris Salter as well as by Phillip Rogaway within daysof its publication as the accepted AES.  However, academic breaks are theones that force you to change things in the design process; practical breaksforce you to change things in fielded equipment.  This work is clearly of theacademic-break variety ",1,Boat
393,"Role-Based Access Control (RBAC) means that access decisions are basedon the roles the user has as part of tasks to be performed ,. The central notion of RBAC is that users do not have discretionary access to enterprise objects.  Instead, access permissions are administrativelyassociated with roles, and users are administratively made members of appropriate roles.  This idea greatly simplifies management of authorizationwhile providing an opportunity for great flexibility in specifying and enforcing enterprise- specific protection policies.  Users can be made members ofroles as determined by their responsibilities and qualifications and can beeasily reassigned from one role to another without modifying the underlyingaccess structure.  Roles can be granted new permissions as new applicationsand actions are incorporated, and permissions can be revoked from roles asneeded. ",1,Boat
394,"Router is an interconnection device similar to a bridge but serves packets orframes containing certain protocols.  Hence, Routers link Local Area Networks (LANs) at the network layer. But with Home Users installing their own routers, Denial of Serive Attacks can become a nightmare.  For instance, in May 2003, the Universityof Wisconsin–Madison found that it was the recipient of a continuous largescale flood of inbound Internet traffic destined for one of the campus’ publicNetwork Time Protocol (NTP) servers.  The flood traffic rate was hundredsof-thousands of packets-per-second, and hundreds of megabits-per-second. The only recourse available to the University was to go to its ISP andasking it to null-route all this traffic to the university servers, meanwhilepaying a huge increase in bandwidth costs—an increase that seriously hurtthe university’s IT budget, and would have quickly depleted it they ISP didnot respond by null-routing the traffic. ",1,Boat
395,"Script Kiddie is a derogatory term used by “real” Hackers and security professionals for less skilled hackers.  These Hackers usually use scripts and toolsfrom internet without appropriate knowledge.  They often target Unix hostswith tools that are for targeting of MS Windows hosts and vice versa.  It hasbeen observed that these hackers are not having much knowledge and evensimple system commands may pose a significant challenge to them.  Unfortunately, these types of Hackers can cause as much harm as “real” Hackerscan. ",1,Boat
396,"Sector means pie-shaped slices and track that are concentric rings on a disk. A combination of two or more sections on a single track makes a clusteror block, the minimum unit used to store information.  The number of sectorsper track determines the size of each cluster.  In turn, the number of clusterson a disk’s surface decides the storage capacity of the disk. The sector is the smallest unit that can be accessed on a disk and it has asize of 512 Bytes. ",1,Boat
397,"Secure Hash A process which reduces a message of arbitrary length to afixed length fingerprint which is very unlikely to be the same for any othermessage.  The word “secure” indicates that the algorithm has been chosen sothat it is not possible to forge a message which to have given hash value, norto create two similar messages with the same hash value. ",1,Boat
398,"Secure Socket Layer (SSL) means that the communications between theclient and the (host) web server are encrypted and, additionally, that the hostweb server may be validated by the client using a Digital Certificate on theserver ,.  SSL is a protocol developedby Netscape.  The most common application of SSL is https for ssl-encryptedhttp.  Nowadays, many other protocols use advantages of SSL, such as POP,SMTP, and NNTP. ",1,Boat
399,Signature Based Intrusion Detection Systems are matching collected dataagainst known set of signatures of known attacks.  This means that thesesystems are only as good as their patter/finger print/signature database. These databases have to be continuously updated and maintained to assure their currency.  This is a tedious task and there are recently attemptsto create central repository and unified descriptive language for thesesystems. ,1,Boat
400,Smurfing is an attack that exploits features of the IP protocol within theTCP/IP protocol used for internet communications.  A smurf attack causes a victim’s computer to become completely ‘waylaid’ with answering fictitious network requests (‘Pings’) that it grinds to ahalt and prevents anyone else from logging on.  ,1,Boat
401,Sniffer is software designed to look at and/or to collect traffic on the wire. Sniffing tools are built into majority of UNIX type systems and there is wealthof free tools available on the internet for other platforms.  Majority of themare designed around the libpcap library and tcpdump tool.  Some IntrusionDetection Systems have option of being run as a sniffer too. ,1,Boat
402,"Social Engineering is a technique where persuasion and/or deception are usedto gain access to the systems.  This is typically implemented through humanconversation or other interaction.  Typical example of this is an attack wherea hacker pretends to be a high positioned IT executive traveling on companybusiness and having problems to connect to the organization’s informationsystem through its remote access point. The person may gradually succeed in persuading the Help Desk operatorto tell him or her all the necessary details for the connection set-up.  Later onattacker calls again, complaining that his password for some reason does notwork and persuades the Help Desk to change it to a password of her or hisliking.  Hence, the person may gain unauthorized access ,. The term can also be applied to exploiting the victim’s good intentions andlack of in-depth technical knowledge in order to inspire fear and confusion. This process is often considered in the context of ‘memetics’, which dealswith the transfer of memes (the ‘unit of cultural inheritance’) from brain tobrain. Where social engineering is linked to an IT security issue or hoax, it nearlyalways trades on technophobia ",1,Boat
403,"P2P Spoofing means that an attacker could have anonymously tricked aninnocent P2P user into downloading a contraband file from another user onthe P2P network.  This can occur by having an attacker modify search requestsand search results in transit by, for instance, placing the innocent user’s IPaddress in the search result packet that lists a contraband file.  Another waymight be whereby a search request for music has a hop count set to 255.  Theflawed P2P application permits the attacker to set the hop count value backto zero, thereby making the innocent user be seen as the originator.  Changingthe search string church hymns to Rolling Stones makes an authority assumethat the innocent user went out to search for illegal content. The difficulties for authorities is to prove that the apparent offender wasthe actual offender, in turn this would require that the agency proofs that therewere no malicious users on the P2P network at the time while the apparentoffender’s P2P application had no implementation flaws that are possible. ",1,Boat
404,"Steganography (“hidden writing”) is a form of data hiding.  Unlike cryptography, which creates an unreadable version of a message for anyone withoutthe key, Steganography conceals even the existence of secret messages.  Oneof the earliest forms of Steganography is spread-spectrum radio transmissions, in which parts of a message (even parts of individual bits) are senton pseudo-randomly varying radio frequencies; without the right equipment,the signal is merely electronic white noise. Steganography circumvents restrictions on encryption and preventsSIGINT (signals intelligence) personnel from detecting encrypted traffic. Digital watermarks and copy-protection schemes are forms of Steganography used to reduce the ease of illegal copying of intellectual property and totrace the origin of files ,. There are many tools available for embedding secret messages in otherfiles; for instance, MP3STEGO modifies MP3 audio files to hold messages. Steganalysis tools look for tell-tale patterns in changed data when lookingfor concealed messages. ",1,Boat
405,"Stream Cipher encrypts in small units, often a bit or a byte at a time.  Unlike abasic block cipher, a stream cipher will have output corresponding to a giveninput will depend on where in the message it occurs.  The simplest type ofstream cipher uses a complicated function, which retains state, to generatea pseudo-random sequence which is then combined with the input using asimple operation such as bytewise addition. ",1,Boat
406,"Just as the way business is organized and conducted has been profoundly changed by information and communications technology, the operation of government at all levels has been similarly affected.  The term e-government (or electronic government) is a way of looking at these changes as a whole and of considering how government uses (or might use) various computer applications. The use of information technology in government can involve changes in the organization and internal communications of government departments, changes in how services are delivered to the public, and providing new ways for the public to interact with the agency. Internally, government agencies have many of the same information management and sharing needs as private enterprises ,.  However, government agencies are likely to have to adapt their information systems to account for complex, specialized regulations (both those the agency administers and others it is subject to).  The standards of openness and accountability are generally different from and stricter than those that apply to private organizations. ",1,Boat
407,"Eiffel is an interesting programming language developed by Bertrand Meyer and his company Eiffel Software in the 1980s.  The language was named for Gustav Eiffel, the architect who designed the famous tower in Paris.  The language and accompanying methodology attracted considerable interest at software engineering conferences. Eiffel fully supports (and in some ways pioneered) programming concepts found in more widely used languages today ,.  Syntactically, Eiffel emphasizes simple, reusable declarations that make the program easier to understand, and tries to avoid obscure or lower-level code such as compiler optimizations. ",1,Boat
408,"Eiffel’s proponents note that it is more than a language: It is designed to provide consistent ways to revise and reuse program components throughout the software development cycle.  The current implementation of Eiffel is available for virtually all platforms and has interfaces to C, C++, and other languages.  This allows Eiffel to be used to create a design framework for reusing existing software components in other languages.  Eiffel’s consistent object-oriented design also makes it useful for documenting or modeling software projects",1,Boat
409,"There are a variety of ways to electronically register, store, and process votes.  In recent years older manual systems (paper ballots or mechanical voting machines) have been replaced in many areas with systems ranging from purely digital (touch screens) to hybrid systems where marked paper ballots are scanned and tabulated by machine.  However, voting systems have been subject to considerable controversy, particularly following the Florida debacle in the 2000 U. S.  presidential election. The criteria by which voting systems are evaluated include:, how easy it is for the voter to understand and use the system, accessibility for disabled persons, whether the voter’s intentions are accurately recorded , the ability to make a permanent record of the vote, prevention of tampering (physical or electronic), provisions for independent auditing of the votes in case of disputeThe degree to which a given system meets these criteria can vary considerably because of both design and implementation issues. ",1,Boat
410,"The earliest form of voting system consisted of paper ballots marked and tabulated entirely by hand.  The first generation of “automatic” voting systems involved mechanical voting machines (where votes were registered by pulling levers).  Next came two types of hybrid systems where votes were cast mechanically but tabulated automatically.  These systems used punch cards , or “marksense” or similar systems where the voter filled in little squares and the ballots were then scanned and tabulated automatically. The ultraclose and highly disputed 2000 U. S.  presidential election “stress-tested” voting systems that most people had previously believed were reasonably accurate.  The principal problems were the interpretation of punch cards that were not properly punched through (so-called dimpled or hanging chads) and the fact that some ballot layouts proved to be confusing or ambiguous.  Two types of voting systems have been proposed as replacements for the problematic earlier technology",1,Boat
411,"This type of system uses a screen display that can be directly manipulated by the voter ,.  In the most common type, called DRE (direct-recording electronic), a computer program interprets and tabulates the vote as it is cast, storing an image in a removable memory unit and (usually) printing out a copy for backup.  After voting is complete, the memory module can be sent to the central counting office.  (Alternatively, votes can be transmitted over a computer network in batches throughout the day. ) In a few cases, voting has also been implemented through secure Internet sites. ",1,Boat
412,"Concern about potential tampering with computers has led many jurisdictions to begin to replace touchscreen systems with optical-scan systems, where the voter marks a sturdy paper ballot.  (About half of U. S.  counties now use optical-scan systems. ) The advantage of optical systems is that the voter physically marks the ballot and can see how he or she has voted, and after tabulation the physical ballots are available for review in case of problems.  However, optical-scan ballots must be properly marked using the correct type of pencil, or they may not be read correctly.  Unlike the touchscreen, it is not possible to give the voter immediate feedback so that any errors can be corrected.  Optical-ballot systems may cost more because of paper and printing costs for the ballots, which may have to be prepared in several languages.  However this cost may be offset by not having to develop or validate the more complicated software needed for all-electronic systems. ",1,Boat
413,"Electronic mail is perhaps the most ubiquitous computer application in use today.  E-mail can be defined as the sending of a message to one or more individuals via a computer system, open the file, and look for messages.  In 1971, however, the ARPANET (ancestor of the Internet—see internet) was used by researchers at Bolt Beranek and Newman (BBN) to send messages from a user at one computer to a user at another.  The availability of e-mail helped fuel the growth of the ARPANET through the 1970s and beyond. connection. Development and ArchitectureThe simplest form of e-mail began in the 1960s as a way that users on a time-sharing computer system could post and read messages.  The messages consisted of text in a file that was accessible to all users.  A user could simply log into the",1,Boat
414,"When people think of a computer, they generally think of a general-purpose computing system housed in a separate box, for use on the desk or as a laptop or hand-held device.  However, the personal computer and its cousins are only the surface of a hidden web of computing capability that reaches deep into numerous devices used in our daily lives.  Modern cars, for example, often contain several specialized computer systems that monitor fuel injection or enhance the car’s grip on the road under changing conditions.  Many kitchen appliances such as microwaves, dishwashers, and even toasters contain their own computer chips.  Communications systems ranging from cell phones to TV satellite dishes include embedded computers.  Most important, embedded systems are now essential to the operation of critical infrastructure such as medical monitoring systems and power transmission networks.  (The potential vulnerability of embedded systems to the Y2K date-related problems was a major concern in the months leading up to 2000, especially because many embedded systems might have to be replaced rather than just reprogrammed.  In the event, it turned out that there were relatively few date-dependent systems and only minor disruptions were experienced",1,Boat
415,"One consequence of the universal computer concept , is that in principle any computer can be programmed to imitate the operation of any other.  An emulator is a program that runs on one computer but accurately processes instructions written for another ,.  For example, fans of older computer games can now download emulation programs that allow modern PCs to run games originally intended for an Apple II microcomputer or an Atari game machine.  Emulators allowing Macintosh and Linux users to run Windows programs have also achieved some success. In order to work properly, the emulator must set up a sort of virtual model of the target microprocessor, including appropriate registers to hold data and instructions and a suitably organized segment of memory.  While carrying out instructions in software rather than in hardware imposes a considerable speed penalty, if the processor of the emulating PC is much faster than the one being emulated, the emulator can actually run faster than the original machine. ",1,Boat
416,"In the earliest programming languages, any part of a program could access any other part simply by executing an instruction such as “jump” or “goto. ” Later, the concept of the subroutine helped impose some order by creating relatively self-contained routines that could be “called” from the main program.  At the time the subroutine is called, it is provided with necessary data in the form of global variables or (preferably) parameters, which are variable references or values passed explicitly when the subroutine is called.  When the subroutine finishes processing, it may return values by changing global variables or changing the values of variables that were passed as parameters",1,Boat
417,"The use of encryption to disguise the meanings of messages goes back thousands of years (the Romans, for example, used substitution ciphers, where each letter in a message was replaced with a different letter).  Mechanical cipher machines first came into general use in the 1930s.  During World War II the German Enigma cipher machine used multiple rotors and a configurable plugboard to create a continuously varying cipher that was thought to be unbreakable.  However, Allied codebreakers built electromechanical and electronic devices that succeeded in exploiting flaws in the German machine (while incidentally advancing computing technology).  During the cold war Western and Soviet cryptographers vied to create increasingly complex cryptosystems while deploying more powerful computers to decrypt their opponent’s messages. ",1,Boat
418,"This concept refers to the organization of data processing and communications across an entire corporation or other organization.  Historically, computing technology and infrastructure often developed at different rates in the various departments of a corporation.  For example, by the 1970s, departments such as payroll and accounting were making heavy use of electronic data processing (EDP) using mainframe computers.  The introduction of the desktop computer in the 1980s often resulted in operations such as marketing, corporate communications, and planning being conducted using a disparate assortment of software, databases, and document repositories.  Even the growing use of networking often meant that an enterprise had several different networks with at best rudimentary intercommunication",1,Boat
419,"Much publicity has been given to figures such as Microsoft founder and multibillionaire Bill Gates, who turned a vest-pocket company selling BASIC language tapes into the dominant seller of operating systems and office software for PCs.  Historically, however, the role of key entrepreneurs in the establishment of information technology sectors repeats the achievements of such 19th- and early 20th-century technology pioneers as Thomas Edison and Henry Ford.  There appear to be certain times when scientific insight and technological capability can be translated into businesses that have the potential to transform society while making the pioneers wealthy",1,Boat
420,"Ergonomics is the study of the “fit” between people and their working environment.  Because computers are such a significant part of the working life of so many people, finding ways for people to maximize efficiency and reduce health risks associated with computer use is increasingly important. Since the user will be looking at the computer monitor for hours on end, it is important that the display be large enough to be comfortably readable and that there be enough contrast.  Glare on the monitor surface should be avoided.  It is recommended that the monitor be placed so that the top line of text is slightly below eye level.  A distance of about 18 inches to two feet (roughly arm’s length) is recommended.  There has been concern about the health effects of electromagnetic radiation generated by monitors.  Most new monitors are designed to have lower emissions",1,Boat
421,"Transmitting data involves the sending of bits (ones and zeros) as signaled by some alternation in physical characteristics (such as voltage or frequency).  There are a number of ways in which errors can be introduced into the data stream.  For example, electrical “noise” in the line might be interpreted as spurious bits, or a bit might be “flipped” from one to zero or vice versa.  Generally speaking, the faster the rates at which bits are being sent, the more sensitive the transmission is to effects that can cause errors. While a few wrong characters might be tolerated in some text messages or graphics files, binary files representing executable programs must generally be received perfectly, since random changes can make programs fail or produce incorrect results.  Data communications engineers have devised a number of methods for checking the accuracy of data transmissions",1,Boat
422,"An important characteristic of quality software is its ability to handle errors that arise in processing (also called run-time errors or “exceptions”).  Before it is released for general use, a program should be thoroughly tested with a variety of input ,.  When errors are found, the soundness of the algorithm and its implementation must be checked, as well as the program logic ,.  Interaction between the program and other programs (including the operating system) as well as with hardware must also be considered.  (See bugsand debugging. )However, even well-tested software is likely to encounter errors.  Therefore a program intended for widespread use must include instructions for dealing with errors, anticipated or otherwise.  The process of error handling can be divided into four stages: validation, detection, communication, and amelioration. ",1,Boat
423,"An expert system is a computer program that uses encoded knowledge and rules of reasoning to draw conclusions or solve problems.  Since reasoning (as opposed to mechanical calculation) is a form of intelligent behavior, the field of expert systems (also called knowledge representation or knowledge engineering) is part of the broader field of AI",1,Boat
424,"An expert system has two main components, a knowledge baseand an inference engine.  The knowledge base consists of a set of assertions (facts) or of rules expressed as if .  .  .  then statements that specify conditions that, if true, allow a particular inference to be drawn ,.  The inference engine accepts new assertions or queries and tests them against the stored rules.  Because satisfying one rule can create a condition that is to be tested by a subsequent rule, chains of reasoning can be built up.  If the reasoning is from initial facts to an ultimate conclusion, it is called forward chaining.  If a conclusion is given and the goal is to prove that conclusion, there can be backward chaining from the conclusion to the assertions",1,Boat
425,"Today the term data is associated in many peoples’ minds mainly with computers.  However, data (as in “given facts” or measurements) has been used as a term by scientists and scholars for centuries.  Just as with a counting bead, a notch in a stick, or a handwritten tally, data as stored in a computer (or on digital media) is a representation of facts about the world.  These facts might be temperature readings, customer addresses, dots in an image, the characteristics of a sound at a given instant, or any number of other things.  But because computer data is not a fact but a representation of facts, its accuracy and usefulness depends not only on the accuracy of the original data, but on its context in the computer",1,Boat
426,"Abstract data types are used to describe a “generic” type of data, specifying how the data is stored and what operations can be performed on it ,. DFor example, an abstract stack data type includes a structure for storing data (such as a list or array) and a set of operations, such as “pushing” an integer onto the stack and “popping” (removing) an integer from the stack.  (For the process of combining data and operations into a single entity, see encapsulation. ) Abstract data types can be implemented directly in object-oriented programming languages",1,Boat
427,"One advantage of using abstract data types is that it separates a structure and functionality from its implementation.  In designing the abstract stack type, for example, one can focus on what a stack does and its essential functions.  One avoids becoming immediately bogged down with details, such as what sorts of data items can be placed on the stack, or exactly what mechanism will be used to keep track of the number of items currently stored.  This approach also avoids “featuritis,” the tendency to see how many possible functions or features one can add to the stack object.  For example, while it might be useful to give a stack the ability to print out a list of its items, it is probably better to wait until one needs such a capability than to burden the basic stack idea with extra baggage that may make it more cumbersome or less efficient. An abstract data type or its embodiment",1,Boat
428,"There are a variety of ways in which data (facts or measurements about the world) can be turned into a digital representation suitable for manipulation by a computer.  For example, pressing a key on the keyboard sends a signal that is stored in a memory buffer using a value that represents the ASCII character code for the key pressed.  Moving the mouse sends a stream of signals that are proportional to the rotation of the ball which in turn is calibrated into a series of coordinates and ultimately to a position on the screen where the cursor is to be moved.  Digital cameras and scanners convert the varying light levels of what they “see” into a digital image",1,Boat
429,"The data acquisition system begins with a transducer, which is a device that converts a physical phenomenon (such as heat) into a proportional electrical signal.  Transducers include devices such as thermistors, thermocouples, and pressure or strain gauges.  The output of the transducer is then fed into a signal conditioning circuit.  The purpose of signal conditioning is to make sure the signal fits into the range needed by the data processing device.  Thus the signal may be amplified or its voltage may be adjusted or scaled to the required level.  Another function of signal conditioning is to isolate the incoming signal from the computer to which the acquisition device is connected.  This is necessary both to protect the delicate computer circuits from possible “spikes” in the incoming signal and to prevent “noise” (extraneous electromagnetic signals created by the computer itself) from distorting the signal, and thus the ultimate measurements.  Various sorts of filters can be added for this purpose. ",1,Boat
430,"Data acquisition systems are essential to gathering and processing the detailed data required by scientific and engineering applications.  The automated control of chemical or biochemical processes requires the ability of the control software to assess real-time physical data in order to make timely adjustments to such factors as temperature, pressure, and the presence of catalysts, inhibitors, or other components of the process.  The highly automated systems used in modern aviation and increasingly, even in ground vehicles, depend on real-time data acquisition.  It is not surprising, then, that data acquisition is one of the fastest-growing fields in computing",1,Boat
431,"Database administration is the management of database systems ,.  Database administration can be divided into four broad areas: data security, data integrity, data accessibility, and system development. ",1,Boat
432,"With regard to databases, ensuring data security includes the assignment and control of users’ level of access to sensitive data and the use of monitoring tools to detect compromise, diversion, or unauthorized changes to database files ,.  When data is proprietary, licensing agreements with both database vendors and content providers may also need to be enforced. ",1,Boat
433,"Data integrity is related to data security, since the completeness and accuracy of data that has been compromised can no longer be guaranteed.  However, data integrity also requires the development and testing of procedures for the entry and verification of data (input) as well as verifying the accuracy of reports (output).  Database administrators may do some programming, but generally work with the programming staff in maintaining data integrity.  Since most data in computers ultimately comes from human beings, the training of operators is also important. Within the database structure itself, the links between data fields must be maintained (referential integrity) and a locking system must be employed to ensure that a new update is not processed while a pending one is incomplete ,. Internal procedures and external regulations may require that a database be periodically audited for accuracy.  While this may be the province of a specially trained information processing auditor, it is often added to the duties of the database administrator",1,Boat
434,"Accessibility has two aspects.  First, the system must be reliable.  Data must be available whenever needed by the organization, and in many applications such as e-commerce, this means 24 hours a day, 7 days a week (24/7).  Reliability requires making the system as robust as possible, such as by “mirroring” the database on multiple servers (which in turn requires making sure updates are stored concurrently).  Failure must also be planned for, which means the imple-130? ? ? ? database administrationmentation of onsite and offsite backups and procedures for restoring data ",1,Boat
435,"A database management system consists of a database (a collection of information, usually organized into records with component fields) and facilities for adding, updating, retrieving, manipulating, and reporting on data. ",1,Boat
436,"Broadly speaking, data communications is the transfer of data between computers and their users.  At its most abstract level, data communications requires two or more computers, a device to turn data into electronic signals (and back again), and a transmission medium.  Telephone lines, fiber optic cable, network (Ethernet) cable, video cable, radio (wireless), or other kinds of links can be used.  Finally, there must be software that can manage the flow of data",1,Boat
437,"Data communications are the basis both for networks and for the proper functioning of servers that provide services such as World Wide Web pages, electronic mail, online databases, and multimedia content (such as audio and streaming video).  While Web page design and e-commerce are the “bright lights” that give cyberspace its character, data communications are like the plumbing without which computers cannot work together.  The growing demand for data communications, particularly broadband services such as DSL and cable modems, translates into a steady demand for engineers and technicians specializing in the maintenance and growth of this infrastructure ,. ",1,Boat
438,"The process of removing redundant information from data so that it takes up less space is called data compression.  Besides saving disk space, compressing data such as e-mail attachments can make data communications faster. Compression methods generally begin with the realization that not all characters are found in equal numbers in text.  For example, in English, letters such as e and s are found much more frequently than letters such as j or x. By assigning the shortest bit codes to the most common characters and the longer codes to the least common characters, the number of bits needed to encode the text can be minimized",1,Boat
439,"The developer of each application program that writes data files must define a format for the data.  The format must be able to preserve all the features that are supported by the program.  For example, a word processing program will include special codes for font selection, typestyles (such as bold or italic), margin settings, and so on. In most markets there are more than one vendor, so there is the potential for users to encounter the need to convert files such as word processing documents from one vendor’s format to another.  For example, a Microsoft Word user needing to send a document to a user who has WordPerfect, or the user may encounter another user who also has Microsoft Word, but a later version. ",1,Boat
440,"A modern enterprise database system can contain hundreds of separate data items, each with important characteristics such as field types and lengths, rules for validating the data, and links to various databases that use that item ,.  There can also be many different views or ways of organizing subsets of the data, and stored procedures (program code modules) used to perform various data processing functions.  A developer who is creating or modifying applications that deal with such a vast database will often need to check on the relationships between data elements, views, procedures, and other aspects of the system",1,Boat
441,"The process of analyzing existing databases in order to find useful information is called data mining.  Generally, a database, whether scientific or commercial, is designed for a data mining? ? ? ? 135particular purpose, such as recording scientific observations or keeping track of customers’ account histories.  However, data often has potential applications beyond those conceived by its collector",1,Boat
442,"A data structure is a way of organizing data for use in a computer program.  There are three basic components to a data structure: a set of suitable basic data types, a way to organize or relate these data items to one another, and a set of operations, or ways to manipulate the data. For example, the array is a data structure that can consist of just about any of the basic data types, although all data must be of the same type.  The way the data is organized is by storing it in sequentially addressable locations.  The operations include storing a data item (element) in the array and retrieving a data item from the array. ",1,Boat
443,"The data structures commonly used in computer science include arrays (as discussed above) and various types of lists.  The primary difference between an array and a list is that an array has no internal links between its elements, data structures? ? ? ? 137while a list has one or more pointers that link the elements.  There are several types of specialized list.  A tree is a list that has a root (an element with no predecessor), and each other element has a unique predecessor.  The guarantee of a unique path to each tree node can make the operations of inserting or deleting an item faster.  A stack is a list that is accessible only at the top (or front).  Any new item is inserted (“pushed”) on top of the last item, and removing (“popping”) an item always removes the item that was last inserted.  This order of access is called LIFO (last in, first out).  A list can also be organized in a first in, first out (FIFO) order.  This type of list is called a queue, and is useful in a situation where tasks must “wait their turn” for attention",1,Boat
444,"The preceding data types all hold single values.  However, most modern languages allow for the construction of data types that can hold more than one piece of data.  The arrayis the most basic structured data type; it represents a series of memory locations that hold data of one of the basic types.  Thus, in Pascal an array of integer holds integers, each taking up two bytes of memory. Many languages have composite data types that can hold data of several different basic types.  For example, the struct in C or the record in Pascal can hold data such as a person’s first and last name, three lines of address (all arrays of characters, or strings), an employee number (perhaps an integer or double), a Boolean field representing the presence or absence of some status, and so on.  This kind of data type is also called a user-defined data type because programmers can define and use these types in almost the same ways as they use the language’s built-in basic types. What is the difference between data types and data structures? There is no hard-and-fast distinction.  Generally, data structures such as lists, stacks, queues, and trees are more complex than simple data types, because they include data relationships and special functions (such as pushing or popping data on a stack).  However, a list is the fundamental data type in list-processing languages such as Lisp, and string operators are built into languages such as Snobol.  (See list processing, stack, queue, and tree. )Further, in many modern languages fundamental and structured data types are combined seamlessly into classes that combine data structures with the relevant operations ,",1,Boat
445,"data warehouseModern business organizations create and store a tremendous amount of data in the form of transactions that become database records.  Increasingly, however, businesses are relying on their ability to use data that was collected for one purpose (such as sales, customer service, and inventory) for purposes of marketing research, planning, or decision support.  For example, transaction data might be revisited with a view to identifying the common characteristics of the firm’s best customers or determining the best way to market a particular type of product.  In order to conduct such research or analysis, the data collected in the course of business must be stored in such a way that it is both accurate and flexible in terms of the number of different ways in which it can be queried.  The idea of the data warehouse is to provide such a repository for data",1,Boat
446,"A decision support system (DSS) is a computer application that focuses on providing access to or analysis of the key information needed to make decisions, particularly in business.  (It can be thought of as a more narrowly focused approach to computer assistance to management—see management information system. )The development of DSS has several roots reaching back to the 1950s.  This includes operational analysis and the theory of organizations and the development of the first interactive (rather than batch-processing) computer systems.  Indeed, the SAGE automated air defense system developed starting in the 1950s could be described as a military DSS.  The system presented real-time information (radar plots) and enabled the operator to select and focus on particular elements using a light pen.  By the 1960s more-systematic research on DSS was underway and included the provocative idea of “human-computer symbiosis” for problem solving ,. ",1,Boat
447,"Dell Computer (NASDAQ: DELL) is one of the world’s leading manufacturers and sellers of desktop and laptop computers ,.  By 2008 Dell had more than 88,000 employees worldwide. The company was founded by Michael Dell, a student at the University of Texas at Austin whose first company was PC’s Limited, founded in 1984.  Even at this early stage Dell successfully employed several practices that would come to typify the Dell strategy: Sell directly to customers (not through stores), build each machine to suit the customer’s preferences, and be aggressive in competing on price. In 1988 the growing company changed its name to Dell Computer Corporation.  In the early 1990s Dell tried an alternative business model, selling through warehouse clubs and computer superstores.  When that met with little success, Dell returned to the original formula.  In 1999 Dell overtook Compaq to become the biggest computer retailer in America. ",1,Boat
448,"The unusual computing term demon (sometimes spelled daemon) refers to a process (program) that runs in the background, checking for and responding to certain events.  The utility of this concept is that it allows for automation of information processing without requiring that an operator initiate or manage the process. For example, a print spooler demon looks for jobs that are queued for printing, and deals with the negotiations necessary to maintain the flow of data to that device.  Another demon (called chron in UNIX systems) reads a file describing processes that are designated to run at particular dates or times.  For example, it may launch a backup utility every morning at 1:00 a. m.  E-mail also depends on the periodic operation of “mailer demons. ”",1,Boat
449,"Design patterns are an attempt to abstract and generalize what is learned in solving one problem so that it can be applied to future similar problems.  The idea was first applied to architecture by Christopher Alexander in his book A Pattern Language.  Alexander described a pattern as a description of situations in which a particular problem occurs, with a solution that takes into account the factors that are “invariant” (not changed by context).  Guidance for applying the solution is also provided. For example, a bus stop, a waiting room, and a line at a theme park are all places where people wait.  A “place to wait” pattern would specify the problem to be solved (how to make waiting as pleasant as possible) and suggest solutions.  Patterns can have different levels of abstraction or scales on which they apply (for example, an intimate theater and a stadium are both places of entertainment, but one is much larger than the other). Patterns in turn are linked into a network called a pattern language.  Thus when working with one pattern, the designer is guided to consider related patterns.  For example, a pattern for a room might relate to patterns for seating or grouping the occupants. ",1,Boat
450,"The concept of patterns and pattern languages carries over well into software design.  As with architectural patterns, a software pattern describes a problem and solution, along with relevant structures ,.  Note that patterns are not executable code; they are at a higher level (one might say abstract enough to be generalizable, specific enough to be applicable). Software patterns can specify how objects are created and ways in which they function and interface with other objects.  Patterns are generally documented using a common format",1,Boat
451,"Traditionally documents such as advertisements, brochures, and reports were prepared by combining typed or printed text with pasted-in illustrations (such as photographs and diagrams).  This painstaking layout process was necessary in order to produce “camera-ready copy” from which a printing company could produce the final product. Starting in the late 1980s, desktop computers became powerful enough to run software that could be used to create page layouts.  In addition, display hardware gained a high enough resolution to allow for pages to be shown on the screen in much the same form as they would appear on the printed page.  (This is known by the acronym WYSIWYG, or “what you see is what you get. ”) The final ingredient for the creation of desktop publishing was the advent of affordable laser or inkjet printers that could print near print quality text and high-resolution graphics",1,Boat
452,"A fundamental problem in computer design is the control of devices such as disk drives and printers.  Each device is designed to respond to a particular set of control commands sent as patterns of binary values through the port to which the device is connected.  For example, a printer will respond to a “new page” command by skipping lines to the end of the current page and moving the print head to the start of the next page, taking margin settings into account.  The problem is this: When an applications program such as a word processor needs to print a document, how should the necessary commands be provided to the printer? If every application program has to include the appropriate set of commands for each device that might be in use, programs will be bloated and much development effort will be required for supporting devices rather than extending the functionality of the product itself.  Instead, the manufacturers of printers and other devices such as scanners and graphics tablets typically provide a program called a driver.  (A version of the driver is created for each major operating system in use. ) The driver serves as the intermediary between the application, the operating system and the low-level device control system.  It is sometimes useful to have drivers in the form of continually running programs that monitor the status of a device and wait for commands. ",1,Boat
453,"Also called digital money or e-cash, digital cash represents the attempt to create a method of payment for online transactions that is as easy to use as the familiar bills and coins in daily commerce ,.  At present, credit cards are the principal means of making online payments.  While using credit cards takes advantage of a well-established infrastructure, it has some disadvantages.  From a security standpoint, each payment potentially exposes the payer to the possibility that the credit card number and possibly other identifying information will be diverted and used for fraudulent transactions and identity theft.  While the use of secure (encrypted) online sites has reduced this risk, it cannot be eliminated entirely ,.  Credit cards are also impracticable for very small payments from cents to a few dollars (such as for access to magazine articles) because the fees charged by the credit card companies would be too high in relation to the value of the transaction. ",1,Boat
454,"The concept of digital convergence is an attempt to explore the implications of so many formerly disparate analog media now being available in digital form.  All forms of digital media have key features in common.  First, they are essentially pure information (computer data).  This means that regardless of whether the data originally represented still images from a camera, video, or film, the sound of a human voice, music, or some other form of expression, that data can be stored, manipulated, and retrieved under the control of computer algorithms.  This makes it easier to create seamless multimedia presentations ,.  Services or products previously considered to be separate can be combined in new ways. ",1,Boat
455,"The dashboard of a car is designed to present vital real-time information to the driver, such as speed, fuel supply, and engine status.  Ideally this information should be easy to grasp at a glance, allowing for prompt action when necessary.  Conversely, unnecessary and potentially distracting information should be avoided, or at least relegated to an unobtrusive secondary display. A digital dashboard is a computer display that uses similar concepts.  Its goal is to provide an executive or manager with the key information that allows him or her to monitor the health of the enterprise and to take action when necessary.  (A digital dashboard can also be part of a larger set of management tools—see decision support system. ",1,Boat
456,"The term digital divide was coined in the late 1990s amid growing concern that groups such as minorities, the elderly, and rural residents were not becoming computer literate and connecting to the Internet at the same rate as the young, educated, and relatively affluent. Nearly a decade later this perception of a chasm has diminished somewhat.  According to the Pew Internet & American Life project, as of 2006 about two-thirds (70 per-148? ? ? ? digital dashboardcent) of American adults were using the Internet, and the number has continued to increase, though more slowly (there is evidence of a “hard core” unconnected population).  Groups that lagged in Internet usage included Americans 65 years or older (35 percent), African Americans (58 percent), and persons without at least a high school education (36 percent). ",1,Boat
457,"By default, once information is digitized it is simply a pattern of bits that can be easily copied within the same or a different medium, using a variety of software or the built-in facilities of the operating system.  Of course the development of tape-recording technology in the mid-20th century already made it possible to copy audio recordings, and the later development of videotape and the VCR did the same for video.  However, while analog copying techniques lose some accuracy (or fidelity) with each generation of copying, digital files can be copied exactly each time.  It is equally easy to e-mail, upload, or otherwise distribute audio or video files. Legally, the creator of an original work can assert copyright—literally, the “right to copy” or to control when and how the work is distributed.  Digital rights management (DRM) refers to a variety of technologies that can be used to enforce this right by making it at least difficult for the purchaser of one copy of a work to copy and distribute it in turn.  (Similar technologies have also been used to prevent copying of software, which is, after all, just another pattern of bits—see copy protection and software piracy andcounterfeiting. )",1,Boat
458,"This concept involves the creation of a software system that runs programs and stores data across a number of different computers, an idea pervasive today.  A simple form is the central computer (such as in a bank or credit card company) with which thousands of terminals communicate to submit transactions.  While this system is in some sense distributed, it is not really decentralized.  Most of the work is done by the central computer, which is not dependent on the terminals for its own functioning.  However, responsibilities can be more evenly apportioned between computers ,. ",1,Boat
459,"Distributed computing is particularly suited to applications that require extensive computing resources and that may need to be scaled (smoothly enlarged) to accommodate increasing needs ,.  Examples might include large databases, intensive scientific computing, and cryptography.  A particularly interesting example is SETI@home, which invites computer users to install a special screen saver that runs a distributed process during the computer’s idle time.  The process analyzes radio telescope data for correlations that might indicate receipt of signals from an extraterrestrial intelligence ,. Besides being able to marshal very large amounts of computing power, distributed systems offer improved fault tolerance.  Because the system is decentralized, if a particular computer fails, its processes can be replaced by ones running on other machines.  Replication (copying) of data across a widely dispersed network can also provide improved data recovery in the event of a disaster",1,Boat
460,"The operation of the Internet requires that each participating computer have a unique address to which data packets can be routed ,.  The Domain Name System (DNS) provides alphabetical equivalents to the numeric IP addresses, giving the now familiar-looking Web addresses (URLs), e-mail addresses, and so on. The system uses a set of “top-level” domains to categorize these names.  One set of domains is based on the nature of the sites involved, including: . com (commercial, corporate), . edu (educational institutions), . gov (government), . mil (military), . org (nonprofit organizations), . int (international organizations), . net (network service providers, and so on). The other set of top-level domains is based on the geographical location of the site.  For example, . au (Australia), . fr (France), and . ca (Canada).  (While the United States has the . us domain, it is generally omitted in practice, because the Internet was developed in the United States)",1,Boat
461,"The Document Object Model (DOM) is a way to represent a Web document , as an object that can be manipulated using code in a scripting language ,.  The DOM was created by the World Wide Web Consortium (W3C) as a way to standardize methods of manipulating Web pages at a time when different browsers used different access models.  The full specification is divided into four levels (0 through 3).  By 2005, most DOMspecifications were supported by the major Web browsers. Using DOM, a programmer can navigate through the hierarchical structure of a document, following links or “descending” into forms and user-interface objects.  With DOM one can also add HTML or XML elements, as well as load, save, or format documents. ",1,Boat
462,"DSL (digital subscriber line) is one of the two most prevalent forms of high-speed wired access to the Internet ,.  DSL can operate over regular phone lines (sometimes called POTS or “plain old telephone service”).  DSL takes advantage of the fact that existing phone lines can carry frequencies far beyond the narrow band used for voice telephony.  When installing DSL, the phone company must evaluate the quality of existing lines to determine how many frequency bands are usable, and thus how much data can be transmitted.  Further, because the higher the frequency the shorter the distance the signal can travel, the available bandwidth drops as one gets farther from the central office or a local DSL access Multiplexer (DSLAM)",1,Boat
463,"A digital video recorder (DVR) records digital television broadcasts and stores them on a disk ,.  DVRs first appeared as commercial products in 1999 in Replay TV and TiVo, the latter becoming the most successful player in the field. A DVR works with digital signals and discs rather than tape used by the video cassette recorders (VCRs) that had become popular starting in the 1980s.  The digital recorder has several advantages over tape:, much larger capacity, limited only by hard drive size, instant (random) access to any recorded programming without having to go forward or backward through a tape, the ability to “time shift” within a live broadcast, including pausing and instant replay, the ability to skip over commercials, digital special effects",1,Boat
464,"The C programming language was developed in the early 1970s by Dennis Ritchie, who based it on the earlier languages BCPL and B.  C was first used on DEC PDP-11 computers running the newly developed UNIX operating system, where the language provided a high-level alternative to the use of PDP Assembly language for development of the many utilities that give UNIX its flexibility.  Since the 1980s, C and its descendent, C++, have become the most widely used programming languages. ",1,Boat
465,"Introduced in 2002, C# (pronounced “C sharp”) is a programming language similar to C++ and Java but simplified in several respects and tailored for use with Microsoft’s latest programming platform ,.  C# is a general-purpose language and is thoroughly objectoriented—all functions must be declared as members of a class or “struct,” and even fundamental data types are derived from the System. Object class ,. Compared with C++, C# is stricter about the use and conversion of data types, not allowing most implicit conversions (such as from an enumeration type to the corresponding integer—see data structures).  Unlike C++, C# does not permit multiple inheritance (where a type can be derived from two or more base types), thereby avoiding an added layer of complexity in class relationships in large software projects.  (However, a similar effect can be obtained by declaring multiple “interfaces” or specified ways of accessing the same class. )Unlike Java (but like C++), C# includes pointers (and a safer version called “delegates”), enumerations (enum types), structs (treated as lightweight classes), and overloading (multiple definitions for operators).  The latest version of the language, C# 3. 0 (introduced in 2007), provides additional features for list processing and functional programming ,",1,Boat
466,"The C++ language was designed by Bjarne Stroustrup at AT&T’s Bell Labs in Murray Hill, New Jersey, starting in 1979.  By that time the C language had become well established as a powerful tool for systems programming ,.  However Stroustrup (and others) believed that C’s limited data structures and function mechanism were proving inadequate to express the relationships found in increasingly large software packages involving many objects with complex relationships. ",1,Boat
467,"During the late 1980s and 1990s, C++ became a very popular language for a variety of applications ranging from systems programming to business applications and games.  The growth of the language coincided with the development of more powerful desktop computers and the release of inexpensive, easy-to-use but powerful development environments from Microsoft, Borland, and others.  Since these compilers could also handle traditional C code, programmers could “port” existing code and use the object-oriented techniques of C++ as they mastered them.  By the late 1990s, however, C++, although still dominant in many areas, was being challenged by Java, a language that simplified some of the more complex features of C++ and that was designed 68? ? ? ? C++particularly for writing software to run on Web servers and browsers ,.  For an alternative approach to creating a somewhat more “streamlined” C-type language, ",1,Boat
468,A basic problem in computer design is how to optimize the fetching of instructions or data so that it will be ready when the processor (CPU) needs it.  One common solution is to use a cache.  A cache is an area of relatively fast-access memory into which data can be stored in anticipation of its being needed for processing.  Caches are used mainly in two contexts: the processor cache and the disk cache,1,Boat
469,"The use of a processor cache is advantageous because instructions and data can be fetched more quickly from the cache (static memory chips next to or within the CPU) than they can be retrieved from the main memory (usually dynamic RAM).  An algorithm analyzes the instructions currently being executed by the processor and tries to anticipate what instructions and data are likely to be needed in the near future.  (For example, if the instructions call for a possible branch to one of two sets of instructions, the cache will load the set that has been used most often or most recently.  Since many programs loop over and over again through the same instructions until some condition is met, the cache’s prediction will be right most of the time. )",1,Boat
470,"A disk cache uses the same general principle as a processor cache.  Here, however, it is RAM (either a part of main memory or separate memory on the disk drive) that is the faster medium and the disk drive itself that is slower.  When an application starts to request data from the disk, the cache reads one or more complete blocks or sectors of data from the disk rather than just the data record being requested.  Then, if the application continues to request sequential data records, these can be read from the high-speed memory on the cache rather than from the disk drive.  It follows that disk caching is most effective when an application, for example, loads a database file that is stored sequentially on the disk",1,Boat
471,"Caching techniques can be used in other ways.  For example, most Web browsers are set to store recently read pages on disk so that if the user directs the browser to go back to such a page it can be read from disk rather than having to be retransmitted over the Internet (generally a slower process).  Web servers and ISPs (such as cable services) can also cache popular pages so they can be served up quickly",1,Boat
472,"The final stage in the development of the calculator would be characterized by the use of electronics to replace mechanical (or electromechanical) action.  The use of logic 70? ? ? ? calculatorcircuits to perform calculations electronically was first seen in the giant computers of the late 1940s, but this was obviously impractical for desktop office use.  By the late 1960s, however, transistorized calculators comparable in size to mechanical desktop calculators came into use.  By the 1970s, the use of integrated circuits made it possible to shrink the calculator down to palm-size and smaller.  These calculators use a microprocessor with a set of “microinstructions” that enable them to perform a repertoire of operations ranging from basic arithmetic to trigonometric, statistical, or business-related function",1,Boat
473,"Development of automotive technology has tended to be incremental rather than revolutionary.  The core “hardware” such as the engine and drive train has changed little over several decades, other than the replacement of carburetors with fuel injection systems, and some improvements in areas such as brake design.  On the other hand there have been significant improvements in safety features such as seat belts, air bags, and improved crash absorption barriers. In recent years, however, the incorporation of computers in automobile design , has led to a number of significant advances in areas such as fuel efficiency, traction/stability, crash response, and driver information and navigation.  Put simply, cars are becoming “smarter” and are making driving easier and safer",1,Boat
474,"Much future progress in car computing will depend on creating integrated networking between vehicles and the road.  An advanced navigation system could take advantage of real-time information being transmitted by the surrounding vehicles.  For example, a stalled car would transmit warning messages to other drivers about the impending obstacle.  Vehicles that sense an oil slick, ice, or other road hazard could also “mark” the location so it can be avoided by subsequent drivers.  Data about the speed and spacing of traffic could provide real-time information about traffic jams, possibly routing vehicles into alternative lanes or other roads to reduce congestion and travel time ",1,Boat
475,"Smart cars are vehicles equipped with advanced computing and communication technologies that enable them to collect, analyze, and share data to provide a wide range of features and services.  These technologies include:Advanced Driver Assistance Systems (ADAS): Smart cars are equipped with a variety of sensors and cameras that enable ADAS features such as lane departure warning, automatic emergency braking, adaptive cruise control, and blind spot monitoring.  These features use computer algorithms to analyze data from the sensors and provide alerts or take action to prevent accidents. Connectivity: Smart cars are connected to the internet and other vehicles, enabling them to share data about traffic conditions, road hazards, and weather conditions.  This connectivity also allows for over-the-air software updates, remote diagnostics, and other services. Infotainment: Smart cars offer advanced infotainment systems that provide features such as internet connectivity, voice commands, music streaming, and navigation.  These systems are often integrated with the vehicle's ADAS features to provide real-time information and alerts. Self-driving: Some smart cars are capable of autonomous driving, using a combination of sensors, cameras, and computer algorithms to navigate roads without human intervention.  These cars are still in development and are not yet widely available. Energy Efficiency: Smart cars often use advanced technologies such as regenerative braking, stop-start systems, and aerodynamic designs to improve fuel efficiency and reduce emissions. ",1,Boat
476,"During the late 1950s and 1960s, software rapidly grew more complex—especially operating system software and large business applications.  With the typical program consisting of many components being developed by different programmers, it became difficult both to see the “big picture” and to maintain consistent procedures for transferring data from one program module to another.  As computer scientists worked to develop sounder principles , it also occurred to them that the power of the computer to automate procedures could be used to create tools for facilitating program design and managing the resulting complexity.  CASE, or computer-aided software engineering, is a catchall phrase that covers a variety of such tools involved with all phases of development",1,Boat
477,"The earliest design tool was the flowchart, often drawn with the aid of a template that could be used to trace the symbols on paper ,.  With its symbols for the flow of execution through branching and looping, the flowchart provides a good tool for visualizing how a program is intended to work.  However large and complex programs often result in a sea of flowcharts that are hard to relate to one another and to the program as a whole.  Starting in the 1960s, the creation of programs for manipulating flow symbols made it easier both to design flowcharts and to visualize them in varying levels of detail. ",1,Boat
478,"Once a program has been designed and implementation is under way, CASE tools can help the programmers maintain consistency across their various modules.  One such tool (now rather venerable) is the data dictionary, which is a database whose records contain information about the definition of data items and a list of program components that use each item ,.  When the definition of a data item is changed, the data dictionary can provide a list of affected components.  Database technology is also applied to software design in the creation of a database of objects within a particular program, which can be used to provide more extensive information during debugging. ",1,Boat
479,"Analysis tools are computer software or web applications that are used to analyze data, identify patterns, and draw insights from large and complex datasets.  These tools are used by analysts, researchers, and data scientists to process and interpret data, in order to make informed decisions and predictions. Some popular analysis tools include:Statistical analysis software: These tools are used to perform statistical analysis on data, such as hypothesis testing, regression analysis, and clustering.  Examples include R, SAS, and SPSS. Data visualization software: These tools are used to create charts, graphs, and other visual representations of data, in order to help users understand and communicate data insights.  Examples include Tableau, Power BI, and QlikView. Business intelligence software: These tools are used to analyze data from various sources, such as sales data, customer data, and financial data, in order to make informed business decisions.  Examples include SAP BusinessObjects, IBM Cognos, and Oracle Business Intelligence. Machine learning software: These tools are used to train and deploy machine learning models, in order to make predictions and automate decision-making.  Examples include TensorFlow, Scikit-learn, and Keras. Big data tools: These tools are used to process and analyze large and complex datasets, such as those generated by social media, sensors, and IoT devices.  Examples include Apache Hadoop, Spark, and Cassandra. ",1,Boat
480,"In the late 1990s, a new consumer technology enabled users to create their own CDs with data or audio tracks.  The cheapest kind, CD-R (Compact Disk Recordable) uses a layer of a dyed material and a thin gold layer to reflect the laser beam.  Data is recorded by a laser beam hitting the dye layer in precise locations and marking it (in one of several ways, depending on technology).  The lengths of marked (“striped”) track and unmarked track together encode the data. ",1,Boat
481,"The DVD (alternatively, Digital Video Disc or Digital Versatile Disc) is similar to a CD, but uses laser light with a shorter wavelength.  This means that the size of the pits and lands will be considerably smaller, which in turns means that much more data can be stored on the same size disk.  A DVD disk typically stores up to 4. 7 GB of data, equivalent to about six CDs.  This capacity can be doubled by using both sides of the disk. The high capacity of DVD-ROMs (and their recordable equivalent, DVD-RAMs) makes them useful for storing feature-length movies or videos, very large games and multimedia programs, or large illustrated encyclopedias.  The development of high-definition television (HDTV) standards spurred the introduction of higher capacity DVD formats.  The competition between Sony’s Blu-Ray and HD-DVD (backed by Toshiba and Microsoft, among others) was resolved by 2008 in favor of the former.  BluRay offers high capacity (25GB for single layer discs, 50GB for dual layer). ",1,Boat
482,"Cellular automata theory has been applied to a variety of fields that deal with the complex interrelationships of components, including biology (microbe growth and population dynamics in general), ecology (including forestry), and animal behavior, such as the flight of birds.  (The cues that a bird identifies in its neighbors are like the input conditions for a cell in a cellular automaton.  The “output” would be the bird’s flight behavior. )The ability of cellular automatons to generate a rich complexity from simple components and rules mimics the development of life from simple components, and thus cellular automation is an important tool in the creation and study of artificial life.  This can be furthered by combining a set of cellular automation rules with a geneticalgorithm, including a mechanism for inheritance of characteristics.  Cellular automation principles can also be applied to engineering in areas such as pattern or image recognition",1,Boat
483,"Governments have always to varying degrees concerned themselves with the content of public media.  The growing use of the Internet for expressive activities , has prompted authoritarian governments such as that of China to attempt to block “objectionable” material both through filtering techniques , and through pressure on service providers.  Further, users identified as creators of banned content may be subjected to prosecution.  However because of the Internet’s decentralized structure and the ability of users to operate relatively anonymously, Internet censorship tends to be only partially effective ,. In the democratic West, Internet censorship generally applies to only a few forms of content.  Attempts to criminalize the online provision of pornography to minors in the 1996 Communications Decency Act have generally been overturned by the courts as excessively infringing on the right of adults to access such content.  However, a succession of bills seeking to require schools and libraries to install Web-filtering software culminated in the Children’s Internet Protection Act, which was upheld by the U. S.  Supreme Court in 2003. ",1,Boat
484,"By itself, a Web page coded in HTML is simply a “static” display that does not interact with the user (other than for the selection of links).  (See html, dhtml, and xhtm. ) Many Web services, including online databases and e-commerce transactions, require that the user be able to interact with the server.  For example, an online shopper may need to browse or search a catalog of CD titles, select one or more for purchase, and then complete the transaction by providing credit card and other information.  These functions are provided by “gateway programs” on the server that can access databases or other facilities. One way to provide interaction with (and through) a Web page is to use the CGI (common gateway interface).  CGI is a facility that allows Web browsers and other client programs to link to and run programs stored on a Web site.  The stored programs, called scripts, can be written in various languages such as JavaScript or PHP , and placed in a cgi-bin folder on the Web server. The CGI script is referenced by an HTML hyperlink on the Web page, such as<A HREF=“http://www. MyServer. com/cgi-bin/MyScript”>MyScript </A>",1,Boat
485,"While the attention of the first computer designers focused mainly on numeric calculations, it was clear that much of the data that business people and others would want to manipulate with the new machines would be textual in nature.  Billing records, for example, would have to include customer names and addresses, not just balance totals. The “natural” representation of data in a computer is as a series of two-state (binary) values, interpreted as binary numbers.  The solution for representing text (letters of the alphabet, punctuation marks, and other special symbols) is to assign a numeric value to each text symbol.  The result is a character code, such as ASCII (American Standard Code for Information Interchange), which is the scheme used most widely today.  (Another system, EBCDIC (Extended Binary-Coded Decimal Interchange Code) was used during the heyday of IBM mainframes, but is seldom used today. ",1,Boat
486,"Sophisticated string processing (such as parsing and pattern matching) tends to be awkward to express in traditional number-oriented programming languages.  Several languages have been designed especially for manipulating textual data.  Snobol, designed in the early 1960s, is best 82? ? ? ? characters and stringsknown for its sophisticated pattern-matching and pattern processing capabilities.  A similar language, Icon, is widely used for specialized string-processing tasks today.  Many programmers working with textual data in the UNIX environment have found that the awk and Perl languages are easier to use than C for extracting and manipulating data fields.  (See awk and Perl. )",1,Boat
487,"Many PC users have become acquainted with chatting through participating in “chat rooms” operated by online services such as America Online (AOL).  A chat room is a “virtual space” in which people meet either to socialize generally or to discuss particular topics.  At their best, chat rooms can develop into true communities whose participants develop long-term friendships and provide one another with information and emotional support ,. However, the essentially anonymous character of chat (where participants often use “handles” rather than real names) that facilitates freedom of expression can also provide a cover for mischief or even crime.  Chat rooms have acquired a rather lurid reputation in the eyes of the general public.  There has been considerable public concern about children becoming involved in inappropriate sexual conversation.  This has been fueled by media stories (sometimes exaggerated) about children being recruited into face-toface meetings with pedophiles.  AOL and other online services have tried to reduce such activity by restricting online sex chat to adults, but there is no reliable mechanism for a service to verify its user’s age.  A chat room can also be supervised by a host or moderator who tries to prevent “flaming” (insults) or other behavior that the online service considers to be inappropriate",1,Boat
488,"For people who find commercial online services to be too expensive or confining, there are alternatives available for just the cost of an Internet connection.  The popular Internet Relay Chat (IRC) was developed in Finland by Jarkko Oikarinen in the late 1980s.  Using one of the freely available client programs, users connect to an IRC server, which in turn is connected to one of dozens of IRC networks.  Users can create their own chat rooms (called channels).  There are thousands of IRC channels with participants all over the world.  To participate, a user simply joins a channel and sees all messages currently being posted by other users of the channel.  In turn, the user’s messages are posted for all to see.  While IRC uses only text, there are now enhanced chat systems (often written in Java to work with a Web browser) that add graphics and other features. There are many other technologies that can be used for conversing via the Internet.  Some chat services (such as Cu-SeeMe) enable participants to transmit their images ,.  Voice can also be transmitted over an Internet connection ,.  For a very pervasive form of “ad hoc” textual communication, see texting and instant messaging",1,Boat
489,"The famous Turing test , proposes that if a human is unable to reliably distinguish messages from a computer from those of another person, the computer program involved can at least be provisionally declared to be “intelligent. ” The advent of textual communication via the Internet , has afforded a variety of ways to attempt to meet this challenge.  Programs that mimic human conversational styles have come to be known as “chatterbots. ”The prototypical chatterbot was ELIZA, developed by Joseph Weizenbaum in the mid-1960s ,.  ELIZA mimicked a form of nondirective psychotherapy in which the therapist echoes or plays off of the client’s statements as a form of gentle encouragement and validation.  Thus if one types, “My father didn’t really like me,” ELIZA might reply, “Tell me more about your father. ” Although primitive, ELIZA once inadvertently fooled an executive into thinking he was exchanging messages with Weizenbaum.  Other classic chatterbots include Parry, designed to mimic a paranoid, and the story-generating Racter. ",1,Boat
490,"With simple rules but endless permutations, chess has fascinated millions of players for hundreds of years.  When mechanical automatons became fashionable in the 18th century, onlookers were intrigued by “the Turk,” a chessplaying automaton.  While the Turk was eventually shown to be a hoax (a human player was hidden inside), the development of the electronic digital computer in the mid-20th century provided the opportunity to create a true automatic chess player. In 1950 Claude Shannon outlined the two basic strategies that would be used by future chess-playing programs.  The “brute force” strategy would examine the possible moves for the computer chess player, the possible replies of the opponent to each move, the possible next moves by the computer, and so on for as many half moves or “plies” as possible.  The moves would be evaluated by a “minimax” algorithm that would find the move that best improves the computer’s position despite the opponent’s best play. ",1,Boat
491,"The earliest computer chess theorists such as Claude Shannon and Alan Turing saw the game as one potential way to demonstrate true machine intelligence.  Ironically, by the time computers had truly mastered chess, the artificial intelligence (AI) community had concluded that mastering the game was largely irrelevant to their goals.  AI pioneers Herbert Simon and John McCarthy have referred to chess as “the Drosophila of AI. ” By this they mean that, like the ubiquitous fruit flies in genetics research, chess became an easy way to measure computer prowess.  But what was it measuring? The dominant brute-force approach was more a measure of computing power than the application of such AI techniques as pattern recognition.  (There is, however, still some interest in writing chess programs that “think” more like a human player. ) In recent years there has been some interest in programming computers to play the Asian board game Go, where positional and structural elements play a greater role than in chess.  However, even the latest generation of Go programs seem to be relying more on a statistical approach than a deep conceptual analysis. ",1,Boat
492,"In personal computers a chipset is a group of integrated circuits that together perform a particular function.  System purchasers generally think in terms of the processor itself (such as a Pentium III, Pentium IV, or competitive chips from AMD or Cyrix).  However they are really buying a system chipset that includes the microprocessor itself , and often a memory cache (which may be part of the microprocessor or a separate chip—see cache) as well as the chips that control the memory bus (which connects the processor to the main memory on the motherboard—see bus. ) The overall performance of the system depends not just on the processor’s architecture (including data width, instruction set, and use of instruction pipelines) but also on the type and size of the cache memory, the memory bus (RDRAM or “Rambus” and SDRAM) and the speed with which the processor can move data to and from memory. In addition to the system chipset, other chipsets on the motherboard are used to support functions such as graphics (the AGP, or Advanced Graphics Port, for example), drive connection (EIDE controller), communication with external devices ,, and connections to expansion cards (the PCI bus). ",1,Boat
493,"In the telecommunications industry, “the last mile” refers to the connections and equipment that actually bring content to users’ homes and businesses.  One source of Cisco’s continued growth in the 2000 decade is the way it has addressed the consumer sector through strategic acquisitions.  In 2003, Cisco acquired Linksys, maker of home Internet routers and wireless access points.  In 2005, Scientific Atlanta—maker of cable modems, digital cable boxes, and other consumer equipment—also became a Cisco company. The company has also entered the area of Internet telephony , by teaming up with Skype to build a cordless phone that can connect to a computer to make phone calls over the Internet. Moving from hardware into software, Cisco in 2007 purchased Utah Street Networks, a San Francisco–based maker of software to link online communities , and operator of the Tribe. net Web site.  Around the same time, Cisco made a much larger buy, acquiring WebEx, maker of online collaboration software, for $3. 2 billion. In 2007 Cisco had revenue of $35 billion, with more than 63,000 employees. ",1,Boat
494,"A class is a data type that combines both a data structure and methods for manipulating the data.  For example, a string class might consist of an array to hold the characters in the string and methods to compare strings, combine strings, or extract portions of a string ,. As with other data types, once a class is declared, objects (sometimes called instances) of the class can be created and used.  This way of structuring programs is called object-oriented programming because the class object is the basic building block ,. Object-oriented programming and classes provide several advantages over traditional block-structured languages.  In a traditional BASIC or even Pascal program, there is no particular connection between the data structure and the procedures or functions that manipulate it.  In a large program one programmer might change the data structure without alerting other programmers whose code assumes the original structure.  On the other hand, someone might write a procedure that directly manipulates the internal data rather than using the methods already provided.  Either transgression can lead to hard-to-find bugs. ",1,Boat
495,"It is often more efficient to have a large, relatively expensive computer provide an application or service to users on many smaller, inexpensive computers that are linked to it by a network connection.  The term server can apply to both the application providing the service and the machine running it.  The program or machine that receives the service is called the client. A familiar example is browsing the Web.  The user runs a Web browser, which is a client program.  The browser connects to the Web server that hosts the desired Web site.  Another example is a corporate server that runs a database.  Users’ client programs connect to the database over a local area network (LAN).  Many retail transactions are also handled using a client-server arrangement.  Thus, when a travel or theater booking agent sells a ticket, the agent’s client program running on a PC or terminal connects to the server containing the database that keeps track of what seats are available",1,Boat
496,"There are several advantages to using the client-server model.  Having most of the processing done by one or more servers means that these powerful and more costly machines can be used to the greatest efficiency.  If more processing capacity is needed, more servers can be brought online without having to revamp the whole system.  Users, on the other hand, only need PCs (or terminals) that are powerful enough to run the smaller client program to connect to the server. Keeping the data in a central location helps ensure its integrity: If a database is on a server, transactions can be committed in an orderly way to ensure that, for example, the same ticket isn’t sold to two people.  A client-server model also offers flexibility to users.  Any client program that meets the standards supported by the server can be used to make a connection. ",1,Boat
497,"The transfer of data within the microprocessor and between the microprocessor and memory must be synchronized to ensure that the data needed to execute each instruction is available when the flow of execution has reached an appropriate point.  This synchronization is accomplished by moving data in intervals that correspond to the pulses of the system clock (a quartz crystal).  This is done by sending control signals that tell the components of the processor and memory when to send or wait for data.  Thus, if the microprocessor is the heart of the computer, the clock is the heart’s pacemaker.  Because most devices cannot run at the same pace as the processor, circuits in various parts of the motherboard create secondary control signals that run at various ratios of the actual system clock speed. ",1,Boat
498,"Common Business-Oriented Language was developed under the impetus of a 1959 Department of Defense initiative to create a common language for developing business applications that centered on the processing of data from files.  (The military, after all, was a “business” whose inventory control and accounting needs dwarfed those of all but the largest corporations. ) At the time, the principal business-oriented language for mainframe computers was FLOW-MATIC, a language developed by Grace Hopper’s team at RemingtonRand UNIVAC and limited to that company’s computers ,.  The first COBOL compilers became available in 1960, and the American National Standards Institute (ANSI) issued a standard specification for the language in 1968.  Expanded standards were issued in 1974 and 1985 (COBOL-74 and COBOL-85) with a new standard issued in 2002. ",1,Boat
